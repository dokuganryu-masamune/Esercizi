/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __commonJS = (cb, mod) => function __require() {
  return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
var __accessCheck = (obj, member, msg) => {
  if (!member.has(obj))
    throw TypeError("Cannot " + msg);
};
var __privateGet = (obj, member, getter) => {
  __accessCheck(obj, member, "read from private field");
  return getter ? getter.call(obj) : member.get(obj);
};
var __privateAdd = (obj, member, value) => {
  if (member.has(obj))
    throw TypeError("Cannot add the same private member more than once");
  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
};
var __privateSet = (obj, member, value, setter) => {
  __accessCheck(obj, member, "write to private field");
  setter ? setter.call(obj, value) : member.set(obj, value);
  return value;
};

// node_modules/recordrtc/RecordRTC.js
var require_RecordRTC = __commonJS({
  "node_modules/recordrtc/RecordRTC.js"(exports, module2) {
    "use strict";
    function RecordRTC2(mediaStream, config) {
      if (!mediaStream) {
        throw "First parameter is required.";
      }
      config = config || {
        type: "video"
      };
      config = new RecordRTCConfiguration(mediaStream, config);
      var self = this;
      function startRecording(config2) {
        if (!config.disableLogs) {
          console.log("RecordRTC version: ", self.version);
        }
        if (!!config2) {
          config = new RecordRTCConfiguration(mediaStream, config2);
        }
        if (!config.disableLogs) {
          console.log("started recording " + config.type + " stream.");
        }
        if (mediaRecorder) {
          mediaRecorder.clearRecordedData();
          mediaRecorder.record();
          setState("recording");
          if (self.recordingDuration) {
            handleRecordingDuration();
          }
          return self;
        }
        initRecorder(function() {
          if (self.recordingDuration) {
            handleRecordingDuration();
          }
        });
        return self;
      }
      function initRecorder(initCallback) {
        if (initCallback) {
          config.initCallback = function() {
            initCallback();
            initCallback = config.initCallback = null;
          };
        }
        var Recorder = new GetRecorderType(mediaStream, config);
        mediaRecorder = new Recorder(mediaStream, config);
        mediaRecorder.record();
        setState("recording");
        if (!config.disableLogs) {
          console.log("Initialized recorderType:", mediaRecorder.constructor.name, "for output-type:", config.type);
        }
      }
      function stopRecording(callback) {
        callback = callback || function() {
        };
        if (!mediaRecorder) {
          warningLog();
          return;
        }
        if (self.state === "paused") {
          self.resumeRecording();
          setTimeout(function() {
            stopRecording(callback);
          }, 1);
          return;
        }
        if (self.state !== "recording" && !config.disableLogs) {
          console.warn('Recording state should be: "recording", however current state is: ', self.state);
        }
        if (!config.disableLogs) {
          console.log("Stopped recording " + config.type + " stream.");
        }
        if (config.type !== "gif") {
          mediaRecorder.stop(_callback);
        } else {
          mediaRecorder.stop();
          _callback();
        }
        setState("stopped");
        function _callback(__blob) {
          if (!mediaRecorder) {
            if (typeof callback.call === "function") {
              callback.call(self, "");
            } else {
              callback("");
            }
            return;
          }
          Object.keys(mediaRecorder).forEach(function(key) {
            if (typeof mediaRecorder[key] === "function") {
              return;
            }
            self[key] = mediaRecorder[key];
          });
          var blob = mediaRecorder.blob;
          if (!blob) {
            if (__blob) {
              mediaRecorder.blob = blob = __blob;
            } else {
              throw "Recording failed.";
            }
          }
          if (blob && !config.disableLogs) {
            console.log(blob.type, "->", bytesToSize(blob.size));
          }
          if (callback) {
            var url;
            try {
              url = URL2.createObjectURL(blob);
            } catch (e) {
            }
            if (typeof callback.call === "function") {
              callback.call(self, url);
            } else {
              callback(url);
            }
          }
          if (!config.autoWriteToDisk) {
            return;
          }
          getDataURL(function(dataURL) {
            var parameter = {};
            parameter[config.type + "Blob"] = dataURL;
            DiskStorage.Store(parameter);
          });
        }
      }
      function pauseRecording() {
        if (!mediaRecorder) {
          warningLog();
          return;
        }
        if (self.state !== "recording") {
          if (!config.disableLogs) {
            console.warn("Unable to pause the recording. Recording state: ", self.state);
          }
          return;
        }
        setState("paused");
        mediaRecorder.pause();
        if (!config.disableLogs) {
          console.log("Paused recording.");
        }
      }
      function resumeRecording() {
        if (!mediaRecorder) {
          warningLog();
          return;
        }
        if (self.state !== "paused") {
          if (!config.disableLogs) {
            console.warn("Unable to resume the recording. Recording state: ", self.state);
          }
          return;
        }
        setState("recording");
        mediaRecorder.resume();
        if (!config.disableLogs) {
          console.log("Resumed recording.");
        }
      }
      function readFile(_blob) {
        postMessage(new FileReaderSync().readAsDataURL(_blob));
      }
      function getDataURL(callback, _mediaRecorder) {
        if (!callback) {
          throw "Pass a callback function over getDataURL.";
        }
        var blob = _mediaRecorder ? _mediaRecorder.blob : (mediaRecorder || {}).blob;
        if (!blob) {
          if (!config.disableLogs) {
            console.warn("Blob encoder did not finish its job yet.");
          }
          setTimeout(function() {
            getDataURL(callback, _mediaRecorder);
          }, 1e3);
          return;
        }
        if (typeof Worker !== "undefined" && !navigator.mozGetUserMedia) {
          var webWorker = processInWebWorker(readFile);
          webWorker.onmessage = function(event2) {
            callback(event2.data);
          };
          webWorker.postMessage(blob);
        } else {
          var reader = new FileReader();
          reader.readAsDataURL(blob);
          reader.onload = function(event2) {
            callback(event2.target.result);
          };
        }
        function processInWebWorker(_function) {
          try {
            var blob2 = URL2.createObjectURL(new Blob([
              _function.toString(),
              "this.onmessage =  function (eee) {" + _function.name + "(eee.data);}"
            ], {
              type: "application/javascript"
            }));
            var worker = new Worker(blob2);
            URL2.revokeObjectURL(blob2);
            return worker;
          } catch (e) {
          }
        }
      }
      function handleRecordingDuration(counter) {
        counter = counter || 0;
        if (self.state === "paused") {
          setTimeout(function() {
            handleRecordingDuration(counter);
          }, 1e3);
          return;
        }
        if (self.state === "stopped") {
          return;
        }
        if (counter >= self.recordingDuration) {
          stopRecording(self.onRecordingStopped);
          return;
        }
        counter += 1e3;
        setTimeout(function() {
          handleRecordingDuration(counter);
        }, 1e3);
      }
      function setState(state) {
        if (!self) {
          return;
        }
        self.state = state;
        if (typeof self.onStateChanged.call === "function") {
          self.onStateChanged.call(self, state);
        } else {
          self.onStateChanged(state);
        }
      }
      var WARNING = 'It seems that recorder is destroyed or "startRecording" is not invoked for ' + config.type + " recorder.";
      function warningLog() {
        if (config.disableLogs === true) {
          return;
        }
        console.warn(WARNING);
      }
      var mediaRecorder;
      var returnObject = {
        /**
         * This method starts the recording.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * var recorder = RecordRTC(mediaStream, {
         *     type: 'video'
         * });
         * recorder.startRecording();
         */
        startRecording,
        /**
         * This method stops the recording. It is strongly recommended to get "blob" or "URI" inside the callback to make sure all recorders finished their job.
         * @param {function} callback - Callback to get the recorded blob.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.stopRecording(function() {
         *     // use either "this" or "recorder" object; both are identical
         *     video.src = this.toURL();
         *     var blob = this.getBlob();
         * });
         */
        stopRecording,
        /**
         * This method pauses the recording. You can resume recording using "resumeRecording" method.
         * @method
         * @memberof RecordRTC
         * @instance
         * @todo Firefox is unable to pause the recording. Fix it.
         * @example
         * recorder.pauseRecording();  // pause the recording
         * recorder.resumeRecording(); // resume again
         */
        pauseRecording,
        /**
         * This method resumes the recording.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.pauseRecording();  // first of all, pause the recording
         * recorder.resumeRecording(); // now resume it
         */
        resumeRecording,
        /**
         * This method initializes the recording.
         * @method
         * @memberof RecordRTC
         * @instance
         * @todo This method should be deprecated.
         * @example
         * recorder.initRecorder();
         */
        initRecorder,
        /**
         * Ask RecordRTC to auto-stop the recording after 5 minutes.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * var fiveMinutes = 5 * 1000 * 60;
         * recorder.setRecordingDuration(fiveMinutes, function() {
         *    var blob = this.getBlob();
         *    video.src = this.toURL();
         * });
         * 
         * // or otherwise
         * recorder.setRecordingDuration(fiveMinutes).onRecordingStopped(function() {
         *    var blob = this.getBlob();
         *    video.src = this.toURL();
         * });
         */
        setRecordingDuration: function(recordingDuration, callback) {
          if (typeof recordingDuration === "undefined") {
            throw "recordingDuration is required.";
          }
          if (typeof recordingDuration !== "number") {
            throw "recordingDuration must be a number.";
          }
          self.recordingDuration = recordingDuration;
          self.onRecordingStopped = callback || function() {
          };
          return {
            onRecordingStopped: function(callback2) {
              self.onRecordingStopped = callback2;
            }
          };
        },
        /**
         * This method can be used to clear/reset all the recorded data.
         * @method
         * @memberof RecordRTC
         * @instance
         * @todo Figure out the difference between "reset" and "clearRecordedData" methods.
         * @example
         * recorder.clearRecordedData();
         */
        clearRecordedData: function() {
          if (!mediaRecorder) {
            warningLog();
            return;
          }
          mediaRecorder.clearRecordedData();
          if (!config.disableLogs) {
            console.log("Cleared old recorded data.");
          }
        },
        /**
         * Get the recorded blob. Use this method inside the "stopRecording" callback.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.stopRecording(function() {
         *     var blob = this.getBlob();
         *
         *     var file = new File([blob], 'filename.webm', {
         *         type: 'video/webm'
         *     });
         *
         *     var formData = new FormData();
         *     formData.append('file', file); // upload "File" object rather than a "Blob"
         *     uploadToServer(formData);
         * });
         * @returns {Blob} Returns recorded data as "Blob" object.
         */
        getBlob: function() {
          if (!mediaRecorder) {
            warningLog();
            return;
          }
          return mediaRecorder.blob;
        },
        /**
         * Get data-URI instead of Blob.
         * @param {function} callback - Callback to get the Data-URI.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.stopRecording(function() {
         *     recorder.getDataURL(function(dataURI) {
         *         video.src = dataURI;
         *     });
         * });
         */
        getDataURL,
        /**
         * Get virtual/temporary URL. Usage of this URL is limited to current tab.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.stopRecording(function() {
         *     video.src = this.toURL();
         * });
         * @returns {String} Returns a virtual/temporary URL for the recorded "Blob".
         */
        toURL: function() {
          if (!mediaRecorder) {
            warningLog();
            return;
          }
          return URL2.createObjectURL(mediaRecorder.blob);
        },
        /**
         * Get internal recording object (i.e. internal module) e.g. MutliStreamRecorder, MediaStreamRecorder, StereoAudioRecorder or WhammyRecorder etc.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * var internalRecorder = recorder.getInternalRecorder();
         * if(internalRecorder instanceof MultiStreamRecorder) {
         *     internalRecorder.addStreams([newAudioStream]);
         *     internalRecorder.resetVideoStreams([screenStream]);
         * }
         * @returns {Object} Returns internal recording object.
         */
        getInternalRecorder: function() {
          return mediaRecorder;
        },
        /**
         * Invoke save-as dialog to save the recorded blob into your disk.
         * @param {string} fileName - Set your own file name.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.stopRecording(function() {
         *     this.save('file-name');
         *
         *     // or manually:
         *     invokeSaveAsDialog(this.getBlob(), 'filename.webm');
         * });
         */
        save: function(fileName) {
          if (!mediaRecorder) {
            warningLog();
            return;
          }
          invokeSaveAsDialog(mediaRecorder.blob, fileName);
        },
        /**
         * This method gets a blob from indexed-DB storage.
         * @param {function} callback - Callback to get the recorded blob.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.getFromDisk(function(dataURL) {
         *     video.src = dataURL;
         * });
         */
        getFromDisk: function(callback) {
          if (!mediaRecorder) {
            warningLog();
            return;
          }
          RecordRTC2.getFromDisk(config.type, callback);
        },
        /**
         * This method appends an array of webp images to the recorded video-blob. It takes an "array" object.
         * @type {Array.<Array>}
         * @param {Array} arrayOfWebPImages - Array of webp images.
         * @method
         * @memberof RecordRTC
         * @instance
         * @todo This method should be deprecated.
         * @example
         * var arrayOfWebPImages = [];
         * arrayOfWebPImages.push({
         *     duration: index,
         *     image: 'data:image/webp;base64,...'
         * });
         * recorder.setAdvertisementArray(arrayOfWebPImages);
         */
        setAdvertisementArray: function(arrayOfWebPImages) {
          config.advertisement = [];
          var length = arrayOfWebPImages.length;
          for (var i = 0; i < length; i++) {
            config.advertisement.push({
              duration: i,
              image: arrayOfWebPImages[i]
            });
          }
        },
        /**
         * It is equivalent to <code class="str">"recorder.getBlob()"</code> method. Usage of "getBlob" is recommended, though.
         * @property {Blob} blob - Recorded Blob can be accessed using this property.
         * @memberof RecordRTC
         * @instance
         * @readonly
         * @example
         * recorder.stopRecording(function() {
         *     var blob = this.blob;
         *
         *     // below one is recommended
         *     var blob = this.getBlob();
         * });
         */
        blob: null,
        /**
         * This works only with {recorderType:StereoAudioRecorder}. Use this property on "stopRecording" to verify the encoder's sample-rates.
         * @property {number} bufferSize - Buffer-size used to encode the WAV container
         * @memberof RecordRTC
         * @instance
         * @readonly
         * @example
         * recorder.stopRecording(function() {
         *     alert('Recorder used this buffer-size: ' + this.bufferSize);
         * });
         */
        bufferSize: 0,
        /**
         * This works only with {recorderType:StereoAudioRecorder}. Use this property on "stopRecording" to verify the encoder's sample-rates.
         * @property {number} sampleRate - Sample-rates used to encode the WAV container
         * @memberof RecordRTC
         * @instance
         * @readonly
         * @example
         * recorder.stopRecording(function() {
         *     alert('Recorder used these sample-rates: ' + this.sampleRate);
         * });
         */
        sampleRate: 0,
        /**
         * {recorderType:StereoAudioRecorder} returns ArrayBuffer object.
         * @property {ArrayBuffer} buffer - Audio ArrayBuffer, supported only in Chrome.
         * @memberof RecordRTC
         * @instance
         * @readonly
         * @example
         * recorder.stopRecording(function() {
         *     var arrayBuffer = this.buffer;
         *     alert(arrayBuffer.byteLength);
         * });
         */
        buffer: null,
        /**
         * This method resets the recorder. So that you can reuse single recorder instance many times.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.reset();
         * recorder.startRecording();
         */
        reset: function() {
          if (self.state === "recording" && !config.disableLogs) {
            console.warn("Stop an active recorder.");
          }
          if (mediaRecorder && typeof mediaRecorder.clearRecordedData === "function") {
            mediaRecorder.clearRecordedData();
          }
          mediaRecorder = null;
          setState("inactive");
          self.blob = null;
        },
        /**
         * This method is called whenever recorder's state changes. Use this as an "event".
         * @property {String} state - A recorder's state can be: recording, paused, stopped or inactive.
         * @method
         * @memberof RecordRTC
         * @instance
         * @example
         * recorder.onStateChanged = function(state) {
         *     console.log('Recorder state: ', state);
         * };
         */
        onStateChanged: function(state) {
          if (!config.disableLogs) {
            console.log("Recorder state changed:", state);
          }
        },
        /**
         * A recorder can have inactive, recording, paused or stopped states.
         * @property {String} state - A recorder's state can be: recording, paused, stopped or inactive.
         * @memberof RecordRTC
         * @static
         * @readonly
         * @example
         * // this looper function will keep you updated about the recorder's states.
         * (function looper() {
         *     document.querySelector('h1').innerHTML = 'Recorder\'s state is: ' + recorder.state;
         *     if(recorder.state === 'stopped') return; // ignore+stop
         *     setTimeout(looper, 1000); // update after every 3-seconds
         * })();
         * recorder.startRecording();
         */
        state: "inactive",
        /**
         * Get recorder's readonly state.
         * @method
         * @memberof RecordRTC
         * @example
         * var state = recorder.getState();
         * @returns {String} Returns recording state.
         */
        getState: function() {
          return self.state;
        },
        /**
         * Destroy RecordRTC instance. Clear all recorders and objects.
         * @method
         * @memberof RecordRTC
         * @example
         * recorder.destroy();
         */
        destroy: function() {
          var disableLogsCache = config.disableLogs;
          config = {
            disableLogs: true
          };
          self.reset();
          setState("destroyed");
          returnObject = self = null;
          if (Storage.AudioContextConstructor) {
            Storage.AudioContextConstructor.close();
            Storage.AudioContextConstructor = null;
          }
          config.disableLogs = disableLogsCache;
          if (!config.disableLogs) {
            console.log("RecordRTC is destroyed.");
          }
        },
        /**
         * RecordRTC version number
         * @property {String} version - Release version number.
         * @memberof RecordRTC
         * @static
         * @readonly
         * @example
         * alert(recorder.version);
         */
        version: "5.6.2"
      };
      if (!this) {
        self = returnObject;
        return returnObject;
      }
      for (var prop in returnObject) {
        this[prop] = returnObject[prop];
      }
      self = this;
      return returnObject;
    }
    RecordRTC2.version = "5.6.2";
    if (typeof module2 !== "undefined") {
      module2.exports = RecordRTC2;
    }
    if (typeof define === "function" && define.amd) {
      define("RecordRTC", [], function() {
        return RecordRTC2;
      });
    }
    RecordRTC2.getFromDisk = function(type, callback) {
      if (!callback) {
        throw "callback is mandatory.";
      }
      console.log("Getting recorded " + (type === "all" ? "blobs" : type + " blob ") + " from disk!");
      DiskStorage.Fetch(function(dataURL, _type) {
        if (type !== "all" && _type === type + "Blob" && callback) {
          callback(dataURL);
        }
        if (type === "all" && callback) {
          callback(dataURL, _type.replace("Blob", ""));
        }
      });
    };
    RecordRTC2.writeToDisk = function(options) {
      console.log("Writing recorded blob(s) to disk!");
      options = options || {};
      if (options.audio && options.video && options.gif) {
        options.audio.getDataURL(function(audioDataURL) {
          options.video.getDataURL(function(videoDataURL) {
            options.gif.getDataURL(function(gifDataURL) {
              DiskStorage.Store({
                audioBlob: audioDataURL,
                videoBlob: videoDataURL,
                gifBlob: gifDataURL
              });
            });
          });
        });
      } else if (options.audio && options.video) {
        options.audio.getDataURL(function(audioDataURL) {
          options.video.getDataURL(function(videoDataURL) {
            DiskStorage.Store({
              audioBlob: audioDataURL,
              videoBlob: videoDataURL
            });
          });
        });
      } else if (options.audio && options.gif) {
        options.audio.getDataURL(function(audioDataURL) {
          options.gif.getDataURL(function(gifDataURL) {
            DiskStorage.Store({
              audioBlob: audioDataURL,
              gifBlob: gifDataURL
            });
          });
        });
      } else if (options.video && options.gif) {
        options.video.getDataURL(function(videoDataURL) {
          options.gif.getDataURL(function(gifDataURL) {
            DiskStorage.Store({
              videoBlob: videoDataURL,
              gifBlob: gifDataURL
            });
          });
        });
      } else if (options.audio) {
        options.audio.getDataURL(function(audioDataURL) {
          DiskStorage.Store({
            audioBlob: audioDataURL
          });
        });
      } else if (options.video) {
        options.video.getDataURL(function(videoDataURL) {
          DiskStorage.Store({
            videoBlob: videoDataURL
          });
        });
      } else if (options.gif) {
        options.gif.getDataURL(function(gifDataURL) {
          DiskStorage.Store({
            gifBlob: gifDataURL
          });
        });
      }
    };
    function RecordRTCConfiguration(mediaStream, config) {
      if (!config.recorderType && !config.type) {
        if (!!config.audio && !!config.video) {
          config.type = "video";
        } else if (!!config.audio && !config.video) {
          config.type = "audio";
        }
      }
      if (config.recorderType && !config.type) {
        if (config.recorderType === WhammyRecorder || config.recorderType === CanvasRecorder || typeof WebAssemblyRecorder !== "undefined" && config.recorderType === WebAssemblyRecorder) {
          config.type = "video";
        } else if (config.recorderType === GifRecorder) {
          config.type = "gif";
        } else if (config.recorderType === StereoAudioRecorder) {
          config.type = "audio";
        } else if (config.recorderType === MediaStreamRecorder) {
          if (getTracks(mediaStream, "audio").length && getTracks(mediaStream, "video").length) {
            config.type = "video";
          } else if (!getTracks(mediaStream, "audio").length && getTracks(mediaStream, "video").length) {
            config.type = "video";
          } else if (getTracks(mediaStream, "audio").length && !getTracks(mediaStream, "video").length) {
            config.type = "audio";
          } else {
          }
        }
      }
      if (typeof MediaStreamRecorder !== "undefined" && typeof MediaRecorder !== "undefined" && "requestData" in MediaRecorder.prototype) {
        if (!config.mimeType) {
          config.mimeType = "video/webm";
        }
        if (!config.type) {
          config.type = config.mimeType.split("/")[0];
        }
        if (!config.bitsPerSecond) {
        }
      }
      if (!config.type) {
        if (config.mimeType) {
          config.type = config.mimeType.split("/")[0];
        }
        if (!config.type) {
          config.type = "audio";
        }
      }
      return config;
    }
    function GetRecorderType(mediaStream, config) {
      var recorder;
      if (isChrome || isEdge || isOpera) {
        recorder = StereoAudioRecorder;
      }
      if (typeof MediaRecorder !== "undefined" && "requestData" in MediaRecorder.prototype && !isChrome) {
        recorder = MediaStreamRecorder;
      }
      if (config.type === "video" && (isChrome || isOpera)) {
        recorder = WhammyRecorder;
        if (typeof WebAssemblyRecorder !== "undefined" && typeof ReadableStream !== "undefined") {
          recorder = WebAssemblyRecorder;
        }
      }
      if (config.type === "gif") {
        recorder = GifRecorder;
      }
      if (config.type === "canvas") {
        recorder = CanvasRecorder;
      }
      if (isMediaRecorderCompatible() && recorder !== CanvasRecorder && recorder !== GifRecorder && typeof MediaRecorder !== "undefined" && "requestData" in MediaRecorder.prototype) {
        if (getTracks(mediaStream, "video").length || getTracks(mediaStream, "audio").length) {
          if (config.type === "audio") {
            if (typeof MediaRecorder.isTypeSupported === "function" && MediaRecorder.isTypeSupported("audio/webm")) {
              recorder = MediaStreamRecorder;
            }
          } else {
            if (typeof MediaRecorder.isTypeSupported === "function" && MediaRecorder.isTypeSupported("video/webm")) {
              recorder = MediaStreamRecorder;
            }
          }
        }
      }
      if (mediaStream instanceof Array && mediaStream.length) {
        recorder = MultiStreamRecorder;
      }
      if (config.recorderType) {
        recorder = config.recorderType;
      }
      if (!config.disableLogs && !!recorder && !!recorder.name) {
        console.log("Using recorderType:", recorder.name || recorder.constructor.name);
      }
      if (!recorder && isSafari) {
        recorder = MediaStreamRecorder;
      }
      return recorder;
    }
    function MRecordRTC(mediaStream) {
      this.addStream = function(_mediaStream) {
        if (_mediaStream) {
          mediaStream = _mediaStream;
        }
      };
      this.mediaType = {
        audio: true,
        video: true
      };
      this.startRecording = function() {
        var mediaType = this.mediaType;
        var recorderType;
        var mimeType = this.mimeType || {
          audio: null,
          video: null,
          gif: null
        };
        if (typeof mediaType.audio !== "function" && isMediaRecorderCompatible() && !getTracks(mediaStream, "audio").length) {
          mediaType.audio = false;
        }
        if (typeof mediaType.video !== "function" && isMediaRecorderCompatible() && !getTracks(mediaStream, "video").length) {
          mediaType.video = false;
        }
        if (typeof mediaType.gif !== "function" && isMediaRecorderCompatible() && !getTracks(mediaStream, "video").length) {
          mediaType.gif = false;
        }
        if (!mediaType.audio && !mediaType.video && !mediaType.gif) {
          throw "MediaStream must have either audio or video tracks.";
        }
        if (!!mediaType.audio) {
          recorderType = null;
          if (typeof mediaType.audio === "function") {
            recorderType = mediaType.audio;
          }
          this.audioRecorder = new RecordRTC2(mediaStream, {
            type: "audio",
            bufferSize: this.bufferSize,
            sampleRate: this.sampleRate,
            numberOfAudioChannels: this.numberOfAudioChannels || 2,
            disableLogs: this.disableLogs,
            recorderType,
            mimeType: mimeType.audio,
            timeSlice: this.timeSlice,
            onTimeStamp: this.onTimeStamp
          });
          if (!mediaType.video) {
            this.audioRecorder.startRecording();
          }
        }
        if (!!mediaType.video) {
          recorderType = null;
          if (typeof mediaType.video === "function") {
            recorderType = mediaType.video;
          }
          var newStream = mediaStream;
          if (isMediaRecorderCompatible() && !!mediaType.audio && typeof mediaType.audio === "function") {
            var videoTrack = getTracks(mediaStream, "video")[0];
            if (isFirefox) {
              newStream = new MediaStream();
              newStream.addTrack(videoTrack);
              if (recorderType && recorderType === WhammyRecorder) {
                recorderType = MediaStreamRecorder;
              }
            } else {
              newStream = new MediaStream();
              newStream.addTrack(videoTrack);
            }
          }
          this.videoRecorder = new RecordRTC2(newStream, {
            type: "video",
            video: this.video,
            canvas: this.canvas,
            frameInterval: this.frameInterval || 10,
            disableLogs: this.disableLogs,
            recorderType,
            mimeType: mimeType.video,
            timeSlice: this.timeSlice,
            onTimeStamp: this.onTimeStamp,
            workerPath: this.workerPath,
            webAssemblyPath: this.webAssemblyPath,
            frameRate: this.frameRate,
            // used by WebAssemblyRecorder; values: usually 30; accepts any.
            bitrate: this.bitrate
            // used by WebAssemblyRecorder; values: 0 to 1000+
          });
          if (!mediaType.audio) {
            this.videoRecorder.startRecording();
          }
        }
        if (!!mediaType.audio && !!mediaType.video) {
          var self = this;
          var isSingleRecorder = isMediaRecorderCompatible() === true;
          if (mediaType.audio instanceof StereoAudioRecorder && !!mediaType.video) {
            isSingleRecorder = false;
          } else if (mediaType.audio !== true && mediaType.video !== true && mediaType.audio !== mediaType.video) {
            isSingleRecorder = false;
          }
          if (isSingleRecorder === true) {
            self.audioRecorder = null;
            self.videoRecorder.startRecording();
          } else {
            self.videoRecorder.initRecorder(function() {
              self.audioRecorder.initRecorder(function() {
                self.videoRecorder.startRecording();
                self.audioRecorder.startRecording();
              });
            });
          }
        }
        if (!!mediaType.gif) {
          recorderType = null;
          if (typeof mediaType.gif === "function") {
            recorderType = mediaType.gif;
          }
          this.gifRecorder = new RecordRTC2(mediaStream, {
            type: "gif",
            frameRate: this.frameRate || 200,
            quality: this.quality || 10,
            disableLogs: this.disableLogs,
            recorderType,
            mimeType: mimeType.gif
          });
          this.gifRecorder.startRecording();
        }
      };
      this.stopRecording = function(callback) {
        callback = callback || function() {
        };
        if (this.audioRecorder) {
          this.audioRecorder.stopRecording(function(blobURL) {
            callback(blobURL, "audio");
          });
        }
        if (this.videoRecorder) {
          this.videoRecorder.stopRecording(function(blobURL) {
            callback(blobURL, "video");
          });
        }
        if (this.gifRecorder) {
          this.gifRecorder.stopRecording(function(blobURL) {
            callback(blobURL, "gif");
          });
        }
      };
      this.pauseRecording = function() {
        if (this.audioRecorder) {
          this.audioRecorder.pauseRecording();
        }
        if (this.videoRecorder) {
          this.videoRecorder.pauseRecording();
        }
        if (this.gifRecorder) {
          this.gifRecorder.pauseRecording();
        }
      };
      this.resumeRecording = function() {
        if (this.audioRecorder) {
          this.audioRecorder.resumeRecording();
        }
        if (this.videoRecorder) {
          this.videoRecorder.resumeRecording();
        }
        if (this.gifRecorder) {
          this.gifRecorder.resumeRecording();
        }
      };
      this.getBlob = function(callback) {
        var output = {};
        if (this.audioRecorder) {
          output.audio = this.audioRecorder.getBlob();
        }
        if (this.videoRecorder) {
          output.video = this.videoRecorder.getBlob();
        }
        if (this.gifRecorder) {
          output.gif = this.gifRecorder.getBlob();
        }
        if (callback) {
          callback(output);
        }
        return output;
      };
      this.destroy = function() {
        if (this.audioRecorder) {
          this.audioRecorder.destroy();
          this.audioRecorder = null;
        }
        if (this.videoRecorder) {
          this.videoRecorder.destroy();
          this.videoRecorder = null;
        }
        if (this.gifRecorder) {
          this.gifRecorder.destroy();
          this.gifRecorder = null;
        }
      };
      this.getDataURL = function(callback) {
        this.getBlob(function(blob) {
          if (blob.audio && blob.video) {
            getDataURL(blob.audio, function(_audioDataURL) {
              getDataURL(blob.video, function(_videoDataURL) {
                callback({
                  audio: _audioDataURL,
                  video: _videoDataURL
                });
              });
            });
          } else if (blob.audio) {
            getDataURL(blob.audio, function(_audioDataURL) {
              callback({
                audio: _audioDataURL
              });
            });
          } else if (blob.video) {
            getDataURL(blob.video, function(_videoDataURL) {
              callback({
                video: _videoDataURL
              });
            });
          }
        });
        function getDataURL(blob, callback00) {
          if (typeof Worker !== "undefined") {
            var webWorker = processInWebWorker(function readFile(_blob) {
              postMessage(new FileReaderSync().readAsDataURL(_blob));
            });
            webWorker.onmessage = function(event2) {
              callback00(event2.data);
            };
            webWorker.postMessage(blob);
          } else {
            var reader = new FileReader();
            reader.readAsDataURL(blob);
            reader.onload = function(event2) {
              callback00(event2.target.result);
            };
          }
        }
        function processInWebWorker(_function) {
          var blob = URL2.createObjectURL(new Blob([
            _function.toString(),
            "this.onmessage =  function (eee) {" + _function.name + "(eee.data);}"
          ], {
            type: "application/javascript"
          }));
          var worker = new Worker(blob);
          var url;
          if (typeof URL2 !== "undefined") {
            url = URL2;
          } else if (typeof webkitURL !== "undefined") {
            url = webkitURL;
          } else {
            throw "Neither URL nor webkitURL detected.";
          }
          url.revokeObjectURL(blob);
          return worker;
        }
      };
      this.writeToDisk = function() {
        RecordRTC2.writeToDisk({
          audio: this.audioRecorder,
          video: this.videoRecorder,
          gif: this.gifRecorder
        });
      };
      this.save = function(args) {
        args = args || {
          audio: true,
          video: true,
          gif: true
        };
        if (!!args.audio && this.audioRecorder) {
          this.audioRecorder.save(typeof args.audio === "string" ? args.audio : "");
        }
        if (!!args.video && this.videoRecorder) {
          this.videoRecorder.save(typeof args.video === "string" ? args.video : "");
        }
        if (!!args.gif && this.gifRecorder) {
          this.gifRecorder.save(typeof args.gif === "string" ? args.gif : "");
        }
      };
    }
    MRecordRTC.getFromDisk = RecordRTC2.getFromDisk;
    MRecordRTC.writeToDisk = RecordRTC2.writeToDisk;
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.MRecordRTC = MRecordRTC;
    }
    var browserFakeUserAgent = "Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45";
    (function(that) {
      if (!that) {
        return;
      }
      if (typeof window !== "undefined") {
        return;
      }
      if (typeof global === "undefined") {
        return;
      }
      global.navigator = {
        userAgent: browserFakeUserAgent,
        getUserMedia: function() {
        }
      };
      if (!global.console) {
        global.console = {};
      }
      if (typeof global.console.log === "undefined" || typeof global.console.error === "undefined") {
        global.console.error = global.console.log = global.console.log || function() {
          console.log(arguments);
        };
      }
      if (typeof document === "undefined") {
        that.document = {
          documentElement: {
            appendChild: function() {
              return "";
            }
          }
        };
        document.createElement = document.captureStream = document.mozCaptureStream = function() {
          var obj = {
            getContext: function() {
              return obj;
            },
            play: function() {
            },
            pause: function() {
            },
            drawImage: function() {
            },
            toDataURL: function() {
              return "";
            },
            style: {}
          };
          return obj;
        };
        that.HTMLVideoElement = function() {
        };
      }
      if (typeof location === "undefined") {
        that.location = {
          protocol: "file:",
          href: "",
          hash: ""
        };
      }
      if (typeof screen === "undefined") {
        that.screen = {
          width: 0,
          height: 0
        };
      }
      if (typeof URL2 === "undefined") {
        that.URL = {
          createObjectURL: function() {
            return "";
          },
          revokeObjectURL: function() {
            return "";
          }
        };
      }
      that.window = global;
    })(typeof global !== "undefined" ? global : null);
    var requestAnimationFrame2 = window.requestAnimationFrame;
    if (typeof requestAnimationFrame2 === "undefined") {
      if (typeof webkitRequestAnimationFrame !== "undefined") {
        requestAnimationFrame2 = webkitRequestAnimationFrame;
      } else if (typeof mozRequestAnimationFrame !== "undefined") {
        requestAnimationFrame2 = mozRequestAnimationFrame;
      } else if (typeof msRequestAnimationFrame !== "undefined") {
        requestAnimationFrame2 = msRequestAnimationFrame;
      } else if (typeof requestAnimationFrame2 === "undefined") {
        lastTime = 0;
        requestAnimationFrame2 = function(callback, element) {
          var currTime = new Date().getTime();
          var timeToCall = Math.max(0, 16 - (currTime - lastTime));
          var id = setTimeout(function() {
            callback(currTime + timeToCall);
          }, timeToCall);
          lastTime = currTime + timeToCall;
          return id;
        };
      }
    }
    var lastTime;
    var cancelAnimationFrame = window.cancelAnimationFrame;
    if (typeof cancelAnimationFrame === "undefined") {
      if (typeof webkitCancelAnimationFrame !== "undefined") {
        cancelAnimationFrame = webkitCancelAnimationFrame;
      } else if (typeof mozCancelAnimationFrame !== "undefined") {
        cancelAnimationFrame = mozCancelAnimationFrame;
      } else if (typeof msCancelAnimationFrame !== "undefined") {
        cancelAnimationFrame = msCancelAnimationFrame;
      } else if (typeof cancelAnimationFrame === "undefined") {
        cancelAnimationFrame = function(id) {
          clearTimeout(id);
        };
      }
    }
    var AudioContext = window.AudioContext;
    if (typeof AudioContext === "undefined") {
      if (typeof webkitAudioContext !== "undefined") {
        AudioContext = webkitAudioContext;
      }
      if (typeof mozAudioContext !== "undefined") {
        AudioContext = mozAudioContext;
      }
    }
    var URL2 = window.URL;
    if (typeof URL2 === "undefined" && typeof webkitURL !== "undefined") {
      URL2 = webkitURL;
    }
    if (typeof navigator !== "undefined" && typeof navigator.getUserMedia === "undefined") {
      if (typeof navigator.webkitGetUserMedia !== "undefined") {
        navigator.getUserMedia = navigator.webkitGetUserMedia;
      }
      if (typeof navigator.mozGetUserMedia !== "undefined") {
        navigator.getUserMedia = navigator.mozGetUserMedia;
      }
    }
    var isEdge = navigator.userAgent.indexOf("Edge") !== -1 && (!!navigator.msSaveBlob || !!navigator.msSaveOrOpenBlob);
    var isOpera = !!window.opera || navigator.userAgent.indexOf("OPR/") !== -1;
    var isFirefox = navigator.userAgent.toLowerCase().indexOf("firefox") > -1 && "netscape" in window && / rv:/.test(navigator.userAgent);
    var isChrome = !isOpera && !isEdge && !!navigator.webkitGetUserMedia || isElectron() || navigator.userAgent.toLowerCase().indexOf("chrome/") !== -1;
    var isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
    if (isSafari && !isChrome && navigator.userAgent.indexOf("CriOS") !== -1) {
      isSafari = false;
      isChrome = true;
    }
    var MediaStream = window.MediaStream;
    if (typeof MediaStream === "undefined" && typeof webkitMediaStream !== "undefined") {
      MediaStream = webkitMediaStream;
    }
    if (typeof MediaStream !== "undefined") {
      if (typeof MediaStream.prototype.stop === "undefined") {
        MediaStream.prototype.stop = function() {
          this.getTracks().forEach(function(track) {
            track.stop();
          });
        };
      }
    }
    function bytesToSize(bytes) {
      var k = 1e3;
      var sizes = ["Bytes", "KB", "MB", "GB", "TB"];
      if (bytes === 0) {
        return "0 Bytes";
      }
      var i = parseInt(Math.floor(Math.log(bytes) / Math.log(k)), 10);
      return (bytes / Math.pow(k, i)).toPrecision(3) + " " + sizes[i];
    }
    function invokeSaveAsDialog(file, fileName) {
      if (!file) {
        throw "Blob object is required.";
      }
      if (!file.type) {
        try {
          file.type = "video/webm";
        } catch (e) {
        }
      }
      var fileExtension = (file.type || "video/webm").split("/")[1];
      if (fileExtension.indexOf(";") !== -1) {
        fileExtension = fileExtension.split(";")[0];
      }
      if (fileName && fileName.indexOf(".") !== -1) {
        var splitted = fileName.split(".");
        fileName = splitted[0];
        fileExtension = splitted[1];
      }
      var fileFullName = (fileName || Math.round(Math.random() * 9999999999) + 888888888) + "." + fileExtension;
      if (typeof navigator.msSaveOrOpenBlob !== "undefined") {
        return navigator.msSaveOrOpenBlob(file, fileFullName);
      } else if (typeof navigator.msSaveBlob !== "undefined") {
        return navigator.msSaveBlob(file, fileFullName);
      }
      var hyperlink = document.createElement("a");
      hyperlink.href = URL2.createObjectURL(file);
      hyperlink.download = fileFullName;
      hyperlink.style = "display:none;opacity:0;color:transparent;";
      (document.body || document.documentElement).appendChild(hyperlink);
      if (typeof hyperlink.click === "function") {
        hyperlink.click();
      } else {
        hyperlink.target = "_blank";
        hyperlink.dispatchEvent(new MouseEvent("click", {
          view: window,
          bubbles: true,
          cancelable: true
        }));
      }
      URL2.revokeObjectURL(hyperlink.href);
    }
    function isElectron() {
      if (typeof window !== "undefined" && typeof window.process === "object" && window.process.type === "renderer") {
        return true;
      }
      if (typeof process !== "undefined" && typeof process.versions === "object" && !!process.versions.electron) {
        return true;
      }
      if (typeof navigator === "object" && typeof navigator.userAgent === "string" && navigator.userAgent.indexOf("Electron") >= 0) {
        return true;
      }
      return false;
    }
    function getTracks(stream, kind) {
      if (!stream || !stream.getTracks) {
        return [];
      }
      return stream.getTracks().filter(function(t) {
        return t.kind === (kind || "audio");
      });
    }
    function setSrcObject(stream, element) {
      if ("srcObject" in element) {
        element.srcObject = stream;
      } else if ("mozSrcObject" in element) {
        element.mozSrcObject = stream;
      } else {
        element.srcObject = stream;
      }
    }
    function getSeekableBlob(inputBlob, callback) {
      if (typeof EBML === "undefined") {
        throw new Error("Please link: https://www.webrtc-experiment.com/EBML.js");
      }
      var reader = new EBML.Reader();
      var decoder = new EBML.Decoder();
      var tools = EBML.tools;
      var fileReader = new FileReader();
      fileReader.onload = function(e) {
        var ebmlElms = decoder.decode(this.result);
        ebmlElms.forEach(function(element) {
          reader.read(element);
        });
        reader.stop();
        var refinedMetadataBuf = tools.makeMetadataSeekable(reader.metadatas, reader.duration, reader.cues);
        var body = this.result.slice(reader.metadataSize);
        var newBlob = new Blob([refinedMetadataBuf, body], {
          type: "video/webm"
        });
        callback(newBlob);
      };
      fileReader.readAsArrayBuffer(inputBlob);
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.invokeSaveAsDialog = invokeSaveAsDialog;
      RecordRTC2.getTracks = getTracks;
      RecordRTC2.getSeekableBlob = getSeekableBlob;
      RecordRTC2.bytesToSize = bytesToSize;
      RecordRTC2.isElectron = isElectron;
    }
    var Storage = {};
    if (typeof AudioContext !== "undefined") {
      Storage.AudioContext = AudioContext;
    } else if (typeof webkitAudioContext !== "undefined") {
      Storage.AudioContext = webkitAudioContext;
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.Storage = Storage;
    }
    function isMediaRecorderCompatible() {
      if (isFirefox || isSafari || isEdge) {
        return true;
      }
      var nVer = navigator.appVersion;
      var nAgt = navigator.userAgent;
      var fullVersion = "" + parseFloat(navigator.appVersion);
      var majorVersion = parseInt(navigator.appVersion, 10);
      var nameOffset, verOffset, ix;
      if (isChrome || isOpera) {
        verOffset = nAgt.indexOf("Chrome");
        fullVersion = nAgt.substring(verOffset + 7);
      }
      if ((ix = fullVersion.indexOf(";")) !== -1) {
        fullVersion = fullVersion.substring(0, ix);
      }
      if ((ix = fullVersion.indexOf(" ")) !== -1) {
        fullVersion = fullVersion.substring(0, ix);
      }
      majorVersion = parseInt("" + fullVersion, 10);
      if (isNaN(majorVersion)) {
        fullVersion = "" + parseFloat(navigator.appVersion);
        majorVersion = parseInt(navigator.appVersion, 10);
      }
      return majorVersion >= 49;
    }
    function MediaStreamRecorder(mediaStream, config) {
      var self = this;
      if (typeof mediaStream === "undefined") {
        throw 'First argument "MediaStream" is required.';
      }
      if (typeof MediaRecorder === "undefined") {
        throw "Your browser does not support the Media Recorder API. Please try other modules e.g. WhammyRecorder or StereoAudioRecorder.";
      }
      config = config || {
        // bitsPerSecond: 256 * 8 * 1024,
        mimeType: "video/webm"
      };
      if (config.type === "audio") {
        if (getTracks(mediaStream, "video").length && getTracks(mediaStream, "audio").length) {
          var stream;
          if (!!navigator.mozGetUserMedia) {
            stream = new MediaStream();
            stream.addTrack(getTracks(mediaStream, "audio")[0]);
          } else {
            stream = new MediaStream(getTracks(mediaStream, "audio"));
          }
          mediaStream = stream;
        }
        if (!config.mimeType || config.mimeType.toString().toLowerCase().indexOf("audio") === -1) {
          config.mimeType = isChrome ? "audio/webm" : "audio/ogg";
        }
        if (config.mimeType && config.mimeType.toString().toLowerCase() !== "audio/ogg" && !!navigator.mozGetUserMedia) {
          config.mimeType = "audio/ogg";
        }
      }
      var arrayOfBlobs = [];
      this.getArrayOfBlobs = function() {
        return arrayOfBlobs;
      };
      this.record = function() {
        self.blob = null;
        self.clearRecordedData();
        self.timestamps = [];
        allStates = [];
        arrayOfBlobs = [];
        var recorderHints = config;
        if (!config.disableLogs) {
          console.log("Passing following config over MediaRecorder API.", recorderHints);
        }
        if (mediaRecorder) {
          mediaRecorder = null;
        }
        if (isChrome && !isMediaRecorderCompatible()) {
          recorderHints = "video/vp8";
        }
        if (typeof MediaRecorder.isTypeSupported === "function" && recorderHints.mimeType) {
          if (!MediaRecorder.isTypeSupported(recorderHints.mimeType)) {
            if (!config.disableLogs) {
              console.warn("MediaRecorder API seems unable to record mimeType:", recorderHints.mimeType);
            }
            recorderHints.mimeType = config.type === "audio" ? "audio/webm" : "video/webm";
          }
        }
        try {
          mediaRecorder = new MediaRecorder(mediaStream, recorderHints);
          config.mimeType = recorderHints.mimeType;
        } catch (e) {
          mediaRecorder = new MediaRecorder(mediaStream);
        }
        if (recorderHints.mimeType && !MediaRecorder.isTypeSupported && "canRecordMimeType" in mediaRecorder && mediaRecorder.canRecordMimeType(recorderHints.mimeType) === false) {
          if (!config.disableLogs) {
            console.warn("MediaRecorder API seems unable to record mimeType:", recorderHints.mimeType);
          }
        }
        mediaRecorder.ondataavailable = function(e) {
          if (e.data) {
            allStates.push("ondataavailable: " + bytesToSize(e.data.size));
          }
          if (typeof config.timeSlice === "number") {
            if (e.data && e.data.size) {
              arrayOfBlobs.push(e.data);
              updateTimeStamp();
              if (typeof config.ondataavailable === "function") {
                var blob = config.getNativeBlob ? e.data : new Blob([e.data], {
                  type: getMimeType(recorderHints)
                });
                config.ondataavailable(blob);
              }
            }
            return;
          }
          if (!e.data || !e.data.size || e.data.size < 100 || self.blob) {
            if (self.recordingCallback) {
              self.recordingCallback(new Blob([], {
                type: getMimeType(recorderHints)
              }));
              self.recordingCallback = null;
            }
            return;
          }
          self.blob = config.getNativeBlob ? e.data : new Blob([e.data], {
            type: getMimeType(recorderHints)
          });
          if (self.recordingCallback) {
            self.recordingCallback(self.blob);
            self.recordingCallback = null;
          }
        };
        mediaRecorder.onstart = function() {
          allStates.push("started");
        };
        mediaRecorder.onpause = function() {
          allStates.push("paused");
        };
        mediaRecorder.onresume = function() {
          allStates.push("resumed");
        };
        mediaRecorder.onstop = function() {
          allStates.push("stopped");
        };
        mediaRecorder.onerror = function(error) {
          if (!error) {
            return;
          }
          if (!error.name) {
            error.name = "UnknownError";
          }
          allStates.push("error: " + error);
          if (!config.disableLogs) {
            if (error.name.toString().toLowerCase().indexOf("invalidstate") !== -1) {
              console.error("The MediaRecorder is not in a state in which the proposed operation is allowed to be executed.", error);
            } else if (error.name.toString().toLowerCase().indexOf("notsupported") !== -1) {
              console.error("MIME type (", recorderHints.mimeType, ") is not supported.", error);
            } else if (error.name.toString().toLowerCase().indexOf("security") !== -1) {
              console.error("MediaRecorder security error", error);
            } else if (error.name === "OutOfMemory") {
              console.error("The UA has exhaused the available memory. User agents SHOULD provide as much additional information as possible in the message attribute.", error);
            } else if (error.name === "IllegalStreamModification") {
              console.error("A modification to the stream has occurred that makes it impossible to continue recording. An example would be the addition of a Track while recording is occurring. User agents SHOULD provide as much additional information as possible in the message attribute.", error);
            } else if (error.name === "OtherRecordingError") {
              console.error("Used for an fatal error other than those listed above. User agents SHOULD provide as much additional information as possible in the message attribute.", error);
            } else if (error.name === "GenericError") {
              console.error("The UA cannot provide the codec or recording option that has been requested.", error);
            } else {
              console.error("MediaRecorder Error", error);
            }
          }
          (function(looper) {
            if (!self.manuallyStopped && mediaRecorder && mediaRecorder.state === "inactive") {
              delete config.timeslice;
              mediaRecorder.start(10 * 60 * 1e3);
              return;
            }
            setTimeout(looper, 1e3);
          })();
          if (mediaRecorder.state !== "inactive" && mediaRecorder.state !== "stopped") {
            mediaRecorder.stop();
          }
        };
        if (typeof config.timeSlice === "number") {
          updateTimeStamp();
          mediaRecorder.start(config.timeSlice);
        } else {
          mediaRecorder.start(36e5);
        }
        if (config.initCallback) {
          config.initCallback();
        }
      };
      this.timestamps = [];
      function updateTimeStamp() {
        self.timestamps.push(new Date().getTime());
        if (typeof config.onTimeStamp === "function") {
          config.onTimeStamp(self.timestamps[self.timestamps.length - 1], self.timestamps);
        }
      }
      function getMimeType(secondObject) {
        if (mediaRecorder && mediaRecorder.mimeType) {
          return mediaRecorder.mimeType;
        }
        return secondObject.mimeType || "video/webm";
      }
      this.stop = function(callback) {
        callback = callback || function() {
        };
        self.manuallyStopped = true;
        if (!mediaRecorder) {
          return;
        }
        this.recordingCallback = callback;
        if (mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        }
        if (typeof config.timeSlice === "number") {
          setTimeout(function() {
            self.blob = new Blob(arrayOfBlobs, {
              type: getMimeType(config)
            });
            self.recordingCallback(self.blob);
          }, 100);
        }
      };
      this.pause = function() {
        if (!mediaRecorder) {
          return;
        }
        if (mediaRecorder.state === "recording") {
          mediaRecorder.pause();
        }
      };
      this.resume = function() {
        if (!mediaRecorder) {
          return;
        }
        if (mediaRecorder.state === "paused") {
          mediaRecorder.resume();
        }
      };
      this.clearRecordedData = function() {
        if (mediaRecorder && mediaRecorder.state === "recording") {
          self.stop(clearRecordedDataCB);
        }
        clearRecordedDataCB();
      };
      function clearRecordedDataCB() {
        arrayOfBlobs = [];
        mediaRecorder = null;
        self.timestamps = [];
      }
      var mediaRecorder;
      this.getInternalRecorder = function() {
        return mediaRecorder;
      };
      function isMediaStreamActive() {
        if ("active" in mediaStream) {
          if (!mediaStream.active) {
            return false;
          }
        } else if ("ended" in mediaStream) {
          if (mediaStream.ended) {
            return false;
          }
        }
        return true;
      }
      this.blob = null;
      this.getState = function() {
        if (!mediaRecorder) {
          return "inactive";
        }
        return mediaRecorder.state || "inactive";
      };
      var allStates = [];
      this.getAllStates = function() {
        return allStates;
      };
      if (typeof config.checkForInactiveTracks === "undefined") {
        config.checkForInactiveTracks = false;
      }
      var self = this;
      (function looper() {
        if (!mediaRecorder || config.checkForInactiveTracks === false) {
          return;
        }
        if (isMediaStreamActive() === false) {
          if (!config.disableLogs) {
            console.log("MediaStream seems stopped.");
          }
          self.stop();
          return;
        }
        setTimeout(looper, 1e3);
      })();
      this.name = "MediaStreamRecorder";
      this.toString = function() {
        return this.name;
      };
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.MediaStreamRecorder = MediaStreamRecorder;
    }
    function StereoAudioRecorder(mediaStream, config) {
      if (!getTracks(mediaStream, "audio").length) {
        throw "Your stream has no audio tracks.";
      }
      config = config || {};
      var self = this;
      var leftchannel = [];
      var rightchannel = [];
      var recording = false;
      var recordingLength = 0;
      var jsAudioNode;
      var numberOfAudioChannels = 2;
      var desiredSampRate = config.desiredSampRate;
      if (config.leftChannel === true) {
        numberOfAudioChannels = 1;
      }
      if (config.numberOfAudioChannels === 1) {
        numberOfAudioChannels = 1;
      }
      if (!numberOfAudioChannels || numberOfAudioChannels < 1) {
        numberOfAudioChannels = 2;
      }
      if (!config.disableLogs) {
        console.log("StereoAudioRecorder is set to record number of channels: " + numberOfAudioChannels);
      }
      if (typeof config.checkForInactiveTracks === "undefined") {
        config.checkForInactiveTracks = true;
      }
      function isMediaStreamActive() {
        if (config.checkForInactiveTracks === false) {
          return true;
        }
        if ("active" in mediaStream) {
          if (!mediaStream.active) {
            return false;
          }
        } else if ("ended" in mediaStream) {
          if (mediaStream.ended) {
            return false;
          }
        }
        return true;
      }
      this.record = function() {
        if (isMediaStreamActive() === false) {
          throw "Please make sure MediaStream is active.";
        }
        resetVariables();
        isAudioProcessStarted = isPaused = false;
        recording = true;
        if (typeof config.timeSlice !== "undefined") {
          looper();
        }
      };
      function mergeLeftRightBuffers(config2, callback) {
        function mergeAudioBuffers(config3, cb) {
          var numberOfAudioChannels2 = config3.numberOfAudioChannels;
          var leftBuffers = config3.leftBuffers.slice(0);
          var rightBuffers = config3.rightBuffers.slice(0);
          var sampleRate2 = config3.sampleRate;
          var internalInterleavedLength = config3.internalInterleavedLength;
          var desiredSampRate2 = config3.desiredSampRate;
          if (numberOfAudioChannels2 === 2) {
            leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength);
            rightBuffers = mergeBuffers(rightBuffers, internalInterleavedLength);
            if (desiredSampRate2) {
              leftBuffers = interpolateArray(leftBuffers, desiredSampRate2, sampleRate2);
              rightBuffers = interpolateArray(rightBuffers, desiredSampRate2, sampleRate2);
            }
          }
          if (numberOfAudioChannels2 === 1) {
            leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength);
            if (desiredSampRate2) {
              leftBuffers = interpolateArray(leftBuffers, desiredSampRate2, sampleRate2);
            }
          }
          if (desiredSampRate2) {
            sampleRate2 = desiredSampRate2;
          }
          function interpolateArray(data, newSampleRate, oldSampleRate) {
            var fitCount = Math.round(data.length * (newSampleRate / oldSampleRate));
            var newData = [];
            var springFactor = Number((data.length - 1) / (fitCount - 1));
            newData[0] = data[0];
            for (var i2 = 1; i2 < fitCount - 1; i2++) {
              var tmp = i2 * springFactor;
              var before = Number(Math.floor(tmp)).toFixed();
              var after = Number(Math.ceil(tmp)).toFixed();
              var atPoint = tmp - before;
              newData[i2] = linearInterpolate(data[before], data[after], atPoint);
            }
            newData[fitCount - 1] = data[data.length - 1];
            return newData;
          }
          function linearInterpolate(before, after, atPoint) {
            return before + (after - before) * atPoint;
          }
          function mergeBuffers(channelBuffer, rLength) {
            var result = new Float64Array(rLength);
            var offset = 0;
            var lng2 = channelBuffer.length;
            for (var i2 = 0; i2 < lng2; i2++) {
              var buffer2 = channelBuffer[i2];
              result.set(buffer2, offset);
              offset += buffer2.length;
            }
            return result;
          }
          function interleave(leftChannel, rightChannel) {
            var length = leftChannel.length + rightChannel.length;
            var result = new Float64Array(length);
            var inputIndex = 0;
            for (var index2 = 0; index2 < length; ) {
              result[index2++] = leftChannel[inputIndex];
              result[index2++] = rightChannel[inputIndex];
              inputIndex++;
            }
            return result;
          }
          function writeUTFBytes(view2, offset, string) {
            var lng2 = string.length;
            for (var i2 = 0; i2 < lng2; i2++) {
              view2.setUint8(offset + i2, string.charCodeAt(i2));
            }
          }
          var interleaved;
          if (numberOfAudioChannels2 === 2) {
            interleaved = interleave(leftBuffers, rightBuffers);
          }
          if (numberOfAudioChannels2 === 1) {
            interleaved = leftBuffers;
          }
          var interleavedLength = interleaved.length;
          var resultingBufferLength = 44 + interleavedLength * 2;
          var buffer = new ArrayBuffer(resultingBufferLength);
          var view = new DataView(buffer);
          writeUTFBytes(view, 0, "RIFF");
          view.setUint32(4, 36 + interleavedLength * 2, true);
          writeUTFBytes(view, 8, "WAVE");
          writeUTFBytes(view, 12, "fmt ");
          view.setUint32(16, 16, true);
          view.setUint16(20, 1, true);
          view.setUint16(22, numberOfAudioChannels2, true);
          view.setUint32(24, sampleRate2, true);
          view.setUint32(28, sampleRate2 * numberOfAudioChannels2 * 2, true);
          view.setUint16(32, numberOfAudioChannels2 * 2, true);
          view.setUint16(34, 16, true);
          writeUTFBytes(view, 36, "data");
          view.setUint32(40, interleavedLength * 2, true);
          var lng = interleavedLength;
          var index = 44;
          var volume = 1;
          for (var i = 0; i < lng; i++) {
            view.setInt16(index, interleaved[i] * (32767 * volume), true);
            index += 2;
          }
          if (cb) {
            return cb({
              buffer,
              view
            });
          }
          postMessage({
            buffer,
            view
          });
        }
        if (config2.noWorker) {
          mergeAudioBuffers(config2, function(data) {
            callback(data.buffer, data.view);
          });
          return;
        }
        var webWorker = processInWebWorker(mergeAudioBuffers);
        webWorker.onmessage = function(event2) {
          callback(event2.data.buffer, event2.data.view);
          URL2.revokeObjectURL(webWorker.workerURL);
          webWorker.terminate();
        };
        webWorker.postMessage(config2);
      }
      function processInWebWorker(_function) {
        var workerURL = URL2.createObjectURL(new Blob([
          _function.toString(),
          ";this.onmessage =  function (eee) {" + _function.name + "(eee.data);}"
        ], {
          type: "application/javascript"
        }));
        var worker = new Worker(workerURL);
        worker.workerURL = workerURL;
        return worker;
      }
      this.stop = function(callback) {
        callback = callback || function() {
        };
        recording = false;
        mergeLeftRightBuffers({
          desiredSampRate,
          sampleRate,
          numberOfAudioChannels,
          internalInterleavedLength: recordingLength,
          leftBuffers: leftchannel,
          rightBuffers: numberOfAudioChannels === 1 ? [] : rightchannel,
          noWorker: config.noWorker
        }, function(buffer, view) {
          self.blob = new Blob([view], {
            type: "audio/wav"
          });
          self.buffer = new ArrayBuffer(view.buffer.byteLength);
          self.view = view;
          self.sampleRate = desiredSampRate || sampleRate;
          self.bufferSize = bufferSize;
          self.length = recordingLength;
          isAudioProcessStarted = false;
          if (callback) {
            callback(self.blob);
          }
        });
      };
      if (typeof RecordRTC2.Storage === "undefined") {
        RecordRTC2.Storage = {
          AudioContextConstructor: null,
          AudioContext: window.AudioContext || window.webkitAudioContext
        };
      }
      if (!RecordRTC2.Storage.AudioContextConstructor || RecordRTC2.Storage.AudioContextConstructor.state === "closed") {
        RecordRTC2.Storage.AudioContextConstructor = new RecordRTC2.Storage.AudioContext();
      }
      var context = RecordRTC2.Storage.AudioContextConstructor;
      var audioInput = context.createMediaStreamSource(mediaStream);
      var legalBufferValues = [0, 256, 512, 1024, 2048, 4096, 8192, 16384];
      var bufferSize = typeof config.bufferSize === "undefined" ? 4096 : config.bufferSize;
      if (legalBufferValues.indexOf(bufferSize) === -1) {
        if (!config.disableLogs) {
          console.log("Legal values for buffer-size are " + JSON.stringify(legalBufferValues, null, "	"));
        }
      }
      if (context.createJavaScriptNode) {
        jsAudioNode = context.createJavaScriptNode(bufferSize, numberOfAudioChannels, numberOfAudioChannels);
      } else if (context.createScriptProcessor) {
        jsAudioNode = context.createScriptProcessor(bufferSize, numberOfAudioChannels, numberOfAudioChannels);
      } else {
        throw "WebAudio API has no support on this browser.";
      }
      audioInput.connect(jsAudioNode);
      if (!config.bufferSize) {
        bufferSize = jsAudioNode.bufferSize;
      }
      var sampleRate = typeof config.sampleRate !== "undefined" ? config.sampleRate : context.sampleRate || 44100;
      if (sampleRate < 22050 || sampleRate > 96e3) {
        if (!config.disableLogs) {
          console.log("sample-rate must be under range 22050 and 96000.");
        }
      }
      if (!config.disableLogs) {
        if (config.desiredSampRate) {
          console.log("Desired sample-rate: " + config.desiredSampRate);
        }
      }
      var isPaused = false;
      this.pause = function() {
        isPaused = true;
      };
      this.resume = function() {
        if (isMediaStreamActive() === false) {
          throw "Please make sure MediaStream is active.";
        }
        if (!recording) {
          if (!config.disableLogs) {
            console.log("Seems recording has been restarted.");
          }
          this.record();
          return;
        }
        isPaused = false;
      };
      this.clearRecordedData = function() {
        config.checkForInactiveTracks = false;
        if (recording) {
          this.stop(clearRecordedDataCB);
        }
        clearRecordedDataCB();
      };
      function resetVariables() {
        leftchannel = [];
        rightchannel = [];
        recordingLength = 0;
        isAudioProcessStarted = false;
        recording = false;
        isPaused = false;
        context = null;
        self.leftchannel = leftchannel;
        self.rightchannel = rightchannel;
        self.numberOfAudioChannels = numberOfAudioChannels;
        self.desiredSampRate = desiredSampRate;
        self.sampleRate = sampleRate;
        self.recordingLength = recordingLength;
        intervalsBasedBuffers = {
          left: [],
          right: [],
          recordingLength: 0
        };
      }
      function clearRecordedDataCB() {
        if (jsAudioNode) {
          jsAudioNode.onaudioprocess = null;
          jsAudioNode.disconnect();
          jsAudioNode = null;
        }
        if (audioInput) {
          audioInput.disconnect();
          audioInput = null;
        }
        resetVariables();
      }
      this.name = "StereoAudioRecorder";
      this.toString = function() {
        return this.name;
      };
      var isAudioProcessStarted = false;
      function onAudioProcessDataAvailable(e) {
        if (isPaused) {
          return;
        }
        if (isMediaStreamActive() === false) {
          if (!config.disableLogs) {
            console.log("MediaStream seems stopped.");
          }
          jsAudioNode.disconnect();
          recording = false;
        }
        if (!recording) {
          if (audioInput) {
            audioInput.disconnect();
            audioInput = null;
          }
          return;
        }
        if (!isAudioProcessStarted) {
          isAudioProcessStarted = true;
          if (config.onAudioProcessStarted) {
            config.onAudioProcessStarted();
          }
          if (config.initCallback) {
            config.initCallback();
          }
        }
        var left = e.inputBuffer.getChannelData(0);
        var chLeft = new Float32Array(left);
        leftchannel.push(chLeft);
        if (numberOfAudioChannels === 2) {
          var right = e.inputBuffer.getChannelData(1);
          var chRight = new Float32Array(right);
          rightchannel.push(chRight);
        }
        recordingLength += bufferSize;
        self.recordingLength = recordingLength;
        if (typeof config.timeSlice !== "undefined") {
          intervalsBasedBuffers.recordingLength += bufferSize;
          intervalsBasedBuffers.left.push(chLeft);
          if (numberOfAudioChannels === 2) {
            intervalsBasedBuffers.right.push(chRight);
          }
        }
      }
      jsAudioNode.onaudioprocess = onAudioProcessDataAvailable;
      if (context.createMediaStreamDestination) {
        jsAudioNode.connect(context.createMediaStreamDestination());
      } else {
        jsAudioNode.connect(context.destination);
      }
      this.leftchannel = leftchannel;
      this.rightchannel = rightchannel;
      this.numberOfAudioChannels = numberOfAudioChannels;
      this.desiredSampRate = desiredSampRate;
      this.sampleRate = sampleRate;
      self.recordingLength = recordingLength;
      var intervalsBasedBuffers = {
        left: [],
        right: [],
        recordingLength: 0
      };
      function looper() {
        if (!recording || typeof config.ondataavailable !== "function" || typeof config.timeSlice === "undefined") {
          return;
        }
        if (intervalsBasedBuffers.left.length) {
          mergeLeftRightBuffers({
            desiredSampRate,
            sampleRate,
            numberOfAudioChannels,
            internalInterleavedLength: intervalsBasedBuffers.recordingLength,
            leftBuffers: intervalsBasedBuffers.left,
            rightBuffers: numberOfAudioChannels === 1 ? [] : intervalsBasedBuffers.right
          }, function(buffer, view) {
            var blob = new Blob([view], {
              type: "audio/wav"
            });
            config.ondataavailable(blob);
            setTimeout(looper, config.timeSlice);
          });
          intervalsBasedBuffers = {
            left: [],
            right: [],
            recordingLength: 0
          };
        } else {
          setTimeout(looper, config.timeSlice);
        }
      }
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.StereoAudioRecorder = StereoAudioRecorder;
    }
    function CanvasRecorder(htmlElement, config) {
      if (typeof html2canvas === "undefined") {
        throw "Please link: https://www.webrtc-experiment.com/screenshot.js";
      }
      config = config || {};
      if (!config.frameInterval) {
        config.frameInterval = 10;
      }
      var isCanvasSupportsStreamCapturing = false;
      ["captureStream", "mozCaptureStream", "webkitCaptureStream"].forEach(function(item) {
        if (item in document.createElement("canvas")) {
          isCanvasSupportsStreamCapturing = true;
        }
      });
      var _isChrome = (!!window.webkitRTCPeerConnection || !!window.webkitGetUserMedia) && !!window.chrome;
      var chromeVersion = 50;
      var matchArray = navigator.userAgent.match(/Chrom(e|ium)\/([0-9]+)\./);
      if (_isChrome && matchArray && matchArray[2]) {
        chromeVersion = parseInt(matchArray[2], 10);
      }
      if (_isChrome && chromeVersion < 52) {
        isCanvasSupportsStreamCapturing = false;
      }
      if (config.useWhammyRecorder) {
        isCanvasSupportsStreamCapturing = false;
      }
      var globalCanvas, mediaStreamRecorder;
      if (isCanvasSupportsStreamCapturing) {
        if (!config.disableLogs) {
          console.log("Your browser supports both MediRecorder API and canvas.captureStream!");
        }
        if (htmlElement instanceof HTMLCanvasElement) {
          globalCanvas = htmlElement;
        } else if (htmlElement instanceof CanvasRenderingContext2D) {
          globalCanvas = htmlElement.canvas;
        } else {
          throw "Please pass either HTMLCanvasElement or CanvasRenderingContext2D.";
        }
      } else if (!!navigator.mozGetUserMedia) {
        if (!config.disableLogs) {
          console.error("Canvas recording is NOT supported in Firefox.");
        }
      }
      var isRecording;
      this.record = function() {
        isRecording = true;
        if (isCanvasSupportsStreamCapturing && !config.useWhammyRecorder) {
          var canvasMediaStream;
          if ("captureStream" in globalCanvas) {
            canvasMediaStream = globalCanvas.captureStream(25);
          } else if ("mozCaptureStream" in globalCanvas) {
            canvasMediaStream = globalCanvas.mozCaptureStream(25);
          } else if ("webkitCaptureStream" in globalCanvas) {
            canvasMediaStream = globalCanvas.webkitCaptureStream(25);
          }
          try {
            var mdStream = new MediaStream();
            mdStream.addTrack(getTracks(canvasMediaStream, "video")[0]);
            canvasMediaStream = mdStream;
          } catch (e) {
          }
          if (!canvasMediaStream) {
            throw "captureStream API are NOT available.";
          }
          mediaStreamRecorder = new MediaStreamRecorder(canvasMediaStream, {
            mimeType: config.mimeType || "video/webm"
          });
          mediaStreamRecorder.record();
        } else {
          whammy.frames = [];
          lastTime2 = new Date().getTime();
          drawCanvasFrame();
        }
        if (config.initCallback) {
          config.initCallback();
        }
      };
      this.getWebPImages = function(callback) {
        if (htmlElement.nodeName.toLowerCase() !== "canvas") {
          callback();
          return;
        }
        var framesLength = whammy.frames.length;
        whammy.frames.forEach(function(frame, idx) {
          var framesRemaining = framesLength - idx;
          if (!config.disableLogs) {
            console.log(framesRemaining + "/" + framesLength + " frames remaining");
          }
          if (config.onEncodingCallback) {
            config.onEncodingCallback(framesRemaining, framesLength);
          }
          var webp = frame.image.toDataURL("image/webp", 1);
          whammy.frames[idx].image = webp;
        });
        if (!config.disableLogs) {
          console.log("Generating WebM");
        }
        callback();
      };
      this.stop = function(callback) {
        isRecording = false;
        var that = this;
        if (isCanvasSupportsStreamCapturing && mediaStreamRecorder) {
          mediaStreamRecorder.stop(callback);
          return;
        }
        this.getWebPImages(function() {
          whammy.compile(function(blob) {
            if (!config.disableLogs) {
              console.log("Recording finished!");
            }
            that.blob = blob;
            if (that.blob.forEach) {
              that.blob = new Blob([], {
                type: "video/webm"
              });
            }
            if (callback) {
              callback(that.blob);
            }
            whammy.frames = [];
          });
        });
      };
      var isPausedRecording = false;
      this.pause = function() {
        isPausedRecording = true;
        if (mediaStreamRecorder instanceof MediaStreamRecorder) {
          mediaStreamRecorder.pause();
          return;
        }
      };
      this.resume = function() {
        isPausedRecording = false;
        if (mediaStreamRecorder instanceof MediaStreamRecorder) {
          mediaStreamRecorder.resume();
          return;
        }
        if (!isRecording) {
          this.record();
        }
      };
      this.clearRecordedData = function() {
        if (isRecording) {
          this.stop(clearRecordedDataCB);
        }
        clearRecordedDataCB();
      };
      function clearRecordedDataCB() {
        whammy.frames = [];
        isRecording = false;
        isPausedRecording = false;
      }
      this.name = "CanvasRecorder";
      this.toString = function() {
        return this.name;
      };
      function cloneCanvas() {
        var newCanvas = document.createElement("canvas");
        var context = newCanvas.getContext("2d");
        newCanvas.width = htmlElement.width;
        newCanvas.height = htmlElement.height;
        context.drawImage(htmlElement, 0, 0);
        return newCanvas;
      }
      function drawCanvasFrame() {
        if (isPausedRecording) {
          lastTime2 = new Date().getTime();
          return setTimeout(drawCanvasFrame, 500);
        }
        if (htmlElement.nodeName.toLowerCase() === "canvas") {
          var duration = new Date().getTime() - lastTime2;
          lastTime2 = new Date().getTime();
          whammy.frames.push({
            image: cloneCanvas(),
            duration
          });
          if (isRecording) {
            setTimeout(drawCanvasFrame, config.frameInterval);
          }
          return;
        }
        html2canvas(htmlElement, {
          grabMouse: typeof config.showMousePointer === "undefined" || config.showMousePointer,
          onrendered: function(canvas) {
            var duration2 = new Date().getTime() - lastTime2;
            if (!duration2) {
              return setTimeout(drawCanvasFrame, config.frameInterval);
            }
            lastTime2 = new Date().getTime();
            whammy.frames.push({
              image: canvas.toDataURL("image/webp", 1),
              duration: duration2
            });
            if (isRecording) {
              setTimeout(drawCanvasFrame, config.frameInterval);
            }
          }
        });
      }
      var lastTime2 = new Date().getTime();
      var whammy = new Whammy.Video(100);
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.CanvasRecorder = CanvasRecorder;
    }
    function WhammyRecorder(mediaStream, config) {
      config = config || {};
      if (!config.frameInterval) {
        config.frameInterval = 10;
      }
      if (!config.disableLogs) {
        console.log("Using frames-interval:", config.frameInterval);
      }
      this.record = function() {
        if (!config.width) {
          config.width = 320;
        }
        if (!config.height) {
          config.height = 240;
        }
        if (!config.video) {
          config.video = {
            width: config.width,
            height: config.height
          };
        }
        if (!config.canvas) {
          config.canvas = {
            width: config.width,
            height: config.height
          };
        }
        canvas.width = config.canvas.width || 320;
        canvas.height = config.canvas.height || 240;
        context = canvas.getContext("2d");
        if (config.video && config.video instanceof HTMLVideoElement) {
          video = config.video.cloneNode();
          if (config.initCallback) {
            config.initCallback();
          }
        } else {
          video = document.createElement("video");
          setSrcObject(mediaStream, video);
          video.onloadedmetadata = function() {
            if (config.initCallback) {
              config.initCallback();
            }
          };
          video.width = config.video.width;
          video.height = config.video.height;
        }
        video.muted = true;
        video.play();
        lastTime2 = new Date().getTime();
        whammy = new Whammy.Video();
        if (!config.disableLogs) {
          console.log("canvas resolutions", canvas.width, "*", canvas.height);
          console.log("video width/height", video.width || canvas.width, "*", video.height || canvas.height);
        }
        drawFrames(config.frameInterval);
      };
      function drawFrames(frameInterval) {
        frameInterval = typeof frameInterval !== "undefined" ? frameInterval : 10;
        var duration = new Date().getTime() - lastTime2;
        if (!duration) {
          return setTimeout(drawFrames, frameInterval, frameInterval);
        }
        if (isPausedRecording) {
          lastTime2 = new Date().getTime();
          return setTimeout(drawFrames, 100);
        }
        lastTime2 = new Date().getTime();
        if (video.paused) {
          video.play();
        }
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        whammy.frames.push({
          duration,
          image: canvas.toDataURL("image/webp")
        });
        if (!isStopDrawing) {
          setTimeout(drawFrames, frameInterval, frameInterval);
        }
      }
      function asyncLoop(o) {
        var i = -1, length = o.length;
        (function loop() {
          i++;
          if (i === length) {
            o.callback();
            return;
          }
          setTimeout(function() {
            o.functionToLoop(loop, i);
          }, 1);
        })();
      }
      function dropBlackFrames(_frames, _framesToCheck, _pixTolerance, _frameTolerance, callback) {
        var localCanvas = document.createElement("canvas");
        localCanvas.width = canvas.width;
        localCanvas.height = canvas.height;
        var context2d = localCanvas.getContext("2d");
        var resultFrames = [];
        var checkUntilNotBlack = _framesToCheck === -1;
        var endCheckFrame = _framesToCheck && _framesToCheck > 0 && _framesToCheck <= _frames.length ? _framesToCheck : _frames.length;
        var sampleColor = {
          r: 0,
          g: 0,
          b: 0
        };
        var maxColorDifference = Math.sqrt(
          Math.pow(255, 2) + Math.pow(255, 2) + Math.pow(255, 2)
        );
        var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;
        var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;
        var doNotCheckNext = false;
        asyncLoop({
          length: endCheckFrame,
          functionToLoop: function(loop, f) {
            var matchPixCount, endPixCheck, maxPixCount;
            var finishImage = function() {
              if (!doNotCheckNext && maxPixCount - matchPixCount <= maxPixCount * frameTolerance) {
              } else {
                if (checkUntilNotBlack) {
                  doNotCheckNext = true;
                }
                resultFrames.push(_frames[f]);
              }
              loop();
            };
            if (!doNotCheckNext) {
              var image = new Image();
              image.onload = function() {
                context2d.drawImage(image, 0, 0, canvas.width, canvas.height);
                var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);
                matchPixCount = 0;
                endPixCheck = imageData.data.length;
                maxPixCount = imageData.data.length / 4;
                for (var pix = 0; pix < endPixCheck; pix += 4) {
                  var currentColor = {
                    r: imageData.data[pix],
                    g: imageData.data[pix + 1],
                    b: imageData.data[pix + 2]
                  };
                  var colorDifference = Math.sqrt(
                    Math.pow(currentColor.r - sampleColor.r, 2) + Math.pow(currentColor.g - sampleColor.g, 2) + Math.pow(currentColor.b - sampleColor.b, 2)
                  );
                  if (colorDifference <= maxColorDifference * pixTolerance) {
                    matchPixCount++;
                  }
                }
                finishImage();
              };
              image.src = _frames[f].image;
            } else {
              finishImage();
            }
          },
          callback: function() {
            resultFrames = resultFrames.concat(_frames.slice(endCheckFrame));
            if (resultFrames.length <= 0) {
              resultFrames.push(_frames[_frames.length - 1]);
            }
            callback(resultFrames);
          }
        });
      }
      var isStopDrawing = false;
      this.stop = function(callback) {
        callback = callback || function() {
        };
        isStopDrawing = true;
        var _this = this;
        setTimeout(function() {
          dropBlackFrames(whammy.frames, -1, null, null, function(frames) {
            whammy.frames = frames;
            if (config.advertisement && config.advertisement.length) {
              whammy.frames = config.advertisement.concat(whammy.frames);
            }
            whammy.compile(function(blob) {
              _this.blob = blob;
              if (_this.blob.forEach) {
                _this.blob = new Blob([], {
                  type: "video/webm"
                });
              }
              if (callback) {
                callback(_this.blob);
              }
            });
          });
        }, 10);
      };
      var isPausedRecording = false;
      this.pause = function() {
        isPausedRecording = true;
      };
      this.resume = function() {
        isPausedRecording = false;
        if (isStopDrawing) {
          this.record();
        }
      };
      this.clearRecordedData = function() {
        if (!isStopDrawing) {
          this.stop(clearRecordedDataCB);
        }
        clearRecordedDataCB();
      };
      function clearRecordedDataCB() {
        whammy.frames = [];
        isStopDrawing = true;
        isPausedRecording = false;
      }
      this.name = "WhammyRecorder";
      this.toString = function() {
        return this.name;
      };
      var canvas = document.createElement("canvas");
      var context = canvas.getContext("2d");
      var video;
      var lastTime2;
      var whammy;
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.WhammyRecorder = WhammyRecorder;
    }
    var Whammy = function() {
      function WhammyVideo(duration) {
        this.frames = [];
        this.duration = duration || 1;
        this.quality = 0.8;
      }
      WhammyVideo.prototype.add = function(frame, duration) {
        if ("canvas" in frame) {
          frame = frame.canvas;
        }
        if ("toDataURL" in frame) {
          frame = frame.toDataURL("image/webp", this.quality);
        }
        if (!/^data:image\/webp;base64,/ig.test(frame)) {
          throw "Input must be formatted properly as a base64 encoded DataURI of type image/webp";
        }
        this.frames.push({
          image: frame,
          duration: duration || this.duration
        });
      };
      function processInWebWorker(_function) {
        var blob = URL2.createObjectURL(new Blob([
          _function.toString(),
          "this.onmessage =  function (eee) {" + _function.name + "(eee.data);}"
        ], {
          type: "application/javascript"
        }));
        var worker = new Worker(blob);
        URL2.revokeObjectURL(blob);
        return worker;
      }
      function whammyInWebWorker(frames) {
        function ArrayToWebM(frames2) {
          var info = checkFrames(frames2);
          if (!info) {
            return [];
          }
          var clusterMaxDuration = 3e4;
          var EBML2 = [{
            "id": 440786851,
            // EBML
            "data": [{
              "data": 1,
              "id": 17030
              // EBMLVersion
            }, {
              "data": 1,
              "id": 17143
              // EBMLReadVersion
            }, {
              "data": 4,
              "id": 17138
              // EBMLMaxIDLength
            }, {
              "data": 8,
              "id": 17139
              // EBMLMaxSizeLength
            }, {
              "data": "webm",
              "id": 17026
              // DocType
            }, {
              "data": 2,
              "id": 17031
              // DocTypeVersion
            }, {
              "data": 2,
              "id": 17029
              // DocTypeReadVersion
            }]
          }, {
            "id": 408125543,
            // Segment
            "data": [{
              "id": 357149030,
              // Info
              "data": [{
                "data": 1e6,
                //do things in millisecs (num of nanosecs for duration scale)
                "id": 2807729
                // TimecodeScale
              }, {
                "data": "whammy",
                "id": 19840
                // MuxingApp
              }, {
                "data": "whammy",
                "id": 22337
                // WritingApp
              }, {
                "data": doubleToString(info.duration),
                "id": 17545
                // Duration
              }]
            }, {
              "id": 374648427,
              // Tracks
              "data": [{
                "id": 174,
                // TrackEntry
                "data": [{
                  "data": 1,
                  "id": 215
                  // TrackNumber
                }, {
                  "data": 1,
                  "id": 29637
                  // TrackUID
                }, {
                  "data": 0,
                  "id": 156
                  // FlagLacing
                }, {
                  "data": "und",
                  "id": 2274716
                  // Language
                }, {
                  "data": "V_VP8",
                  "id": 134
                  // CodecID
                }, {
                  "data": "VP8",
                  "id": 2459272
                  // CodecName
                }, {
                  "data": 1,
                  "id": 131
                  // TrackType
                }, {
                  "id": 224,
                  // Video
                  "data": [{
                    "data": info.width,
                    "id": 176
                    // PixelWidth
                  }, {
                    "data": info.height,
                    "id": 186
                    // PixelHeight
                  }]
                }]
              }]
            }]
          }];
          var frameNumber = 0;
          var clusterTimecode = 0;
          while (frameNumber < frames2.length) {
            var clusterFrames = [];
            var clusterDuration = 0;
            do {
              clusterFrames.push(frames2[frameNumber]);
              clusterDuration += frames2[frameNumber].duration;
              frameNumber++;
            } while (frameNumber < frames2.length && clusterDuration < clusterMaxDuration);
            var clusterCounter = 0;
            var cluster = {
              "id": 524531317,
              // Cluster
              "data": getClusterData(clusterTimecode, clusterCounter, clusterFrames)
            };
            EBML2[1].data.push(cluster);
            clusterTimecode += clusterDuration;
          }
          return generateEBML(EBML2);
        }
        function getClusterData(clusterTimecode, clusterCounter, clusterFrames) {
          return [{
            "data": clusterTimecode,
            "id": 231
            // Timecode
          }].concat(clusterFrames.map(function(webp) {
            var block = makeSimpleBlock({
              discardable: 0,
              frame: webp.data.slice(4),
              invisible: 0,
              keyframe: 1,
              lacing: 0,
              trackNum: 1,
              timecode: Math.round(clusterCounter)
            });
            clusterCounter += webp.duration;
            return {
              data: block,
              id: 163
            };
          }));
        }
        function checkFrames(frames2) {
          if (!frames2[0]) {
            postMessage({
              error: "Something went wrong. Maybe WebP format is not supported in the current browser."
            });
            return;
          }
          var width = frames2[0].width, height = frames2[0].height, duration = frames2[0].duration;
          for (var i = 1; i < frames2.length; i++) {
            duration += frames2[i].duration;
          }
          return {
            duration,
            width,
            height
          };
        }
        function numToBuffer(num) {
          var parts = [];
          while (num > 0) {
            parts.push(num & 255);
            num = num >> 8;
          }
          return new Uint8Array(parts.reverse());
        }
        function strToBuffer(str) {
          return new Uint8Array(str.split("").map(function(e) {
            return e.charCodeAt(0);
          }));
        }
        function bitsToBuffer(bits) {
          var data = [];
          var pad = bits.length % 8 ? new Array(1 + 8 - bits.length % 8).join("0") : "";
          bits = pad + bits;
          for (var i = 0; i < bits.length; i += 8) {
            data.push(parseInt(bits.substr(i, 8), 2));
          }
          return new Uint8Array(data);
        }
        function generateEBML(json) {
          var ebml = [];
          for (var i = 0; i < json.length; i++) {
            var data = json[i].data;
            if (typeof data === "object") {
              data = generateEBML(data);
            }
            if (typeof data === "number") {
              data = bitsToBuffer(data.toString(2));
            }
            if (typeof data === "string") {
              data = strToBuffer(data);
            }
            var len = data.size || data.byteLength || data.length;
            var zeroes = Math.ceil(Math.ceil(Math.log(len) / Math.log(2)) / 8);
            var sizeToString = len.toString(2);
            var padded = new Array(zeroes * 7 + 7 + 1 - sizeToString.length).join("0") + sizeToString;
            var size = new Array(zeroes).join("0") + "1" + padded;
            ebml.push(numToBuffer(json[i].id));
            ebml.push(bitsToBuffer(size));
            ebml.push(data);
          }
          return new Blob(ebml, {
            type: "video/webm"
          });
        }
        function toBinStrOld(bits) {
          var data = "";
          var pad = bits.length % 8 ? new Array(1 + 8 - bits.length % 8).join("0") : "";
          bits = pad + bits;
          for (var i = 0; i < bits.length; i += 8) {
            data += String.fromCharCode(parseInt(bits.substr(i, 8), 2));
          }
          return data;
        }
        function makeSimpleBlock(data) {
          var flags = 0;
          if (data.keyframe) {
            flags |= 128;
          }
          if (data.invisible) {
            flags |= 8;
          }
          if (data.lacing) {
            flags |= data.lacing << 1;
          }
          if (data.discardable) {
            flags |= 1;
          }
          if (data.trackNum > 127) {
            throw "TrackNumber > 127 not supported";
          }
          var out = [data.trackNum | 128, data.timecode >> 8, data.timecode & 255, flags].map(function(e) {
            return String.fromCharCode(e);
          }).join("") + data.frame;
          return out;
        }
        function parseWebP(riff) {
          var VP8 = riff.RIFF[0].WEBP[0];
          var frameStart = VP8.indexOf("\x9D*");
          for (var i = 0, c = []; i < 4; i++) {
            c[i] = VP8.charCodeAt(frameStart + 3 + i);
          }
          var width, height, tmp;
          tmp = c[1] << 8 | c[0];
          width = tmp & 16383;
          tmp = c[3] << 8 | c[2];
          height = tmp & 16383;
          return {
            width,
            height,
            data: VP8,
            riff
          };
        }
        function getStrLength(string, offset) {
          return parseInt(string.substr(offset + 4, 4).split("").map(function(i) {
            var unpadded = i.charCodeAt(0).toString(2);
            return new Array(8 - unpadded.length + 1).join("0") + unpadded;
          }).join(""), 2);
        }
        function parseRIFF(string) {
          var offset = 0;
          var chunks = {};
          while (offset < string.length) {
            var id = string.substr(offset, 4);
            var len = getStrLength(string, offset);
            var data = string.substr(offset + 4 + 4, len);
            offset += 4 + 4 + len;
            chunks[id] = chunks[id] || [];
            if (id === "RIFF" || id === "LIST") {
              chunks[id].push(parseRIFF(data));
            } else {
              chunks[id].push(data);
            }
          }
          return chunks;
        }
        function doubleToString(num) {
          return [].slice.call(
            new Uint8Array(new Float64Array([num]).buffer),
            0
          ).map(function(e) {
            return String.fromCharCode(e);
          }).reverse().join("");
        }
        var webm = new ArrayToWebM(frames.map(function(frame) {
          var webp = parseWebP(parseRIFF(atob(frame.image.slice(23))));
          webp.duration = frame.duration;
          return webp;
        }));
        postMessage(webm);
      }
      WhammyVideo.prototype.compile = function(callback) {
        var webWorker = processInWebWorker(whammyInWebWorker);
        webWorker.onmessage = function(event2) {
          if (event2.data.error) {
            console.error(event2.data.error);
            return;
          }
          callback(event2.data);
        };
        webWorker.postMessage(this.frames);
      };
      return {
        /**
         * A more abstract-ish API.
         * @method
         * @memberof Whammy
         * @example
         * recorder = new Whammy().Video(0.8, 100);
         * @param {?number} speed - 0.8
         * @param {?number} quality - 100
         */
        Video: WhammyVideo
      };
    }();
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.Whammy = Whammy;
    }
    var DiskStorage = {
      /**
       * This method must be called once to initialize IndexedDB ObjectStore. Though, it is auto-used internally.
       * @method
       * @memberof DiskStorage
       * @internal
       * @example
       * DiskStorage.init();
       */
      init: function() {
        var self = this;
        if (typeof indexedDB === "undefined" || typeof indexedDB.open === "undefined") {
          console.error("IndexedDB API are not available in this browser.");
          return;
        }
        var dbVersion = 1;
        var dbName = this.dbName || location.href.replace(/\/|:|#|%|\.|\[|\]/g, ""), db;
        var request = indexedDB.open(dbName, dbVersion);
        function createObjectStore(dataBase) {
          dataBase.createObjectStore(self.dataStoreName);
        }
        function putInDB() {
          var transaction = db.transaction([self.dataStoreName], "readwrite");
          if (self.videoBlob) {
            transaction.objectStore(self.dataStoreName).put(self.videoBlob, "videoBlob");
          }
          if (self.gifBlob) {
            transaction.objectStore(self.dataStoreName).put(self.gifBlob, "gifBlob");
          }
          if (self.audioBlob) {
            transaction.objectStore(self.dataStoreName).put(self.audioBlob, "audioBlob");
          }
          function getFromStore(portionName) {
            transaction.objectStore(self.dataStoreName).get(portionName).onsuccess = function(event2) {
              if (self.callback) {
                self.callback(event2.target.result, portionName);
              }
            };
          }
          getFromStore("audioBlob");
          getFromStore("videoBlob");
          getFromStore("gifBlob");
        }
        request.onerror = self.onError;
        request.onsuccess = function() {
          db = request.result;
          db.onerror = self.onError;
          if (db.setVersion) {
            if (db.version !== dbVersion) {
              var setVersion = db.setVersion(dbVersion);
              setVersion.onsuccess = function() {
                createObjectStore(db);
                putInDB();
              };
            } else {
              putInDB();
            }
          } else {
            putInDB();
          }
        };
        request.onupgradeneeded = function(event2) {
          createObjectStore(event2.target.result);
        };
      },
      /**
       * This method fetches stored blobs from IndexedDB.
       * @method
       * @memberof DiskStorage
       * @internal
       * @example
       * DiskStorage.Fetch(function(dataURL, type) {
       *     if(type === 'audioBlob') { }
       *     if(type === 'videoBlob') { }
       *     if(type === 'gifBlob')   { }
       * });
       */
      Fetch: function(callback) {
        this.callback = callback;
        this.init();
        return this;
      },
      /**
       * This method stores blobs in IndexedDB.
       * @method
       * @memberof DiskStorage
       * @internal
       * @example
       * DiskStorage.Store({
       *     audioBlob: yourAudioBlob,
       *     videoBlob: yourVideoBlob,
       *     gifBlob  : yourGifBlob
       * });
       */
      Store: function(config) {
        this.audioBlob = config.audioBlob;
        this.videoBlob = config.videoBlob;
        this.gifBlob = config.gifBlob;
        this.init();
        return this;
      },
      /**
       * This function is invoked for any known/unknown error.
       * @method
       * @memberof DiskStorage
       * @internal
       * @example
       * DiskStorage.onError = function(error){
       *     alerot( JSON.stringify(error) );
       * };
       */
      onError: function(error) {
        console.error(JSON.stringify(error, null, "	"));
      },
      /**
       * @property {string} dataStoreName - Name of the ObjectStore created in IndexedDB storage.
       * @memberof DiskStorage
       * @internal
       * @example
       * DiskStorage.dataStoreName = 'recordRTC';
       */
      dataStoreName: "recordRTC",
      dbName: null
    };
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.DiskStorage = DiskStorage;
    }
    function GifRecorder(mediaStream, config) {
      if (typeof GIFEncoder === "undefined") {
        var script = document.createElement("script");
        script.src = "https://www.webrtc-experiment.com/gif-recorder.js";
        (document.body || document.documentElement).appendChild(script);
      }
      config = config || {};
      var isHTMLObject = mediaStream instanceof CanvasRenderingContext2D || mediaStream instanceof HTMLCanvasElement;
      this.record = function() {
        if (typeof GIFEncoder === "undefined") {
          setTimeout(self.record, 1e3);
          return;
        }
        if (!isLoadedMetaData) {
          setTimeout(self.record, 1e3);
          return;
        }
        if (!isHTMLObject) {
          if (!config.width) {
            config.width = video.offsetWidth || 320;
          }
          if (!config.height) {
            config.height = video.offsetHeight || 240;
          }
          if (!config.video) {
            config.video = {
              width: config.width,
              height: config.height
            };
          }
          if (!config.canvas) {
            config.canvas = {
              width: config.width,
              height: config.height
            };
          }
          canvas.width = config.canvas.width || 320;
          canvas.height = config.canvas.height || 240;
          video.width = config.video.width || 320;
          video.height = config.video.height || 240;
        }
        gifEncoder = new GIFEncoder();
        gifEncoder.setRepeat(0);
        gifEncoder.setDelay(config.frameRate || 200);
        gifEncoder.setQuality(config.quality || 10);
        gifEncoder.start();
        if (typeof config.onGifRecordingStarted === "function") {
          config.onGifRecordingStarted();
        }
        startTime = Date.now();
        function drawVideoFrame(time) {
          if (self.clearedRecordedData === true) {
            return;
          }
          if (isPausedRecording) {
            return setTimeout(function() {
              drawVideoFrame(time);
            }, 100);
          }
          lastAnimationFrame = requestAnimationFrame2(drawVideoFrame);
          if (typeof lastFrameTime === void 0) {
            lastFrameTime = time;
          }
          if (time - lastFrameTime < 90) {
            return;
          }
          if (!isHTMLObject && video.paused) {
            video.play();
          }
          if (!isHTMLObject) {
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
          }
          if (config.onGifPreview) {
            config.onGifPreview(canvas.toDataURL("image/png"));
          }
          gifEncoder.addFrame(context);
          lastFrameTime = time;
        }
        lastAnimationFrame = requestAnimationFrame2(drawVideoFrame);
        if (config.initCallback) {
          config.initCallback();
        }
      };
      this.stop = function(callback) {
        callback = callback || function() {
        };
        if (lastAnimationFrame) {
          cancelAnimationFrame(lastAnimationFrame);
        }
        endTime = Date.now();
        this.blob = new Blob([new Uint8Array(gifEncoder.stream().bin)], {
          type: "image/gif"
        });
        callback(this.blob);
        gifEncoder.stream().bin = [];
      };
      var isPausedRecording = false;
      this.pause = function() {
        isPausedRecording = true;
      };
      this.resume = function() {
        isPausedRecording = false;
      };
      this.clearRecordedData = function() {
        self.clearedRecordedData = true;
        clearRecordedDataCB();
      };
      function clearRecordedDataCB() {
        if (gifEncoder) {
          gifEncoder.stream().bin = [];
        }
      }
      this.name = "GifRecorder";
      this.toString = function() {
        return this.name;
      };
      var canvas = document.createElement("canvas");
      var context = canvas.getContext("2d");
      if (isHTMLObject) {
        if (mediaStream instanceof CanvasRenderingContext2D) {
          context = mediaStream;
          canvas = context.canvas;
        } else if (mediaStream instanceof HTMLCanvasElement) {
          context = mediaStream.getContext("2d");
          canvas = mediaStream;
        }
      }
      var isLoadedMetaData = true;
      if (!isHTMLObject) {
        var video = document.createElement("video");
        video.muted = true;
        video.autoplay = true;
        video.playsInline = true;
        isLoadedMetaData = false;
        video.onloadedmetadata = function() {
          isLoadedMetaData = true;
        };
        setSrcObject(mediaStream, video);
        video.play();
      }
      var lastAnimationFrame = null;
      var startTime, endTime, lastFrameTime;
      var gifEncoder;
      var self = this;
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.GifRecorder = GifRecorder;
    }
    function MultiStreamsMixer(arrayOfMediaStreams, elementClass) {
      var browserFakeUserAgent2 = "Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45";
      (function(that) {
        if (typeof RecordRTC2 !== "undefined") {
          return;
        }
        if (!that) {
          return;
        }
        if (typeof window !== "undefined") {
          return;
        }
        if (typeof global === "undefined") {
          return;
        }
        global.navigator = {
          userAgent: browserFakeUserAgent2,
          getUserMedia: function() {
          }
        };
        if (!global.console) {
          global.console = {};
        }
        if (typeof global.console.log === "undefined" || typeof global.console.error === "undefined") {
          global.console.error = global.console.log = global.console.log || function() {
            console.log(arguments);
          };
        }
        if (typeof document === "undefined") {
          that.document = {
            documentElement: {
              appendChild: function() {
                return "";
              }
            }
          };
          document.createElement = document.captureStream = document.mozCaptureStream = function() {
            var obj = {
              getContext: function() {
                return obj;
              },
              play: function() {
              },
              pause: function() {
              },
              drawImage: function() {
              },
              toDataURL: function() {
                return "";
              },
              style: {}
            };
            return obj;
          };
          that.HTMLVideoElement = function() {
          };
        }
        if (typeof location === "undefined") {
          that.location = {
            protocol: "file:",
            href: "",
            hash: ""
          };
        }
        if (typeof screen === "undefined") {
          that.screen = {
            width: 0,
            height: 0
          };
        }
        if (typeof URL3 === "undefined") {
          that.URL = {
            createObjectURL: function() {
              return "";
            },
            revokeObjectURL: function() {
              return "";
            }
          };
        }
        that.window = global;
      })(typeof global !== "undefined" ? global : null);
      elementClass = elementClass || "multi-streams-mixer";
      var videos = [];
      var isStopDrawingFrames = false;
      var canvas = document.createElement("canvas");
      var context = canvas.getContext("2d");
      canvas.style.opacity = 0;
      canvas.style.position = "absolute";
      canvas.style.zIndex = -1;
      canvas.style.top = "-1000em";
      canvas.style.left = "-1000em";
      canvas.className = elementClass;
      (document.body || document.documentElement).appendChild(canvas);
      this.disableLogs = false;
      this.frameInterval = 10;
      this.width = 360;
      this.height = 240;
      this.useGainNode = true;
      var self = this;
      var AudioContext2 = window.AudioContext;
      if (typeof AudioContext2 === "undefined") {
        if (typeof webkitAudioContext !== "undefined") {
          AudioContext2 = webkitAudioContext;
        }
        if (typeof mozAudioContext !== "undefined") {
          AudioContext2 = mozAudioContext;
        }
      }
      var URL3 = window.URL;
      if (typeof URL3 === "undefined" && typeof webkitURL !== "undefined") {
        URL3 = webkitURL;
      }
      if (typeof navigator !== "undefined" && typeof navigator.getUserMedia === "undefined") {
        if (typeof navigator.webkitGetUserMedia !== "undefined") {
          navigator.getUserMedia = navigator.webkitGetUserMedia;
        }
        if (typeof navigator.mozGetUserMedia !== "undefined") {
          navigator.getUserMedia = navigator.mozGetUserMedia;
        }
      }
      var MediaStream2 = window.MediaStream;
      if (typeof MediaStream2 === "undefined" && typeof webkitMediaStream !== "undefined") {
        MediaStream2 = webkitMediaStream;
      }
      if (typeof MediaStream2 !== "undefined") {
        if (typeof MediaStream2.prototype.stop === "undefined") {
          MediaStream2.prototype.stop = function() {
            this.getTracks().forEach(function(track) {
              track.stop();
            });
          };
        }
      }
      var Storage2 = {};
      if (typeof AudioContext2 !== "undefined") {
        Storage2.AudioContext = AudioContext2;
      } else if (typeof webkitAudioContext !== "undefined") {
        Storage2.AudioContext = webkitAudioContext;
      }
      function setSrcObject2(stream, element) {
        if ("srcObject" in element) {
          element.srcObject = stream;
        } else if ("mozSrcObject" in element) {
          element.mozSrcObject = stream;
        } else {
          element.srcObject = stream;
        }
      }
      this.startDrawingFrames = function() {
        drawVideosToCanvas();
      };
      function drawVideosToCanvas() {
        if (isStopDrawingFrames) {
          return;
        }
        var videosLength = videos.length;
        var fullcanvas = false;
        var remaining = [];
        videos.forEach(function(video) {
          if (!video.stream) {
            video.stream = {};
          }
          if (video.stream.fullcanvas) {
            fullcanvas = video;
          } else {
            remaining.push(video);
          }
        });
        if (fullcanvas) {
          canvas.width = fullcanvas.stream.width;
          canvas.height = fullcanvas.stream.height;
        } else if (remaining.length) {
          canvas.width = videosLength > 1 ? remaining[0].width * 2 : remaining[0].width;
          var height = 1;
          if (videosLength === 3 || videosLength === 4) {
            height = 2;
          }
          if (videosLength === 5 || videosLength === 6) {
            height = 3;
          }
          if (videosLength === 7 || videosLength === 8) {
            height = 4;
          }
          if (videosLength === 9 || videosLength === 10) {
            height = 5;
          }
          canvas.height = remaining[0].height * height;
        } else {
          canvas.width = self.width || 360;
          canvas.height = self.height || 240;
        }
        if (fullcanvas && fullcanvas instanceof HTMLVideoElement) {
          drawImage(fullcanvas);
        }
        remaining.forEach(function(video, idx) {
          drawImage(video, idx);
        });
        setTimeout(drawVideosToCanvas, self.frameInterval);
      }
      function drawImage(video, idx) {
        if (isStopDrawingFrames) {
          return;
        }
        var x = 0;
        var y = 0;
        var width = video.width;
        var height = video.height;
        if (idx === 1) {
          x = video.width;
        }
        if (idx === 2) {
          y = video.height;
        }
        if (idx === 3) {
          x = video.width;
          y = video.height;
        }
        if (idx === 4) {
          y = video.height * 2;
        }
        if (idx === 5) {
          x = video.width;
          y = video.height * 2;
        }
        if (idx === 6) {
          y = video.height * 3;
        }
        if (idx === 7) {
          x = video.width;
          y = video.height * 3;
        }
        if (typeof video.stream.left !== "undefined") {
          x = video.stream.left;
        }
        if (typeof video.stream.top !== "undefined") {
          y = video.stream.top;
        }
        if (typeof video.stream.width !== "undefined") {
          width = video.stream.width;
        }
        if (typeof video.stream.height !== "undefined") {
          height = video.stream.height;
        }
        context.drawImage(video, x, y, width, height);
        if (typeof video.stream.onRender === "function") {
          video.stream.onRender(context, x, y, width, height, idx);
        }
      }
      function getMixedStream() {
        isStopDrawingFrames = false;
        var mixedVideoStream = getMixedVideoStream();
        var mixedAudioStream = getMixedAudioStream();
        if (mixedAudioStream) {
          mixedAudioStream.getTracks().filter(function(t) {
            return t.kind === "audio";
          }).forEach(function(track) {
            mixedVideoStream.addTrack(track);
          });
        }
        var fullcanvas;
        arrayOfMediaStreams.forEach(function(stream) {
          if (stream.fullcanvas) {
            fullcanvas = true;
          }
        });
        return mixedVideoStream;
      }
      function getMixedVideoStream() {
        resetVideoStreams();
        var capturedStream;
        if ("captureStream" in canvas) {
          capturedStream = canvas.captureStream();
        } else if ("mozCaptureStream" in canvas) {
          capturedStream = canvas.mozCaptureStream();
        } else if (!self.disableLogs) {
          console.error("Upgrade to latest Chrome or otherwise enable this flag: chrome://flags/#enable-experimental-web-platform-features");
        }
        var videoStream = new MediaStream2();
        capturedStream.getTracks().filter(function(t) {
          return t.kind === "video";
        }).forEach(function(track) {
          videoStream.addTrack(track);
        });
        canvas.stream = videoStream;
        return videoStream;
      }
      function getMixedAudioStream() {
        if (!Storage2.AudioContextConstructor) {
          Storage2.AudioContextConstructor = new Storage2.AudioContext();
        }
        self.audioContext = Storage2.AudioContextConstructor;
        self.audioSources = [];
        if (self.useGainNode === true) {
          self.gainNode = self.audioContext.createGain();
          self.gainNode.connect(self.audioContext.destination);
          self.gainNode.gain.value = 0;
        }
        var audioTracksLength = 0;
        arrayOfMediaStreams.forEach(function(stream) {
          if (!stream.getTracks().filter(function(t) {
            return t.kind === "audio";
          }).length) {
            return;
          }
          audioTracksLength++;
          var audioSource = self.audioContext.createMediaStreamSource(stream);
          if (self.useGainNode === true) {
            audioSource.connect(self.gainNode);
          }
          self.audioSources.push(audioSource);
        });
        if (!audioTracksLength) {
          return;
        }
        self.audioDestination = self.audioContext.createMediaStreamDestination();
        self.audioSources.forEach(function(audioSource) {
          audioSource.connect(self.audioDestination);
        });
        return self.audioDestination.stream;
      }
      function getVideo(stream) {
        var video = document.createElement("video");
        setSrcObject2(stream, video);
        video.className = elementClass;
        video.muted = true;
        video.volume = 0;
        video.width = stream.width || self.width || 360;
        video.height = stream.height || self.height || 240;
        video.play();
        return video;
      }
      this.appendStreams = function(streams) {
        if (!streams) {
          throw "First parameter is required.";
        }
        if (!(streams instanceof Array)) {
          streams = [streams];
        }
        streams.forEach(function(stream) {
          var newStream = new MediaStream2();
          if (stream.getTracks().filter(function(t) {
            return t.kind === "video";
          }).length) {
            var video = getVideo(stream);
            video.stream = stream;
            videos.push(video);
            newStream.addTrack(stream.getTracks().filter(function(t) {
              return t.kind === "video";
            })[0]);
          }
          if (stream.getTracks().filter(function(t) {
            return t.kind === "audio";
          }).length) {
            var audioSource = self.audioContext.createMediaStreamSource(stream);
            self.audioDestination = self.audioContext.createMediaStreamDestination();
            audioSource.connect(self.audioDestination);
            newStream.addTrack(self.audioDestination.stream.getTracks().filter(function(t) {
              return t.kind === "audio";
            })[0]);
          }
          arrayOfMediaStreams.push(newStream);
        });
      };
      this.releaseStreams = function() {
        videos = [];
        isStopDrawingFrames = true;
        if (self.gainNode) {
          self.gainNode.disconnect();
          self.gainNode = null;
        }
        if (self.audioSources.length) {
          self.audioSources.forEach(function(source) {
            source.disconnect();
          });
          self.audioSources = [];
        }
        if (self.audioDestination) {
          self.audioDestination.disconnect();
          self.audioDestination = null;
        }
        if (self.audioContext) {
          self.audioContext.close();
        }
        self.audioContext = null;
        context.clearRect(0, 0, canvas.width, canvas.height);
        if (canvas.stream) {
          canvas.stream.stop();
          canvas.stream = null;
        }
      };
      this.resetVideoStreams = function(streams) {
        if (streams && !(streams instanceof Array)) {
          streams = [streams];
        }
        resetVideoStreams(streams);
      };
      function resetVideoStreams(streams) {
        videos = [];
        streams = streams || arrayOfMediaStreams;
        streams.forEach(function(stream) {
          if (!stream.getTracks().filter(function(t) {
            return t.kind === "video";
          }).length) {
            return;
          }
          var video = getVideo(stream);
          video.stream = stream;
          videos.push(video);
        });
      }
      this.name = "MultiStreamsMixer";
      this.toString = function() {
        return this.name;
      };
      this.getMixedStream = getMixedStream;
    }
    if (typeof RecordRTC2 === "undefined") {
      if (typeof module2 !== "undefined") {
        module2.exports = MultiStreamsMixer;
      }
      if (typeof define === "function" && define.amd) {
        define("MultiStreamsMixer", [], function() {
          return MultiStreamsMixer;
        });
      }
    }
    function MultiStreamRecorder(arrayOfMediaStreams, options) {
      arrayOfMediaStreams = arrayOfMediaStreams || [];
      var self = this;
      var mixer;
      var mediaRecorder;
      options = options || {
        elementClass: "multi-streams-mixer",
        mimeType: "video/webm",
        video: {
          width: 360,
          height: 240
        }
      };
      if (!options.frameInterval) {
        options.frameInterval = 10;
      }
      if (!options.video) {
        options.video = {};
      }
      if (!options.video.width) {
        options.video.width = 360;
      }
      if (!options.video.height) {
        options.video.height = 240;
      }
      this.record = function() {
        mixer = new MultiStreamsMixer(arrayOfMediaStreams, options.elementClass || "multi-streams-mixer");
        if (getAllVideoTracks().length) {
          mixer.frameInterval = options.frameInterval || 10;
          mixer.width = options.video.width || 360;
          mixer.height = options.video.height || 240;
          mixer.startDrawingFrames();
        }
        if (options.previewStream && typeof options.previewStream === "function") {
          options.previewStream(mixer.getMixedStream());
        }
        mediaRecorder = new MediaStreamRecorder(mixer.getMixedStream(), options);
        mediaRecorder.record();
      };
      function getAllVideoTracks() {
        var tracks = [];
        arrayOfMediaStreams.forEach(function(stream) {
          getTracks(stream, "video").forEach(function(track) {
            tracks.push(track);
          });
        });
        return tracks;
      }
      this.stop = function(callback) {
        if (!mediaRecorder) {
          return;
        }
        mediaRecorder.stop(function(blob) {
          self.blob = blob;
          callback(blob);
          self.clearRecordedData();
        });
      };
      this.pause = function() {
        if (mediaRecorder) {
          mediaRecorder.pause();
        }
      };
      this.resume = function() {
        if (mediaRecorder) {
          mediaRecorder.resume();
        }
      };
      this.clearRecordedData = function() {
        if (mediaRecorder) {
          mediaRecorder.clearRecordedData();
          mediaRecorder = null;
        }
        if (mixer) {
          mixer.releaseStreams();
          mixer = null;
        }
      };
      this.addStreams = function(streams) {
        if (!streams) {
          throw "First parameter is required.";
        }
        if (!(streams instanceof Array)) {
          streams = [streams];
        }
        arrayOfMediaStreams.concat(streams);
        if (!mediaRecorder || !mixer) {
          return;
        }
        mixer.appendStreams(streams);
        if (options.previewStream && typeof options.previewStream === "function") {
          options.previewStream(mixer.getMixedStream());
        }
      };
      this.resetVideoStreams = function(streams) {
        if (!mixer) {
          return;
        }
        if (streams && !(streams instanceof Array)) {
          streams = [streams];
        }
        mixer.resetVideoStreams(streams);
      };
      this.getMixer = function() {
        return mixer;
      };
      this.name = "MultiStreamRecorder";
      this.toString = function() {
        return this.name;
      };
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.MultiStreamRecorder = MultiStreamRecorder;
    }
    function RecordRTCPromisesHandler(mediaStream, options) {
      if (!this) {
        throw 'Use "new RecordRTCPromisesHandler()"';
      }
      if (typeof mediaStream === "undefined") {
        throw 'First argument "MediaStream" is required.';
      }
      var self = this;
      self.recordRTC = new RecordRTC2(mediaStream, options);
      this.startRecording = function() {
        return new Promise(function(resolve, reject) {
          try {
            self.recordRTC.startRecording();
            resolve();
          } catch (e) {
            reject(e);
          }
        });
      };
      this.stopRecording = function() {
        return new Promise(function(resolve, reject) {
          try {
            self.recordRTC.stopRecording(function(url) {
              self.blob = self.recordRTC.getBlob();
              if (!self.blob || !self.blob.size) {
                reject("Empty blob.", self.blob);
                return;
              }
              resolve(url);
            });
          } catch (e) {
            reject(e);
          }
        });
      };
      this.pauseRecording = function() {
        return new Promise(function(resolve, reject) {
          try {
            self.recordRTC.pauseRecording();
            resolve();
          } catch (e) {
            reject(e);
          }
        });
      };
      this.resumeRecording = function() {
        return new Promise(function(resolve, reject) {
          try {
            self.recordRTC.resumeRecording();
            resolve();
          } catch (e) {
            reject(e);
          }
        });
      };
      this.getDataURL = function(callback) {
        return new Promise(function(resolve, reject) {
          try {
            self.recordRTC.getDataURL(function(dataURL) {
              resolve(dataURL);
            });
          } catch (e) {
            reject(e);
          }
        });
      };
      this.getBlob = function() {
        return new Promise(function(resolve, reject) {
          try {
            resolve(self.recordRTC.getBlob());
          } catch (e) {
            reject(e);
          }
        });
      };
      this.getInternalRecorder = function() {
        return new Promise(function(resolve, reject) {
          try {
            resolve(self.recordRTC.getInternalRecorder());
          } catch (e) {
            reject(e);
          }
        });
      };
      this.reset = function() {
        return new Promise(function(resolve, reject) {
          try {
            resolve(self.recordRTC.reset());
          } catch (e) {
            reject(e);
          }
        });
      };
      this.destroy = function() {
        return new Promise(function(resolve, reject) {
          try {
            resolve(self.recordRTC.destroy());
          } catch (e) {
            reject(e);
          }
        });
      };
      this.getState = function() {
        return new Promise(function(resolve, reject) {
          try {
            resolve(self.recordRTC.getState());
          } catch (e) {
            reject(e);
          }
        });
      };
      this.blob = null;
      this.version = "5.6.2";
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.RecordRTCPromisesHandler = RecordRTCPromisesHandler;
    }
    function WebAssemblyRecorder(stream, config) {
      if (typeof ReadableStream === "undefined" || typeof WritableStream === "undefined") {
        console.error("Following polyfill is strongly recommended: https://unpkg.com/@mattiasbuelens/web-streams-polyfill/dist/polyfill.min.js");
      }
      config = config || {};
      config.width = config.width || 640;
      config.height = config.height || 480;
      config.frameRate = config.frameRate || 30;
      config.bitrate = config.bitrate || 1200;
      config.realtime = config.realtime || true;
      function createBufferURL(buffer, type) {
        return URL2.createObjectURL(new Blob([buffer], {
          type: type || ""
        }));
      }
      var finished;
      function cameraStream() {
        return new ReadableStream({
          start: function(controller) {
            var cvs = document.createElement("canvas");
            var video = document.createElement("video");
            var first = true;
            video.srcObject = stream;
            video.muted = true;
            video.height = config.height;
            video.width = config.width;
            video.volume = 0;
            video.onplaying = function() {
              cvs.width = config.width;
              cvs.height = config.height;
              var ctx = cvs.getContext("2d");
              var frameTimeout = 1e3 / config.frameRate;
              var cameraTimer = setInterval(function f() {
                if (finished) {
                  clearInterval(cameraTimer);
                  controller.close();
                }
                if (first) {
                  first = false;
                  if (config.onVideoProcessStarted) {
                    config.onVideoProcessStarted();
                  }
                }
                ctx.drawImage(video, 0, 0);
                if (controller._controlledReadableStream.state !== "closed") {
                  try {
                    controller.enqueue(
                      ctx.getImageData(0, 0, config.width, config.height)
                    );
                  } catch (e) {
                  }
                }
              }, frameTimeout);
            };
            video.play();
          }
        });
      }
      var worker;
      function startRecording(stream2, buffer) {
        if (!config.workerPath && !buffer) {
          finished = false;
          fetch(
            "https://unpkg.com/webm-wasm@latest/dist/webm-worker.js"
          ).then(function(r) {
            r.arrayBuffer().then(function(buffer2) {
              startRecording(stream2, buffer2);
            });
          });
          return;
        }
        if (!config.workerPath && buffer instanceof ArrayBuffer) {
          var blob = new Blob([buffer], {
            type: "text/javascript"
          });
          config.workerPath = URL2.createObjectURL(blob);
        }
        if (!config.workerPath) {
          console.error("workerPath parameter is missing.");
        }
        worker = new Worker(config.workerPath);
        worker.postMessage(config.webAssemblyPath || "https://unpkg.com/webm-wasm@latest/dist/webm-wasm.wasm");
        worker.addEventListener("message", function(event2) {
          if (event2.data === "READY") {
            worker.postMessage({
              width: config.width,
              height: config.height,
              bitrate: config.bitrate || 1200,
              timebaseDen: config.frameRate || 30,
              realtime: config.realtime
            });
            cameraStream().pipeTo(new WritableStream({
              write: function(image) {
                if (finished) {
                  console.error("Got image, but recorder is finished!");
                  return;
                }
                worker.postMessage(image.data.buffer, [image.data.buffer]);
              }
            }));
          } else if (!!event2.data) {
            if (!isPaused) {
              arrayOfBuffers.push(event2.data);
            }
          }
        });
      }
      this.record = function() {
        arrayOfBuffers = [];
        isPaused = false;
        this.blob = null;
        startRecording(stream);
        if (typeof config.initCallback === "function") {
          config.initCallback();
        }
      };
      var isPaused;
      this.pause = function() {
        isPaused = true;
      };
      this.resume = function() {
        isPaused = false;
      };
      function terminate(callback) {
        if (!worker) {
          if (callback) {
            callback();
          }
          return;
        }
        worker.addEventListener("message", function(event2) {
          if (event2.data === null) {
            worker.terminate();
            worker = null;
            if (callback) {
              callback();
            }
          }
        });
        worker.postMessage(null);
      }
      var arrayOfBuffers = [];
      this.stop = function(callback) {
        finished = true;
        var recorder = this;
        terminate(function() {
          recorder.blob = new Blob(arrayOfBuffers, {
            type: "video/webm"
          });
          callback(recorder.blob);
        });
      };
      this.name = "WebAssemblyRecorder";
      this.toString = function() {
        return this.name;
      };
      this.clearRecordedData = function() {
        arrayOfBuffers = [];
        isPaused = false;
        this.blob = null;
      };
      this.blob = null;
    }
    if (typeof RecordRTC2 !== "undefined") {
      RecordRTC2.WebAssemblyRecorder = WebAssemblyRecorder;
    }
  }
});

// src/main.ts
var main_exports = {};
__export(main_exports, {
  default: () => NeuroVoxPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian14 = require("obsidian");

// src/utils/VideoProcessor.ts
var import_obsidian2 = require("obsidian");

// node_modules/@ffmpeg/ffmpeg/dist/esm/const.js
var CORE_VERSION = "0.12.6";
var CORE_URL = `https://unpkg.com/@ffmpeg/core@${CORE_VERSION}/dist/umd/ffmpeg-core.js`;
var FFMessageType;
(function(FFMessageType2) {
  FFMessageType2["LOAD"] = "LOAD";
  FFMessageType2["EXEC"] = "EXEC";
  FFMessageType2["WRITE_FILE"] = "WRITE_FILE";
  FFMessageType2["READ_FILE"] = "READ_FILE";
  FFMessageType2["DELETE_FILE"] = "DELETE_FILE";
  FFMessageType2["RENAME"] = "RENAME";
  FFMessageType2["CREATE_DIR"] = "CREATE_DIR";
  FFMessageType2["LIST_DIR"] = "LIST_DIR";
  FFMessageType2["DELETE_DIR"] = "DELETE_DIR";
  FFMessageType2["ERROR"] = "ERROR";
  FFMessageType2["DOWNLOAD"] = "DOWNLOAD";
  FFMessageType2["PROGRESS"] = "PROGRESS";
  FFMessageType2["LOG"] = "LOG";
  FFMessageType2["MOUNT"] = "MOUNT";
  FFMessageType2["UNMOUNT"] = "UNMOUNT";
})(FFMessageType || (FFMessageType = {}));

// node_modules/@ffmpeg/ffmpeg/dist/esm/utils.js
var getMessageID = (() => {
  let messageID = 0;
  return () => messageID++;
})();

// node_modules/@ffmpeg/ffmpeg/dist/esm/errors.js
var ERROR_UNKNOWN_MESSAGE_TYPE = new Error("unknown message type");
var ERROR_NOT_LOADED = new Error("ffmpeg is not loaded, call `await ffmpeg.load()` first");
var ERROR_TERMINATED = new Error("called FFmpeg.terminate()");
var ERROR_IMPORT_FAILURE = new Error("failed to import ffmpeg-core.js");

// node_modules/@ffmpeg/ffmpeg/dist/esm/classes.js
var import_meta = {};
var _worker, _resolves, _rejects, _logEventCallbacks, _progressEventCallbacks, _registerHandlers, _send;
var FFmpeg = class {
  constructor() {
    __privateAdd(this, _worker, null);
    /**
     * #resolves and #rejects tracks Promise resolves and rejects to
     * be called when we receive message from web worker.
     */
    __privateAdd(this, _resolves, {});
    __privateAdd(this, _rejects, {});
    __privateAdd(this, _logEventCallbacks, []);
    __privateAdd(this, _progressEventCallbacks, []);
    __publicField(this, "loaded", false);
    /**
     * register worker message event handlers.
     */
    __privateAdd(this, _registerHandlers, () => {
      if (__privateGet(this, _worker)) {
        __privateGet(this, _worker).onmessage = ({ data: { id, type, data } }) => {
          switch (type) {
            case FFMessageType.LOAD:
              this.loaded = true;
              __privateGet(this, _resolves)[id](data);
              break;
            case FFMessageType.MOUNT:
            case FFMessageType.UNMOUNT:
            case FFMessageType.EXEC:
            case FFMessageType.WRITE_FILE:
            case FFMessageType.READ_FILE:
            case FFMessageType.DELETE_FILE:
            case FFMessageType.RENAME:
            case FFMessageType.CREATE_DIR:
            case FFMessageType.LIST_DIR:
            case FFMessageType.DELETE_DIR:
              __privateGet(this, _resolves)[id](data);
              break;
            case FFMessageType.LOG:
              __privateGet(this, _logEventCallbacks).forEach((f) => f(data));
              break;
            case FFMessageType.PROGRESS:
              __privateGet(this, _progressEventCallbacks).forEach((f) => f(data));
              break;
            case FFMessageType.ERROR:
              __privateGet(this, _rejects)[id](data);
              break;
          }
          delete __privateGet(this, _resolves)[id];
          delete __privateGet(this, _rejects)[id];
        };
      }
    });
    /**
     * Generic function to send messages to web worker.
     */
    __privateAdd(this, _send, ({ type, data }, trans = [], signal) => {
      if (!__privateGet(this, _worker)) {
        return Promise.reject(ERROR_NOT_LOADED);
      }
      return new Promise((resolve, reject) => {
        const id = getMessageID();
        __privateGet(this, _worker) && __privateGet(this, _worker).postMessage({ id, type, data }, trans);
        __privateGet(this, _resolves)[id] = resolve;
        __privateGet(this, _rejects)[id] = reject;
        signal == null ? void 0 : signal.addEventListener("abort", () => {
          reject(new DOMException(`Message # ${id} was aborted`, "AbortError"));
        }, { once: true });
      });
    });
    /**
     * Loads ffmpeg-core inside web worker. It is required to call this method first
     * as it initializes WebAssembly and other essential variables.
     *
     * @category FFmpeg
     * @returns `true` if ffmpeg core is loaded for the first time.
     */
    __publicField(this, "load", ({ classWorkerURL, ...config } = {}, { signal } = {}) => {
      if (!__privateGet(this, _worker)) {
        __privateSet(this, _worker, classWorkerURL ? new Worker(new URL(classWorkerURL, import_meta.url), {
          type: "module"
        }) : (
          // We need to duplicated the code here to enable webpack
          // to bundle worekr.js here.
          new Worker(new URL("./worker.js", import_meta.url), {
            type: "module"
          })
        ));
        __privateGet(this, _registerHandlers).call(this);
      }
      return __privateGet(this, _send).call(this, {
        type: FFMessageType.LOAD,
        data: config
      }, void 0, signal);
    });
    /**
     * Execute ffmpeg command.
     *
     * @remarks
     * To avoid common I/O issues, ["-nostdin", "-y"] are prepended to the args
     * by default.
     *
     * @example
     * ```ts
     * const ffmpeg = new FFmpeg();
     * await ffmpeg.load();
     * await ffmpeg.writeFile("video.avi", ...);
     * // ffmpeg -i video.avi video.mp4
     * await ffmpeg.exec(["-i", "video.avi", "video.mp4"]);
     * const data = ffmpeg.readFile("video.mp4");
     * ```
     *
     * @returns `0` if no error, `!= 0` if timeout (1) or error.
     * @category FFmpeg
     */
    __publicField(this, "exec", (args, timeout = -1, { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.EXEC,
      data: { args, timeout }
    }, void 0, signal));
    /**
     * Terminate all ongoing API calls and terminate web worker.
     * `FFmpeg.load()` must be called again before calling any other APIs.
     *
     * @category FFmpeg
     */
    __publicField(this, "terminate", () => {
      const ids = Object.keys(__privateGet(this, _rejects));
      for (const id of ids) {
        __privateGet(this, _rejects)[id](ERROR_TERMINATED);
        delete __privateGet(this, _rejects)[id];
        delete __privateGet(this, _resolves)[id];
      }
      if (__privateGet(this, _worker)) {
        __privateGet(this, _worker).terminate();
        __privateSet(this, _worker, null);
        this.loaded = false;
      }
    });
    /**
     * Write data to ffmpeg.wasm.
     *
     * @example
     * ```ts
     * const ffmpeg = new FFmpeg();
     * await ffmpeg.load();
     * await ffmpeg.writeFile("video.avi", await fetchFile("../video.avi"));
     * await ffmpeg.writeFile("text.txt", "hello world");
     * ```
     *
     * @category File System
     */
    __publicField(this, "writeFile", (path, data, { signal } = {}) => {
      const trans = [];
      if (data instanceof Uint8Array) {
        trans.push(data.buffer);
      }
      return __privateGet(this, _send).call(this, {
        type: FFMessageType.WRITE_FILE,
        data: { path, data }
      }, trans, signal);
    });
    __publicField(this, "mount", (fsType, options, mountPoint) => {
      const trans = [];
      return __privateGet(this, _send).call(this, {
        type: FFMessageType.MOUNT,
        data: { fsType, options, mountPoint }
      }, trans);
    });
    __publicField(this, "unmount", (mountPoint) => {
      const trans = [];
      return __privateGet(this, _send).call(this, {
        type: FFMessageType.UNMOUNT,
        data: { mountPoint }
      }, trans);
    });
    /**
     * Read data from ffmpeg.wasm.
     *
     * @example
     * ```ts
     * const ffmpeg = new FFmpeg();
     * await ffmpeg.load();
     * const data = await ffmpeg.readFile("video.mp4");
     * ```
     *
     * @category File System
     */
    __publicField(this, "readFile", (path, encoding = "binary", { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.READ_FILE,
      data: { path, encoding }
    }, void 0, signal));
    /**
     * Delete a file.
     *
     * @category File System
     */
    __publicField(this, "deleteFile", (path, { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.DELETE_FILE,
      data: { path }
    }, void 0, signal));
    /**
     * Rename a file or directory.
     *
     * @category File System
     */
    __publicField(this, "rename", (oldPath, newPath, { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.RENAME,
      data: { oldPath, newPath }
    }, void 0, signal));
    /**
     * Create a directory.
     *
     * @category File System
     */
    __publicField(this, "createDir", (path, { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.CREATE_DIR,
      data: { path }
    }, void 0, signal));
    /**
     * List directory contents.
     *
     * @category File System
     */
    __publicField(this, "listDir", (path, { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.LIST_DIR,
      data: { path }
    }, void 0, signal));
    /**
     * Delete an empty directory.
     *
     * @category File System
     */
    __publicField(this, "deleteDir", (path, { signal } = {}) => __privateGet(this, _send).call(this, {
      type: FFMessageType.DELETE_DIR,
      data: { path }
    }, void 0, signal));
  }
  on(event2, callback) {
    if (event2 === "log") {
      __privateGet(this, _logEventCallbacks).push(callback);
    } else if (event2 === "progress") {
      __privateGet(this, _progressEventCallbacks).push(callback);
    }
  }
  off(event2, callback) {
    if (event2 === "log") {
      __privateSet(this, _logEventCallbacks, __privateGet(this, _logEventCallbacks).filter((f) => f !== callback));
    } else if (event2 === "progress") {
      __privateSet(this, _progressEventCallbacks, __privateGet(this, _progressEventCallbacks).filter((f) => f !== callback));
    }
  }
};
_worker = new WeakMap();
_resolves = new WeakMap();
_rejects = new WeakMap();
_logEventCallbacks = new WeakMap();
_progressEventCallbacks = new WeakMap();
_registerHandlers = new WeakMap();
_send = new WeakMap();

// node_modules/@ffmpeg/util/dist/esm/errors.js
var ERROR_RESPONSE_BODY_READER = new Error("failed to get response body reader");
var ERROR_INCOMPLETED_DOWNLOAD = new Error("failed to complete download");

// node_modules/@ffmpeg/util/dist/esm/const.js
var HeaderContentLength = "Content-Length";

// node_modules/@ffmpeg/util/dist/esm/index.js
var readFromBlobOrFile = (blob) => new Promise((resolve, reject) => {
  const fileReader = new FileReader();
  fileReader.onload = () => {
    const { result } = fileReader;
    if (result instanceof ArrayBuffer) {
      resolve(new Uint8Array(result));
    } else {
      resolve(new Uint8Array());
    }
  };
  fileReader.onerror = (event2) => {
    var _a, _b;
    reject(Error(`File could not be read! Code=${((_b = (_a = event2 == null ? void 0 : event2.target) == null ? void 0 : _a.error) == null ? void 0 : _b.code) || -1}`));
  };
  fileReader.readAsArrayBuffer(blob);
});
var fetchFile = async (file) => {
  let data;
  if (typeof file === "string") {
    if (/data:_data\/([a-zA-Z]*);base64,([^"]*)/.test(file)) {
      data = atob(file.split(",")[1]).split("").map((c) => c.charCodeAt(0));
    } else {
      data = await (await fetch(file)).arrayBuffer();
    }
  } else if (file instanceof URL) {
    data = await (await fetch(file)).arrayBuffer();
  } else if (file instanceof File || file instanceof Blob) {
    data = await readFromBlobOrFile(file);
  } else {
    return new Uint8Array();
  }
  return new Uint8Array(data);
};
var downloadWithProgress = async (url, cb) => {
  var _a;
  const resp = await fetch(url);
  let buf;
  try {
    const total = parseInt(resp.headers.get(HeaderContentLength) || "-1");
    const reader = (_a = resp.body) == null ? void 0 : _a.getReader();
    if (!reader)
      throw ERROR_RESPONSE_BODY_READER;
    const chunks = [];
    let received = 0;
    for (; ; ) {
      const { done, value } = await reader.read();
      const delta = value ? value.length : 0;
      if (done) {
        if (total != -1 && total !== received)
          throw ERROR_INCOMPLETED_DOWNLOAD;
        cb && cb({ url, total, received, delta, done });
        break;
      }
      chunks.push(value);
      received += delta;
      cb && cb({ url, total, received, delta, done });
    }
    const data = new Uint8Array(received);
    let position = 0;
    for (const chunk of chunks) {
      data.set(chunk, position);
      position += chunk.length;
    }
    buf = data.buffer;
  } catch (e) {
    console.log(`failed to send download progress event: `, e);
    buf = await resp.arrayBuffer();
    cb && cb({
      url,
      total: buf.byteLength,
      received: buf.byteLength,
      delta: 0,
      done: true
    });
  }
  return buf;
};
var toBlobURL = async (url, mimeType, progress = false, cb) => {
  const buf = progress ? await downloadWithProgress(url, cb) : await (await fetch(url)).arrayBuffer();
  const blob = new Blob([buf], { type: mimeType });
  return URL.createObjectURL(blob);
};

// src/utils/RecordingProcessor.ts
var import_obsidian = require("obsidian");
var _RecordingProcessor = class {
  // CD quality audio for better fidelity
  constructor(plugin, pluginData) {
    this.plugin = plugin;
    this.pluginData = pluginData;
    this.processingState = {
      isProcessing: false,
      currentStep: null,
      startTime: Date.now()
    };
    this.steps = [];
    this.currentStep = null;
    this.config = {
      maxRetries: 3,
      retryDelay: 1e3
    };
    this.MAX_AUDIO_SIZE_MB = 25;
    this.MAX_AUDIO_SIZE_BYTES = this.MAX_AUDIO_SIZE_MB * 1024 * 1024;
    this.CHUNK_OVERLAP_SECONDS = 2;
    this.SAMPLE_RATE = 44100;
  }
  static getInstance(plugin, pluginData) {
    var _a;
    return (_a = this.instance) != null ? _a : this.instance = new _RecordingProcessor(plugin, pluginData);
  }
  async saveState() {
    try {
      const state = {
        ...this.processingState,
        audioBlob: void 0
      };
      await this.plugin.saveData(state);
    } catch (error) {
    }
  }
  async loadState() {
    try {
      const state = await this.plugin.loadData();
      if (state) {
        this.processingState = { ...state, audioBlob: void 0 };
      }
    } catch (error) {
    }
  }
  async processRecording(audioBlob, activeFile, cursorPosition, audioFilePath, shouldSaveAudio = false) {
    this.processingState.audioBlob = audioBlob;
    this.processingState.startTime = Date.now();
    await this.saveState();
    if (this.processingState.isProcessing) {
      throw new Error("Recording is already in progress.");
    }
    try {
      this.processingState.isProcessing = true;
      await this.saveState();
      this.steps = [];
      await this.validateRequirements();
      let finalPath = audioFilePath || "";
      if (!audioFilePath && shouldSaveAudio) {
        finalPath = await this.saveAudioFile(audioBlob);
      }
      if (audioBlob.size <= this.MAX_AUDIO_SIZE_BYTES) {
        const result = await this.executeProcessingPipelineWithRecovery(audioBlob, finalPath);
        await this.insertResults(result, activeFile, cursorPosition);
      } else {
        await this.processLargeAudioFile(audioBlob, shouldSaveAudio, finalPath, activeFile, cursorPosition);
      }
    } catch (error) {
      this.handleError("Processing failed", error);
      this.processingState.error = error instanceof Error ? error.message : "Unknown error";
      await this.saveState();
      throw error;
    } finally {
      this.cleanup();
    }
  }
  async splitAudioBlob(audioBlob) {
    if (audioBlob.size <= this.MAX_AUDIO_SIZE_BYTES) {
      return [audioBlob];
    }
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const arrayBuffer = await audioBlob.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      const totalDuration = audioBuffer.duration;
      const chunkDuration = Math.floor(totalDuration * (this.MAX_AUDIO_SIZE_BYTES / audioBlob.size));
      const chunks = [];
      for (let startTime = 0; startTime < totalDuration; startTime += chunkDuration) {
        const endTime = Math.min(startTime + chunkDuration + this.CHUNK_OVERLAP_SECONDS, totalDuration);
        const chunkBuffer = audioContext.createBuffer(
          audioBuffer.numberOfChannels,
          Math.ceil((endTime - startTime) * audioBuffer.sampleRate),
          audioBuffer.sampleRate
        );
        for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
          const channelData = audioBuffer.getChannelData(channel);
          const chunkData = chunkBuffer.getChannelData(channel);
          const startSample = Math.floor(startTime * audioBuffer.sampleRate);
          const endSample = Math.ceil(endTime * audioBuffer.sampleRate);
          chunkData.set(channelData.subarray(startSample, endSample));
        }
        const chunk = await new Promise((resolve) => {
          const source = audioContext.createBufferSource();
          source.buffer = chunkBuffer;
          const destination = audioContext.createMediaStreamDestination();
          source.connect(destination);
          const recorder = new MediaRecorder(destination.stream, {
            mimeType: audioBlob.type
          });
          const chunks2 = [];
          recorder.ondataavailable = (e) => {
            if (e.data.size > 0)
              chunks2.push(e.data);
          };
          recorder.onstop = () => {
            resolve(new Blob(chunks2, { type: audioBlob.type }));
          };
          recorder.start();
          source.start(0);
          setTimeout(() => {
            source.stop();
            recorder.stop();
          }, chunkBuffer.duration * 1e3);
        });
        chunks.push(chunk);
      }
      await audioContext.close();
      return chunks;
    } catch (error) {
      return [audioBlob];
    }
  }
  async convertToFloat32Array(arrayBuffer) {
    try {
      return new Float32Array(arrayBuffer);
    } catch (error) {
      const view = new DataView(arrayBuffer);
      const samples = new Float32Array(arrayBuffer.byteLength / 4);
      for (let i = 0; i < samples.length; i++) {
        samples[i] = view.getFloat32(i * 4, true);
      }
      return samples;
    }
  }
  async validateRequirements() {
    const transcriptionAdapter = this.getAdapter(
      this.pluginData.transcriptionProvider,
      "transcription"
    );
    if (this.pluginData.generateSummary) {
      this.getAdapter(this.pluginData.summaryProvider, "language");
    }
    await this.ensureRecordingFolderExists();
  }
  getAdapter(provider, category) {
    const adapter = this.plugin.aiAdapters.get(provider);
    if (!adapter) {
      throw new Error(`${provider} adapter not found`);
    }
    if (!adapter.isReady(category)) {
      const apiKey = adapter.getApiKey();
      if (!apiKey) {
        throw new Error(`${provider} API key is not configured`);
      }
      throw new Error(
        `${provider} adapter is not ready for ${category}. Please check your settings and model availability.`
      );
    }
    return adapter;
  }
  async ensureRecordingFolderExists() {
    const folderPath = this.pluginData.recordingFolderPath;
    if (!folderPath)
      return;
    const parts = folderPath.split("/").filter(Boolean);
    let currentPath = "";
    for (const part of parts) {
      currentPath = currentPath ? `${currentPath}/${part}` : part;
      const folder = this.plugin.app.vault.getAbstractFileByPath(currentPath);
      if (!folder) {
        await this.plugin.app.vault.createFolder(currentPath);
      } else if (!(folder instanceof import_obsidian.TFolder)) {
        throw new Error(`${currentPath} exists but is not a folder`);
      }
    }
  }
  async saveAudioFile(audioBlob) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    const baseFileName = `recording-${timestamp}.webm`;
    const folderPath = this.pluginData.recordingFolderPath || "";
    let fileName = baseFileName;
    let filePath = folderPath ? `${folderPath}/${fileName}` : fileName;
    let count = 1;
    while (await this.plugin.app.vault.adapter.exists(filePath)) {
      fileName = `recording-${timestamp}-${count}.webm`;
      filePath = folderPath ? `${folderPath}/${fileName}` : fileName;
      count++;
    }
    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const file = await this.plugin.app.vault.createBinary(
        filePath,
        new Uint8Array(arrayBuffer)
      );
      if (!file) {
        throw new Error("Failed to create audio file");
      }
      return file.path;
    } catch (error) {
      this.handleError("Failed to save audio file", error);
      throw error;
    }
  }
  async executeProcessingPipeline(audioBlob, audioFilePath) {
    const audioBuffer = await this.executeStep(
      "Audio Conversion",
      async () => await audioBlob.arrayBuffer()
    );
    const transcription = await this.executeStep(
      "Transcription",
      () => this.transcribeAudio(audioBuffer)
    );
    const summary = this.pluginData.generateSummary ? await this.executeStep(
      "Summarization",
      () => this.generateSummary(transcription)
    ) : void 0;
    return {
      transcription,
      summary,
      timings: this.calculateTimings(),
      audioFilePath,
      audioBlob
    };
  }
  async executeProcessingPipelineWithRecovery(audioBlob, audioFilePath) {
    try {
      const result = await this.executeProcessingPipeline(audioBlob, audioFilePath);
      return result;
    } catch (error) {
      if (this.processingState.transcription) {
        return {
          transcription: this.processingState.transcription,
          summary: this.processingState.summary,
          timings: this.calculateTimings(),
          audioFilePath,
          audioBlob
        };
      }
      throw error;
    }
  }
  async concatenateAudioChunks(chunks) {
    try {
      const firstChunk = chunks[0];
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const processedChunks = [];
      for (const chunk of chunks) {
        try {
          const arrayBuffer = await chunk.arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          const source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          const destination = audioContext.createMediaStreamDestination();
          source.connect(destination);
          const recorder = new MediaRecorder(destination.stream, {
            mimeType: firstChunk.type
          });
          const processedData = await new Promise((resolve) => {
            const chunks2 = [];
            recorder.ondataavailable = (e) => {
              if (e.data.size > 0)
                chunks2.push(e.data);
            };
            recorder.onstop = () => {
              resolve(new Blob(chunks2, { type: firstChunk.type }));
            };
            recorder.start();
            source.start(0);
            setTimeout(() => {
              source.stop();
              recorder.stop();
            }, audioBuffer.duration * 1e3);
          });
          processedChunks.push(processedData);
        } catch (error) {
          processedChunks.push(chunk);
        }
      }
      await audioContext.close();
      return new Blob(processedChunks, { type: firstChunk.type });
    } catch (error) {
      return chunks[0];
    }
  }
  async processLargeAudioFile(audioBlob, shouldSaveAudio, audioFilePath, activeFile, cursorPosition) {
    const chunks = await this.splitAudioBlob(audioBlob);
    const allResults = [];
    const chunkPaths = [];
    for (let i = 0; i < chunks.length; i++) {
      try {
        const chunk = chunks[i];
        const chunkPath = audioFilePath ? `${audioFilePath}.part${i}` : shouldSaveAudio ? await this.saveAudioFile(chunk) : "";
        if (chunkPath) {
          chunkPaths.push(chunkPath);
        }
        const result = await this.executeProcessingPipelineWithRecovery(chunk, chunkPath);
        allResults.push(result);
        this.processingState.processedChunks = i + 1;
        this.processingState.totalChunks = chunks.length;
        await this.saveState();
        new import_obsidian.Notice(`Processing chunk ${i + 1} of ${chunks.length}`);
      } catch (error) {
      }
    }
    if (allResults.length > 0) {
      try {
        const concatenatedAudio = await this.concatenateAudioChunks(chunks);
        const finalPath = audioFilePath || (shouldSaveAudio ? await this.saveAudioFile(concatenatedAudio) : "");
        if (shouldSaveAudio) {
          for (const chunkPath of chunkPaths) {
            try {
              await this.plugin.app.vault.adapter.remove(chunkPath);
            } catch (error) {
            }
          }
        }
        const finalResult = {
          transcription: allResults.map((r) => r.transcription).join("\n"),
          summary: allResults.some((r) => r.summary) ? allResults.map((r) => r.summary).filter(Boolean).join("\n") : void 0,
          timings: this.calculateTimings(),
          audioFilePath: finalPath,
          audioBlob: concatenatedAudio
        };
        await this.insertResults(finalResult, activeFile, cursorPosition);
      } catch (error) {
        await this.insertAggregatedResults(allResults, activeFile, cursorPosition);
      }
    } else {
      throw new Error("No chunks were successfully processed");
    }
  }
  async executeStep(stepName, operation, retryCount = 0) {
    this.startStep(stepName);
    try {
      const result = await operation();
      this.completeStep();
      return result;
    } catch (error) {
      if (retryCount < this.config.maxRetries) {
        await new Promise((resolve) => setTimeout(resolve, this.config.retryDelay));
        return this.executeStep(stepName, operation, retryCount + 1);
      }
      this.handleError(`${stepName} failed after ${retryCount} retries`, error);
      throw error;
    }
  }
  async transcribeAudio(audioBuffer) {
    const adapter = this.getAdapter(this.pluginData.transcriptionProvider, "transcription");
    return adapter.transcribeAudio(audioBuffer, this.pluginData.transcriptionModel);
  }
  async generateSummary(transcription) {
    const adapter = this.getAdapter(this.pluginData.summaryProvider, "language");
    const prompt = `${this.pluginData.summaryPrompt}

${transcription}`;
    return adapter.generateResponse(prompt, this.pluginData.summaryModel, {
      maxTokens: this.pluginData.summaryMaxTokens,
      temperature: this.pluginData.summaryTemperature
    });
  }
  formatContent(result) {
    let content = "";
    if (result.audioFilePath) {
      content = this.pluginData.transcriptionCalloutFormat.replace("{audioPath}", result.audioFilePath).replace("{transcription}", result.transcription) + "\n";
    } else {
      content = "> [!note] Transcription\n> " + result.transcription.replace(/\n/g, "\n> ") + "\n";
    }
    if (this.pluginData.generateSummary && result.summary) {
      content += "---\n" + this.pluginData.summaryCalloutFormat.replace("{summary}", result.summary) + "\n\n";
    }
    return content;
  }
  async insertResults(result, file, cursorPosition) {
    const content = this.formatContent(result);
    await this.executeStep("Content Insertion", async () => {
      const fileContent = await this.plugin.app.vault.read(file);
      const updatedContent = this.insertAtPosition(fileContent, content, cursorPosition);
      await this.plugin.app.vault.modify(file, updatedContent);
    });
  }
  async insertAggregatedResults(results, file, cursorPosition) {
    let combinedTranscription = "";
    let combinedSummary = "";
    for (const r of results) {
      combinedTranscription += r.transcription + "\n";
      if (r.summary)
        combinedSummary += r.summary + "\n";
    }
    const merged = {
      transcription: combinedTranscription.trim(),
      summary: combinedSummary.trim() || void 0,
      timings: {},
      audioFilePath: results.map((r) => r.audioFilePath).join(", "),
      audioBlob: new Blob()
    };
    await this.insertResults(merged, file, cursorPosition);
  }
  insertAtPosition(content, newContent, position) {
    const lines = content.split("\n");
    const offset = lines.slice(0, position.line).reduce((acc, line) => acc + line.length + 1, 0) + position.ch;
    return content.slice(0, offset) + newContent + content.slice(offset);
  }
  startStep(name) {
    this.currentStep = { name, startTime: performance.now() };
    this.steps.push(this.currentStep);
  }
  completeStep() {
    if (this.currentStep) {
      this.currentStep.endTime = performance.now();
    }
  }
  calculateTimings() {
    return Object.fromEntries(
      this.steps.filter((step) => step.endTime).map((step) => [step.name, step.endTime - step.startTime])
    );
  }
  handleError(context, error) {
    const message = error instanceof Error ? error.message : "Unknown error occurred";
    new import_obsidian.Notice(`${context}: ${message}`);
  }
  showSuccessMessage() {
    new import_obsidian.Notice(`Recording processed successfully.`);
  }
  deduplicateChunks(results) {
    if (results.length <= 1)
      return results;
    const processed = [results[0]];
    for (let i = 1; i < results.length; i++) {
      const current = results[i];
      const previous = processed[processed.length - 1];
      const overlap = this.findLargestOverlap(
        previous.transcription,
        current.transcription
      );
      if (overlap) {
        current.transcription = current.transcription.substring(overlap.length);
      }
      processed.push(current);
    }
    return processed;
  }
  findLargestOverlap(str1, str2) {
    const minOverlapLength = 10;
    let overlap = "";
    const end1 = str1.slice(-100);
    const start2 = str2.slice(0, 100);
    for (let i = minOverlapLength; i < Math.min(end1.length, start2.length); i++) {
      const endPart = end1.slice(-i);
      if (start2.startsWith(endPart)) {
        overlap = endPart;
      }
    }
    return overlap;
  }
  cleanupTranscription(text) {
    return text.replace(/\s+/g, " ").replace(/(\w)\s+(\W)/g, "$1$2").replace(/(\W)\s+(\w)/g, "$1 $2").replace(/\s+\./g, ".").replace(/\s+,/g, ",").trim();
  }
  cleanup() {
    this.processingState = {
      isProcessing: false,
      currentStep: null,
      startTime: Date.now()
    };
    this.saveState().catch((error) => error);
  }
};
var RecordingProcessor = _RecordingProcessor;
RecordingProcessor.instance = null;

// src/utils/VideoProcessor.ts
var _VideoProcessor = class {
  constructor(plugin, pluginData) {
    this.plugin = plugin;
    this.pluginData = pluginData;
    this.isProcessing = false;
  }
  static async getInstance(plugin, pluginData) {
    if (!this.instance) {
      this.instance = new _VideoProcessor(plugin, pluginData);
      await this.instance.initializeFFmpeg();
    }
    return this.instance;
  }
  async initializeFFmpeg() {
    this.ffmpeg = new FFmpeg();
    const baseURL = "https://unpkg.com/@ffmpeg/core@0.12.6/dist/umd";
    await this.ffmpeg.load({
      coreURL: await toBlobURL(`${baseURL}/ffmpeg-core.js`, "text/javascript"),
      wasmURL: await toBlobURL(`${baseURL}/ffmpeg-core.wasm`, "application/wasm")
    });
  }
  async processVideo(file) {
    if (this.isProcessing) {
      throw new Error("Video processing is already in progress.");
    }
    try {
      this.isProcessing = true;
      new import_obsidian2.Notice("\u{1F3A5} Starting video processing...");
      const transcriptFile = await this.createTranscriptFile(file);
      const audioBuffer = await this.extractAudioFromVideo(file);
      const recordingProcessor = RecordingProcessor.getInstance(this.plugin, this.pluginData);
      const audioBlob = new Blob([audioBuffer], { type: "audio/wav" });
      await recordingProcessor.processRecording(
        audioBlob,
        transcriptFile,
        { line: 0, ch: 0 },
        file.path
      );
      new import_obsidian2.Notice("\u2728 Video transcription completed");
      await this.plugin.app.workspace.getLeaf().openFile(transcriptFile);
    } catch (error) {
      const message = error instanceof Error ? error.message : "Unknown error occurred";
      new import_obsidian2.Notice("\u274C Video processing failed: " + message);
      throw error;
    } finally {
      this.isProcessing = false;
    }
  }
  async createTranscriptFile(videoFile) {
    const baseName = videoFile.basename.replace(/[\\/:*?"<>|]/g, "");
    const fileName = `${baseName} - Video Transcript.md`;
    return this.plugin.app.vault.create(fileName, "");
  }
  async extractAudioFromVideo(file) {
    new import_obsidian2.Notice("\u{1F3B5} Extracting audio from video...");
    try {
      const videoData = await this.plugin.app.vault.readBinary(file);
      const videoBlob = new Blob([videoData], { type: this.getVideoMimeType(file.extension) });
      const videoURL = URL.createObjectURL(videoBlob);
      await this.ffmpeg.writeFile("input." + file.extension, await fetchFile(videoURL));
      await this.ffmpeg.exec([
        "-i",
        "input." + file.extension,
        "-vn",
        // No video
        "-acodec",
        "libmp3lame",
        // MP3 codec
        "-ab",
        "320k",
        // Bitrate
        "-ar",
        "44100",
        // Sample rate
        "-ac",
        "2",
        // Stereo
        "output.mp3"
        // Output file
      ]);
      const data = await this.ffmpeg.readFile("output.mp3");
      URL.revokeObjectURL(videoURL);
      await this.ffmpeg.deleteFile("input." + file.extension);
      await this.ffmpeg.deleteFile("output.mp3");
      return data.buffer;
    } catch (error) {
      const message = error instanceof Error ? error.message : "Unknown error occurred";
      throw new Error("Failed to extract audio: " + message);
    }
  }
  getVideoMimeType(extension) {
    const mimeTypes = {
      "mp4": "video/mp4",
      "webm": "video/webm",
      "mov": "video/quicktime"
    };
    return mimeTypes[extension.toLowerCase()] || "video/mp4";
  }
};
var VideoProcessor = _VideoProcessor;
VideoProcessor.instance = null;

// src/adapters/AIAdapter.ts
var import_obsidian3 = require("obsidian");
var AIModels = {
  ["openai" /* OpenAI */]: [
    { id: "whisper-1", name: "OpenAI", category: "transcription" },
    { id: "gpt-4o", name: "GPT 4o", category: "language", maxTokens: 16e3 },
    { id: "gpt-4o-mini", name: "GPT 4o Mini", category: "language", maxTokens: 16e3 },
    { id: "o1-2024-12-17", name: "o1", category: "language", maxTokens: 1e5 },
    { id: "o1-mini-2024-09-12", name: "o1 Mini", category: "language", maxTokens: 66e3 },
    { id: "o3-mini-2025-31", name: "o3 Mini", category: "language", maxTokens: 1e5 }
  ],
  ["groq" /* Groq */]: [
    { id: "distil-whisper-large-v3-en", name: "Groq", category: "transcription" },
    { id: "gemma2-9b-it", name: "Gemma 2 9B IT", category: "language", maxTokens: 4096 },
    { id: "deepseek-r1-distill-llama-70b", name: "r1", category: "language", maxTokens: 8192 },
    { id: "llama3-groq-70b-8192-tool-use-preview", name: "Llama 3 Groq 70B Versatile", category: "language", maxTokens: 8192 },
    { id: "llama3-groq-8b-8192-tool-use-preview", name: "Llama 3 Groq 8B Instant", category: "language", maxTokens: 4096 },
    { id: "llama-3.1-70b-versatile", name: "Llama 3.1 70b", category: "language", maxTokens: 8192 },
    { id: "llama-3.2-3b-preview", name: "Llama 3.2 3b", category: "language", maxTokens: 8192 },
    { id: "llama-3.2-90b-vision-preview", name: "Llama 3.2 90b", category: "language", maxTokens: 8192 },
    { id: "mixtral-8x7b-32768", name: "Mixtral 8x7b", category: "language", maxTokens: 32768 }
  ]
};
function getModelInfo(modelId) {
  for (const models of Object.values(AIModels)) {
    const model = models.find((m) => m.id === modelId);
    if (model)
      return model;
  }
  return void 0;
}
var AIAdapter = class {
  constructor(settings, provider) {
    this.settings = settings;
    this.provider = provider;
    this.keyValidated = false;
    this.lastValidatedKey = "";
    this.models = AIModels[provider];
  }
  setApiKey(key) {
    const currentKey = this.getApiKey();
    if (key !== currentKey) {
      this.keyValidated = false;
      this.lastValidatedKey = "";
    }
    this.setApiKeyInternal(key);
  }
  async generateResponse(prompt, model, options) {
    try {
      const endpoint = `${this.getApiBaseUrl()}${this.getTextGenerationEndpoint()}`;
      const body = {
        model,
        messages: [{ role: "user", content: prompt }],
        max_tokens: (options == null ? void 0 : options.maxTokens) || 1e3,
        temperature: (options == null ? void 0 : options.temperature) || 0.7
      };
      const response = await this.makeAPIRequest(
        endpoint,
        "POST",
        { "Content-Type": "application/json" },
        JSON.stringify(body)
      );
      return this.parseTextGenerationResponse(response);
    } catch (error) {
      const message = this.getErrorMessage(error);
      throw new Error(`Failed to generate response: ${message}`);
    }
  }
  async transcribeAudio(audioArrayBuffer, model) {
    var _a, _b, _c, _d, _e, _f;
    try {
      const { headers, body } = await this.prepareTranscriptionRequest(audioArrayBuffer, model);
      const endpoint = `${this.getApiBaseUrl()}${this.getTranscriptionEndpoint()}`;
      try {
        const response = await this.makeAPIRequest(
          endpoint,
          "POST",
          headers,
          body
        );
        return this.parseTranscriptionResponse(response);
      } catch (error) {
        if (((_a = error == null ? void 0 : error.response) == null ? void 0 : _a.status) === 400) {
          throw new Error(`Invalid request format: ${((_d = (_c = (_b = error == null ? void 0 : error.response) == null ? void 0 : _b.data) == null ? void 0 : _c.error) == null ? void 0 : _d.message) || "Check audio format and model name"}`);
        } else if (((_e = error == null ? void 0 : error.response) == null ? void 0 : _e.status) === 401) {
          throw new Error("Invalid API key or unauthorized access");
        } else if (((_f = error == null ? void 0 : error.response) == null ? void 0 : _f.status) === 413) {
          throw new Error("Audio file too large. Maximum size is 25MB");
        }
        throw error;
      }
    } catch (error) {
      const message = this.getErrorMessage(error);
      throw new Error(`Failed to transcribe audio: ${message}`);
    }
  }
  async validateApiKey() {
    try {
      const currentKey = this.getApiKey();
      if (!currentKey) {
        this.keyValidated = false;
        this.lastValidatedKey = "";
        return false;
      }
      if (this.keyValidated && this.lastValidatedKey === currentKey) {
        return true;
      }
      const isValid = await this.validateApiKeyImpl();
      if (isValid) {
        this.keyValidated = true;
        this.lastValidatedKey = currentKey;
      } else {
        this.keyValidated = false;
        this.lastValidatedKey = "";
      }
      return isValid;
    } catch (error) {
      this.keyValidated = false;
      this.lastValidatedKey = "";
      return false;
    }
  }
  getAvailableModels(category) {
    return this.models.filter((model) => model.category === category);
  }
  isReady(category = "transcription") {
    const currentKey = this.getApiKey();
    if (!currentKey)
      return false;
    return this.keyValidated && this.lastValidatedKey === currentKey;
  }
  async makeAPIRequest(endpoint, method, headers, body) {
    try {
      const requestHeaders = {
        "Authorization": `Bearer ${this.getApiKey()}`,
        ...headers
      };
      const response = await (0, import_obsidian3.requestUrl)({
        url: endpoint,
        method,
        headers: requestHeaders,
        body: body || void 0,
        throw: true
      });
      if (!response.json) {
        throw new Error("Invalid response format");
      }
      return response.json;
    } catch (error) {
      throw error;
    }
  }
  async prepareTranscriptionRequest(audioArrayBuffer, model) {
    const boundary = "boundary";
    const encoder = new TextEncoder();
    const parts = [];
    parts.push(encoder.encode(`--${boundary}\r
`));
    parts.push(encoder.encode('Content-Disposition: form-data; name="file"; filename="audio.wav"\r\n\r\n'));
    parts.push(new Uint8Array(audioArrayBuffer));
    parts.push(encoder.encode("\r\n"));
    parts.push(encoder.encode(`--${boundary}\r
`));
    parts.push(encoder.encode('Content-Disposition: form-data; name="model"\r\n\r\n'));
    parts.push(encoder.encode(model));
    parts.push(encoder.encode("\r\n"));
    parts.push(encoder.encode(`--${boundary}--\r
`));
    const totalLength = parts.reduce((acc, part) => acc + part.length, 0);
    const finalBuffer = new Uint8Array(totalLength);
    let offset = 0;
    for (const part of parts) {
      finalBuffer.set(part, offset);
      offset += part.length;
    }
    return {
      headers: {
        "Content-Type": `multipart/form-data; boundary=${boundary}`
      },
      body: finalBuffer.buffer
    };
  }
  getErrorMessage(error) {
    if (error instanceof Error)
      return error.message;
    if (typeof error === "string")
      return error;
    return "Unknown error occurred";
  }
};

// src/settings/Settings.ts
var DEFAULT_SETTINGS = {
  // AI Providers
  openaiApiKey: "",
  groqApiKey: "",
  // Recording
  recordingFolderPath: "Recordings",
  saveRecording: true,
  showFloatingButton: true,
  useRecordingModal: true,
  showToolbarButton: true,
  micButtonColor: "#4B4B4B",
  transcriptionModel: "whisper-1",
  transcriptionProvider: "openai" /* OpenAI */,
  transcriptionCalloutFormat: ">[!info]- Transcription\n>![[{audioPath}]]\n>{transcription}",
  showTimer: true,
  autoStopEnabled: false,
  autoStopDuration: 5,
  // Summary
  generateSummary: true,
  summaryPrompt: "Summarize the following transcript concisely, capturing the main points and key details.",
  summaryMaxTokens: 500,
  summaryModel: "gpt-4o-mini",
  summaryProvider: "openai" /* OpenAI */,
  summaryTemperature: 0.7,
  summaryCalloutFormat: ">[!summary]- Summary\n>{summary}",
  // Current Provider
  currentProvider: "openai" /* OpenAI */
};

// src/settings/SettingTab.ts
var import_obsidian8 = require("obsidian");

// src/settings/accordions/BaseAccordion.ts
var import_obsidian4 = require("obsidian");
var BaseAccordion = class {
  constructor(containerEl, title, description = "") {
    this.isOpen = false;
    this.containerEl = containerEl;
    this.accordionEl = this.containerEl.createDiv({ cls: "neurovox-accordion" });
    this.headerEl = this.accordionEl.createDiv({ cls: "neurovox-accordion-header" });
    const titleWrapper = this.headerEl.createDiv({ cls: "neurovox-accordion-title-wrapper" });
    titleWrapper.createSpan({ text: title, cls: "neurovox-accordion-title" });
    this.toggleIcon = this.headerEl.createSpan({ cls: "neurovox-accordion-toggle" });
    this.updateToggleIcon();
    if (description) {
      const descriptionEl = this.accordionEl.createDiv({ cls: "neurovox-accordion-description" });
      descriptionEl.createSpan({ text: description });
    }
    this.contentEl = this.accordionEl.createDiv({ cls: "neurovox-accordion-content" });
    this.contentEl.style.display = "none";
    this.headerEl.addEventListener("click", () => this.toggleAccordion());
  }
  toggleAccordion() {
    this.isOpen = !this.isOpen;
    this.contentEl.style.display = this.isOpen ? "block" : "none";
    this.updateToggleIcon();
    this.accordionEl.classList.toggle("neurovox-accordion-open", this.isOpen);
  }
  updateToggleIcon() {
    this.toggleIcon.empty();
    const iconText = document.createTextNode(this.isOpen ? "\u2796" : "\u2795");
    this.toggleIcon.appendChild(iconText);
  }
  createSettingItem(name, desc) {
    const setting = new import_obsidian4.Setting(this.contentEl);
    setting.setName(name).setDesc(desc);
    return setting;
  }
};

// src/settings/accordions/ModelHookupAccordion.ts
var import_obsidian5 = require("obsidian");
var ModelHookupAccordion = class extends BaseAccordion {
  constructor(containerEl, settings, getAdapter, plugin) {
    super(
      containerEl,
      "\u{1F511} API Keys",
      "Configure API keys for AI providers."
    );
    this.settings = settings;
    this.getAdapter = getAdapter;
    this.plugin = plugin;
  }
  setAccordions(recording, summary) {
    this.recordingAccordion = recording;
    this.summaryAccordion = summary;
  }
  async refreshAccordions() {
    await Promise.all([
      this.recordingAccordion.refresh(),
      this.summaryAccordion.refresh()
    ]);
  }
  render() {
    const openaiSetting = new import_obsidian5.Setting(this.contentEl).setName("OpenAI API Key").setDesc("Enter your OpenAI API key").addText((text) => {
      text.setPlaceholder("sk-...").setValue(this.settings.openaiApiKey);
      text.inputEl.type = "password";
      text.onChange(async (value) => {
        const trimmedValue = value.trim();
        this.settings.openaiApiKey = trimmedValue;
        await this.plugin.saveSettings();
        const adapter = this.getAdapter("openai" /* OpenAI */);
        if (!adapter) {
          return;
        }
        adapter.setApiKey(trimmedValue);
        const isValid = await adapter.validateApiKey();
        if (isValid) {
          openaiSetting.setDesc("\u2705 API key validated successfully");
          try {
            await this.refreshAccordions();
          } catch (error) {
            openaiSetting.setDesc("\u2705 API key valid, but failed to update model lists");
          }
        } else {
          openaiSetting.setDesc("\u274C Invalid API key. Please check your credentials.");
        }
      });
    });
    const groqSetting = new import_obsidian5.Setting(this.contentEl).setName("Groq API Key").setDesc("Enter your Groq API key").addText((text) => {
      text.setPlaceholder("gsk_...").setValue(this.settings.groqApiKey);
      text.inputEl.type = "password";
      text.onChange(async (value) => {
        const trimmedValue = value.trim();
        this.settings.groqApiKey = trimmedValue;
        await this.plugin.saveSettings();
        const adapter = this.getAdapter("groq" /* Groq */);
        if (!adapter) {
          return;
        }
        adapter.setApiKey(trimmedValue);
        const isValid = await adapter.validateApiKey();
        if (isValid) {
          groqSetting.setDesc("\u2705 API key validated successfully");
          try {
            await this.refreshAccordions();
          } catch (error) {
            groqSetting.setDesc("\u2705 API key valid, but failed to update model lists");
          }
        } else {
          groqSetting.setDesc("\u274C Invalid API key. Please check your credentials.");
        }
      });
    });
  }
};

// src/settings/accordions/RecordingAccordion.ts
var import_obsidian6 = require("obsidian");
var RecordingAccordion = class extends BaseAccordion {
  constructor(containerEl, settings, getAdapter, plugin) {
    super(containerEl, "\u{1F399} Recording", "Configure recording preferences and select a transcription model.");
    this.settings = settings;
    this.getAdapter = getAdapter;
    this.plugin = plugin;
  }
  render() {
    this.createRecordingPathSetting();
    this.createSaveRecordingSetting();
    this.createFloatingButtonSetting();
    if (this.settings.showFloatingButton) {
      this.createModalToggleSetting();
    }
    this.createToolbarButtonSetting();
    this.createMicButtonColorSetting();
    this.createTranscriptionFormatSetting();
    this.createTranscriptionModelSetting();
  }
  createRecordingPathSetting() {
    new import_obsidian6.Setting(this.contentEl).setName("Recording path").setDesc("Specify the folder path to save recordings relative to the vault root").addText((text) => {
      text.setPlaceholder("Recordings").setValue(this.settings.recordingFolderPath).onChange(async (value) => {
        this.settings.recordingFolderPath = value.trim() || "Recordings";
        await this.plugin.saveSettings();
      });
    });
  }
  createSaveRecordingSetting() {
    new import_obsidian6.Setting(this.contentEl).setName("Save recording").setDesc("Save the audio file after recording").addToggle((toggle) => {
      toggle.setValue(this.settings.saveRecording).onChange(async (value) => {
        this.settings.saveRecording = value;
        await this.plugin.saveSettings();
      });
    });
  }
  createFloatingButtonSetting() {
    const floatingBtnSetting = new import_obsidian6.Setting(this.contentEl).setName("Show floating button").setDesc("Show a floating microphone button for quick recording").addToggle((toggle) => {
      toggle.setValue(this.settings.showFloatingButton).onChange(async (value) => {
        this.settings.showFloatingButton = value;
        await this.plugin.saveSettings();
        this.refresh();
      });
    });
  }
  createModalToggleSetting() {
    const modalToggleSetting = new import_obsidian6.Setting(this.contentEl).setName("Use recording modal").setDesc("When enabled, shows a modal with controls. When disabled, use direct recording through the mic button.").setClass("neurovox-modal-toggle-setting").addToggle((toggle) => {
      toggle.setValue(this.settings.useRecordingModal).onChange(async (value) => {
        this.settings.useRecordingModal = value;
        await this.plugin.saveSettings();
      });
    });
    modalToggleSetting.settingEl.style.paddingLeft = "2em";
    modalToggleSetting.settingEl.style.borderLeft = "2px solid var(--background-modifier-border)";
  }
  /**
   * Refreshes the accordion content
   */
  refresh() {
    const { contentEl } = this;
    contentEl.empty();
    this.render();
  }
  createToolbarButtonSetting() {
    new import_obsidian6.Setting(this.contentEl).setName("Show toolbar button").setDesc("Show a microphone button in the toolbar").addToggle((toggle) => {
      toggle.setValue(this.settings.showToolbarButton).onChange(async (value) => {
        this.settings.showToolbarButton = value;
        if (value) {
          if (!this.plugin.toolbarButton) {
            this.plugin.initializeUI();
          }
        } else {
          if (this.plugin.toolbarButton) {
            this.plugin.toolbarButton.remove();
            this.plugin.toolbarButton = null;
          }
        }
        await this.plugin.saveSettings();
      });
    });
  }
  createMicButtonColorSetting() {
    new import_obsidian6.Setting(this.contentEl).setName("Mic button color").setDesc("Choose the color for the microphone buttons").addColorPicker((color) => {
      color.setValue(this.settings.micButtonColor).onChange(async (value) => {
        this.settings.micButtonColor = value;
        this.plugin.updateAllButtonColors();
        await this.plugin.saveSettings();
      });
    });
  }
  createTranscriptionFormatSetting() {
    new import_obsidian6.Setting(this.contentEl).setName("Transcription format").setDesc("Customize the transcription callout format. Use {audioPath} for audio file path and {transcription} for the transcribed text").addTextArea((text) => {
      text.setPlaceholder(">[!info]- Transcription\n>![[{audioPath}]]\n>{transcription}").setValue(this.settings.transcriptionCalloutFormat).onChange(async (value) => {
        this.settings.transcriptionCalloutFormat = value;
        await this.plugin.saveSettings();
      });
      text.inputEl.rows = 4;
      text.inputEl.style.width = "100%";
    });
  }
  createTranscriptionModelSetting() {
    const setting = new import_obsidian6.Setting(this.contentEl).setName("Transcription model").setDesc("Select the AI model for transcription").addDropdown((dropdown) => {
      this.modelDropdown = dropdown;
      this.populateModelDropdown(dropdown);
      dropdown.setValue(this.settings.transcriptionModel);
      dropdown.onChange(async (value) => {
        this.settings.transcriptionModel = value;
        const provider = this.getProviderFromModel(value);
        if (provider) {
          this.settings.transcriptionProvider = provider;
          await this.plugin.saveSettings();
        }
      });
    });
  }
  populateModelDropdown(dropdown) {
    let hasModels = false;
    const options = {};
    ["openai" /* OpenAI */, "groq" /* Groq */].forEach((provider) => {
      const apiKey = this.settings[`${provider}ApiKey`];
      if (apiKey) {
        const adapter = this.getAdapter(provider);
        if (adapter) {
          const models = adapter.getAvailableModels("transcription");
          if (models.length > 0) {
            hasModels = true;
            options[`${provider.toUpperCase()}_HEADER`] = `--- ${provider.toUpperCase()} Models ---`;
            models.forEach((model) => {
              options[model.id] = model.name;
            });
          }
        }
      }
    });
    if (!hasModels) {
      options["none"] = "No API keys configured";
      dropdown.setDisabled(true);
    } else {
      dropdown.setDisabled(false);
    }
    dropdown.addOptions(options);
  }
  getProviderFromModel(modelId) {
    for (const [provider, models] of Object.entries(AIModels)) {
      if (models.some((model) => model.id === modelId)) {
        return provider;
      }
    }
    return null;
  }
};

// src/settings/accordions/SummaryAccordion.ts
var import_obsidian7 = require("obsidian");
var SummaryAccordion = class extends BaseAccordion {
  constructor(containerEl, settings, getAdapter, plugin) {
    super(
      containerEl,
      "\u{1F4DD} Summarize",
      "Configure AI summary generation preferences and customize the prompt template."
    );
    this.settings = settings;
    this.getAdapter = getAdapter;
    this.plugin = plugin;
    this.modelDropdown = null;
    this.modelSetting = null;
    this.promptArea = null;
    this.maxTokensSlider = null;
    this.temperatureSlider = null;
  }
  async refresh() {
    try {
      if (!this.modelDropdown) {
        return;
      }
      await this.setupModelDropdown(this.modelDropdown);
      if (this.settings.summaryModel) {
        await this.updateMaxTokensLimit(this.settings.summaryModel);
      }
    } catch (error) {
      throw error;
    }
  }
  render() {
    this.addEnableToggle();
    this.addModelSelection();
    this.addPromptTemplate();
    this.addSummaryFormat();
    this.addMaxTokens();
    this.addTemperatureControl();
  }
  addEnableToggle() {
    new import_obsidian7.Setting(this.contentEl).setName("Enable AI summary").setDesc("Automatically generate an AI summary after transcription").addToggle((toggle) => {
      toggle.setValue(this.settings.generateSummary).onChange(async (value) => {
        this.settings.generateSummary = value;
        await this.plugin.saveSettings();
      });
    });
  }
  addModelSelection() {
    if (this.modelSetting) {
      this.modelSetting.settingEl.remove();
    }
    this.modelSetting = new import_obsidian7.Setting(this.contentEl).setName("Summary model").setDesc("Select the AI model for generating summaries").addDropdown((dropdown) => {
      this.modelDropdown = dropdown;
      this.setupModelDropdown(dropdown);
      dropdown.onChange(async (value) => {
        this.settings.summaryModel = value;
        const provider = this.getProviderFromModel(value);
        if (provider) {
          this.settings.summaryProvider = provider;
          await this.plugin.saveSettings();
        }
        await this.updateMaxTokensLimit(value);
      });
    });
  }
  async setupModelDropdown(dropdown) {
    dropdown.selectEl.empty();
    let hasValidProvider = false;
    for (const provider of ["openai" /* OpenAI */, "groq" /* Groq */]) {
      const apiKey = this.settings[`${provider}ApiKey`];
      if (apiKey) {
        const models = AIModels[provider].filter((model) => model.category === "language");
        if (models.length > 0) {
          hasValidProvider = true;
          const group = document.createElement("optgroup");
          group.label = `${provider.toUpperCase()} Models`;
          models.forEach((model) => {
            const option = document.createElement("option");
            option.value = model.id;
            option.text = model.name;
            group.appendChild(option);
          });
          dropdown.selectEl.appendChild(group);
        }
      }
    }
    if (!hasValidProvider) {
      dropdown.addOption("none", "No API keys configured");
      dropdown.setDisabled(true);
      this.settings.summaryModel = "";
    } else {
      dropdown.setDisabled(false);
      if (!this.settings.summaryModel) {
        const firstOption = dropdown.selectEl.querySelector('option:not([value="none"])');
        if (firstOption) {
          const modelId = firstOption.value;
          const provider = this.getProviderFromModel(modelId);
          if (provider) {
            this.settings.summaryProvider = provider;
            this.settings.summaryModel = modelId;
            dropdown.setValue(modelId);
          }
        }
      } else {
        dropdown.setValue(this.settings.summaryModel);
      }
    }
    await this.plugin.saveSettings();
  }
  addPromptTemplate() {
    new import_obsidian7.Setting(this.contentEl).setName("Summary prompt template").setDesc("Customize the prompt used for generating summaries. Use {transcript} as a placeholder for the transcribed text.").addTextArea((text) => {
      this.promptArea = text;
      text.setPlaceholder("Please provide a concise summary of the following transcript: {transcript}").setValue(this.settings.summaryPrompt).onChange(async (value) => {
        this.settings.summaryPrompt = value;
        await this.plugin.saveSettings();
      });
      text.inputEl.rows = 4;
      text.inputEl.style.width = "100%";
    });
  }
  addSummaryFormat() {
    new import_obsidian7.Setting(this.contentEl).setName("Summary format").setDesc("Customize the summary callout format. Use {summary} for the generated summary").addTextArea((text) => {
      text.setPlaceholder(">[!summary]- Summary\n>{summary}").setValue(this.settings.summaryCalloutFormat).onChange(async (value) => {
        this.settings.summaryCalloutFormat = value;
        await this.plugin.saveSettings();
      });
      text.inputEl.rows = 4;
      text.inputEl.style.width = "100%";
    });
  }
  addMaxTokens() {
    new import_obsidian7.Setting(this.contentEl).setName("Maximum summary length").setDesc("Set the maximum number of tokens for the generated summary").addSlider((slider) => {
      this.maxTokensSlider = slider;
      slider.setLimits(100, 4096, 100).setValue(this.settings.summaryMaxTokens).setDynamicTooltip().onChange(async (value) => {
        this.settings.summaryMaxTokens = value;
        await this.plugin.saveSettings();
      });
    });
  }
  addTemperatureControl() {
    new import_obsidian7.Setting(this.contentEl).setName("Summary creativity").setDesc("Adjust the creativity level of the summary (0 = more focused, 1 = more creative)").addSlider((slider) => {
      this.temperatureSlider = slider;
      slider.setLimits(0, 1, 0.1).setValue(this.settings.summaryTemperature).setDynamicTooltip().onChange(async (value) => {
        this.settings.summaryTemperature = value;
        await this.plugin.saveSettings();
      });
    });
  }
  getProviderFromModel(modelId) {
    for (const [provider, models] of Object.entries(AIModels)) {
      if (models.some((model) => model.id === modelId)) {
        return provider;
      }
    }
    return null;
  }
  async updateMaxTokensLimit(modelId) {
    const model = getModelInfo(modelId);
    const maxTokens = (model == null ? void 0 : model.maxTokens) || 1e3;
    if (this.maxTokensSlider) {
      this.maxTokensSlider.sliderEl.max = maxTokens.toString();
      const currentValue = parseInt(this.maxTokensSlider.sliderEl.value);
      if (currentValue > maxTokens) {
        this.maxTokensSlider.setValue(maxTokens);
        this.settings.summaryMaxTokens = maxTokens;
        await this.plugin.saveSettings();
      }
    }
  }
};

// src/settings/SettingTab.ts
var NeuroVoxSettingTab = class extends import_obsidian8.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.recordingAccordion = null;
    this.summaryAccordion = null;
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    const modelHookupContainer = containerEl.createDiv();
    const recordingContainer = containerEl.createDiv();
    const summaryContainer = containerEl.createDiv();
    this.recordingAccordion = new RecordingAccordion(
      recordingContainer,
      this.plugin.settings,
      (provider) => this.plugin.aiAdapters.get(provider),
      this.plugin
    );
    this.summaryAccordion = new SummaryAccordion(
      summaryContainer,
      this.plugin.settings,
      (provider) => this.plugin.aiAdapters.get(provider),
      this.plugin
    );
    const modelHookupAccordion = new ModelHookupAccordion(
      modelHookupContainer,
      this.plugin.settings,
      (provider) => this.plugin.aiAdapters.get(provider),
      this.plugin
    );
    modelHookupAccordion.setAccordions(this.recordingAccordion, this.summaryAccordion);
    modelHookupAccordion.render();
    this.recordingAccordion.render();
    this.summaryAccordion.render();
  }
  getRecordingAccordion() {
    return this.recordingAccordion;
  }
  getSummaryAccordion() {
    return this.summaryAccordion;
  }
};

// src/ui/FloatingButton.ts
var import_obsidian9 = require("obsidian");

// src/utils/ButtonPositionManager.ts
var ButtonPositionManager = class {
  constructor(containerEl, buttonEl, activeContainer, buttonSize, margin, onPositionChange, onDragEnd, onClick) {
    this.containerEl = containerEl;
    this.buttonEl = buttonEl;
    this.activeContainer = activeContainer;
    this.buttonSize = buttonSize;
    this.margin = margin;
    this.onPositionChange = onPositionChange;
    this.onDragEnd = onDragEnd;
    this.onClick = onClick;
    this.isDragging = false;
    this.hasMoved = false;
    this.dragStartX = 0;
    this.dragStartY = 0;
    this.currentX = 0;
    this.currentY = 0;
    this.lastContainerWidth = null;
    this.relativeX = 0;
    this.relativeY = 0;
    this.DRAG_THRESHOLD = 5;
    this.handleDragStart = (e) => {
      if (e.button !== 0)
        return;
      e.preventDefault();
      e.stopPropagation();
      this.isDragging = true;
      this.hasMoved = false;
      this.dragStartX = e.clientX - this.currentX;
      this.dragStartY = e.clientY - this.currentY;
      this.buttonEl.classList.add("is-dragging");
    };
    /**
     * Handles the end of a drag operation
     */
    this.handleDragEnd = (e) => {
      if (!this.isDragging)
        return;
      if (e) {
        e.preventDefault();
        e.stopPropagation();
      }
      this.isDragging = false;
      this.buttonEl.classList.remove("is-dragging");
      if (this.hasMoved) {
        this.onDragEnd({
          x: this.currentX,
          y: this.currentY
        });
      }
      setTimeout(() => {
        this.hasMoved = false;
      }, 100);
    };
    /**
     * Handles drag movement and determines if threshold is met
     */
    this.handleDragMove = (e) => {
      if (!this.isDragging)
        return;
      e.preventDefault();
      e.stopPropagation();
      const newX = e.clientX - this.dragStartX;
      const newY = e.clientY - this.dragStartY;
      if (!this.hasMoved && (Math.abs(newX - this.currentX) > this.DRAG_THRESHOLD || Math.abs(newY - this.currentY) > this.DRAG_THRESHOLD)) {
        this.hasMoved = true;
      }
      this.setPosition(newX, newY);
      this.constrainPosition();
    };
    /**
     * Handles touch events for mobile support
     */
    this.handleTouchStart = (e) => {
      if (e.touches.length !== 1)
        return;
      e.preventDefault();
      const touch = e.touches[0];
      this.isDragging = true;
      this.hasMoved = false;
      this.dragStartX = touch.clientX - this.currentX;
      this.dragStartY = touch.clientY - this.currentY;
      this.buttonEl.classList.add("is-dragging");
    };
    this.handleTouchMove = (e) => {
      if (!this.isDragging || e.touches.length !== 1)
        return;
      e.preventDefault();
      const touch = e.touches[0];
      const newX = touch.clientX - this.dragStartX;
      const newY = touch.clientY - this.dragStartY;
      if (!this.hasMoved && (Math.abs(newX - this.currentX) > this.DRAG_THRESHOLD || Math.abs(newY - this.currentY) > this.DRAG_THRESHOLD)) {
        this.hasMoved = true;
      }
      this.setPosition(newX, newY);
      this.constrainPosition();
    };
    this.handleTouchEnd = () => {
      if (!this.isDragging)
        return;
      const wasDragging = this.hasMoved;
      this.isDragging = false;
      this.buttonEl.classList.remove("is-dragging");
      if (!wasDragging) {
        this.onClick();
      } else {
        this.onDragEnd({
          x: this.currentX,
          y: this.currentY
        });
      }
      this.hasMoved = false;
    };
    this._boundHandlers = {
      move: this.handleDragMove.bind(this),
      end: this.handleDragEnd.bind(this),
      touchMove: this.handleTouchMove.bind(this),
      touchEnd: this.handleTouchEnd.bind(this)
    };
    this.setupEventListeners();
  }
  setPosition(x, y, updateRelative = true) {
    this.currentX = x;
    this.currentY = y;
    if (updateRelative && this.activeContainer) {
      const containerRect = this.activeContainer.getBoundingClientRect();
      this.relativeX = x / containerRect.width;
      this.relativeY = y / containerRect.height;
    }
    this.onPositionChange(x, y);
  }
  constrainPosition() {
    if (!this.activeContainer)
      return;
    const containerRect = this.activeContainer.getBoundingClientRect();
    this.lastContainerWidth = containerRect.width;
    if (containerRect.width < this.buttonSize + this.margin * 2 || containerRect.height < this.buttonSize + this.margin * 2) {
      return;
    }
    const maxX = containerRect.width - this.buttonSize - this.margin;
    const maxY = containerRect.height - this.buttonSize - this.margin;
    const targetX = this.relativeX * containerRect.width;
    const targetY = this.relativeY * containerRect.height;
    const x = Math.max(this.margin, Math.min(targetX, maxX));
    const y = Math.max(this.margin, Math.min(targetY, maxY));
    this.setPosition(x, y, false);
  }
  updateContainer(newContainer) {
    if (!newContainer) {
      this.activeContainer = null;
      return;
    }
    const oldContainer = this.activeContainer;
    this.activeContainer = newContainer;
    if (oldContainer) {
      const newRect = newContainer.getBoundingClientRect();
      const newX = this.relativeX * newRect.width;
      const newY = this.relativeY * newRect.height;
      this.setPosition(newX, newY, false);
    }
    this.constrainPosition();
  }
  setupEventListeners() {
    this.buttonEl.addEventListener("mousedown", this.handleDragStart.bind(this));
    document.addEventListener("mousemove", this._boundHandlers.move);
    document.addEventListener("mouseup", this._boundHandlers.end);
    this.buttonEl.addEventListener("touchstart", this.handleTouchStart.bind(this));
    document.addEventListener("touchmove", this._boundHandlers.touchMove);
    document.addEventListener("touchend", this._boundHandlers.touchEnd);
  }
  getCurrentPosition() {
    return {
      x: this.currentX,
      y: this.currentY
    };
  }
  /**
   * Handles cleanup of position manager resources
   */
  cleanup() {
    this.buttonEl.removeEventListener("mousedown", this.handleDragStart);
    this.buttonEl.removeEventListener("touchstart", this.handleTouchStart);
    document.removeEventListener("mousemove", this._boundHandlers.move);
    document.removeEventListener("mouseup", this._boundHandlers.end);
    document.removeEventListener("touchmove", this._boundHandlers.touchMove);
    document.removeEventListener("touchend", this._boundHandlers.touchEnd);
  }
};

// src/utils/RecordingManager.ts
var import_recordrtc = __toESM(require_RecordRTC());
var AudioRecordingManager = class {
  constructor() {
    this.recorder = null;
    this.stream = null;
    this.AUDIO_CONFIG = {
      type: "audio",
      mimeType: "audio/webm;codecs=pcm",
      // Use PCM encoding for better quality
      recorderType: import_recordrtc.default.StereoAudioRecorder,
      numberOfAudioChannels: 1,
      desiredSampRate: 44100,
      // CD quality audio
      timeSlice: 1e3
      // Update each second
    };
  }
  /**
   * Initializes the recording manager with microphone access
   */
  async initialize() {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      this.recorder = new import_recordrtc.default(this.stream, this.AUDIO_CONFIG);
    } catch (error) {
      throw new Error("Failed to access microphone");
    }
  }
  start() {
    if (!this.recorder) {
      throw new Error("Audio recorder not initialized");
    }
    this.recorder.startRecording();
  }
  pause() {
    if (!this.recorder)
      return;
    this.recorder.pauseRecording();
  }
  resume() {
    if (!this.recorder)
      return;
    this.recorder.resumeRecording();
  }
  async stop() {
    if (!this.recorder)
      return null;
    return new Promise((resolve) => {
      if (!this.recorder) {
        resolve(null);
        return;
      }
      this.recorder.stopRecording(() => {
        var _a;
        const blob = ((_a = this.recorder) == null ? void 0 : _a.getBlob()) || null;
        if (blob) {
          Object.defineProperty(blob, "name", {
            value: `recording-${new Date().getTime()}.wav`,
            writable: true
          });
        }
        resolve(blob);
      });
    });
  }
  cleanup() {
    if (this.recorder) {
      try {
        this.recorder.destroy();
      } catch (error) {
      }
      this.recorder = null;
    }
    if (this.stream) {
      try {
        this.stream.getTracks().forEach((track) => track.stop());
      } catch (error) {
      }
      this.stream = null;
    }
  }
  getState() {
    return this.recorder ? this.recorder.state : "inactive";
  }
  isRecording() {
    return this.getState() === "recording";
  }
  isInitialized() {
    return this.recorder !== null;
  }
};

// src/ui/FloatingButton.ts
var _FloatingButton = class {
  constructor(plugin, pluginData, onClickCallback) {
    this.plugin = plugin;
    this.pluginData = pluginData;
    this.onClickCallback = onClickCallback;
    this.activeLeafContainer = null;
    this.resizeObserver = null;
    this.positionManager = null;
    this.resizeTimeout = null;
    this.audioManager = null;
    this.isRecording = false;
    this.isProcessing = false;
    if (_FloatingButton.instance) {
      _FloatingButton.instance.remove();
    }
    this.buttonEl = null;
    this.containerEl = null;
    this.initializeComponents();
  }
  static getInstance(plugin, pluginData, onClickCallback) {
    if (!_FloatingButton.instance || _FloatingButton.instance.isInvalid()) {
      if (_FloatingButton.instance) {
        _FloatingButton.instance.remove();
      }
      _FloatingButton.instance = new _FloatingButton(plugin, pluginData, onClickCallback);
    }
    return _FloatingButton.instance;
  }
  isInvalid() {
    var _a, _b;
    return !((_a = this.containerEl) == null ? void 0 : _a.isConnected) || !((_b = this.buttonEl) == null ? void 0 : _b.isConnected);
  }
  getComputedSize() {
    const computedStyle = getComputedStyle(document.documentElement);
    return parseInt(computedStyle.getPropertyValue("--neurovox-button-size")) || 48;
  }
  getComputedMargin() {
    const computedStyle = getComputedStyle(document.documentElement);
    return parseInt(computedStyle.getPropertyValue("--neurovox-button-margin")) || 20;
  }
  getComputedResizeDelay() {
    const computedStyle = getComputedStyle(document.documentElement);
    return parseInt(computedStyle.getPropertyValue("--neurovox-resize-delay")) || 100;
  }
  initializeComponents() {
    this.setupResizeObserver();
    this.createElements();
    this.setupWorkspaceEvents();
  }
  setupResizeObserver() {
    this.resizeObserver = new ResizeObserver(() => {
      if (this.activeLeafContainer && this.pluginData.showFloatingButton) {
        requestAnimationFrame(() => {
          if (this.positionManager) {
            this.positionManager.constrainPosition();
          }
        });
      }
    });
  }
  createElements() {
    this.createContainer();
    this.createButton();
    this.attachToActiveLeaf();
  }
  createContainer() {
    this.containerEl = document.createElement("div");
    this.containerEl.classList.add("neurovox-button-container");
  }
  /* Handles button click events independently of drag behavior.
  * This ensures recording only starts on direct clicks, not after drags.
  */
  createButton() {
    if (!this.containerEl)
      return;
    this.buttonEl = document.createElement("button");
    this.buttonEl.classList.add("neurovox-button", "floating");
    this.buttonEl.setAttribute("aria-label", "Start recording (drag to move)");
    (0, import_obsidian9.setIcon)(this.buttonEl, "mic");
    this.buttonEl.addEventListener("click", (event2) => {
      var _a, _b;
      if (((_a = this.positionManager) == null ? void 0 : _a.isDragging) || ((_b = this.positionManager) == null ? void 0 : _b.hasMoved)) {
        event2.preventDefault();
        event2.stopPropagation();
        return;
      }
      this.handleClick();
    });
    this.updateButtonColor();
    this.containerEl.appendChild(this.buttonEl);
  }
  async initializePositionManager() {
    if (!this.containerEl || !this.buttonEl || !this.activeLeafContainer)
      return;
    this.positionManager = new ButtonPositionManager(
      this.containerEl,
      this.buttonEl,
      this.activeLeafContainer,
      this.getComputedSize(),
      this.getComputedMargin(),
      this.handlePositionChange.bind(this),
      this.handleDragEnd.bind(this),
      this.onClickCallback
    );
    setTimeout(async () => {
      await this.setInitialPosition();
    }, 0);
  }
  handlePositionChange(x, y) {
    if (!this.containerEl)
      return;
    requestAnimationFrame(() => {
      if (this.containerEl) {
        this.containerEl.style.transform = `translate3d(${x}px, ${y}px, 0)`;
      }
    });
  }
  async handleDragEnd(position) {
    this.pluginData.buttonPosition = position;
    await this.plugin.savePluginData();
  }
  async setInitialPosition() {
    const savedPosition = this.pluginData.buttonPosition;
    if (savedPosition && this.activeLeafContainer && this.positionManager) {
      const containerRect = this.activeLeafContainer.getBoundingClientRect();
      const x = Math.min(
        Math.max(savedPosition.x, this.getComputedMargin()),
        containerRect.width - this.getComputedSize() - this.getComputedMargin()
      );
      const y = Math.min(
        Math.max(savedPosition.y, this.getComputedMargin()),
        containerRect.height - this.getComputedSize() - this.getComputedMargin()
      );
      requestAnimationFrame(() => {
        if (this.positionManager) {
          this.positionManager.setPosition(x, y, true);
        }
      });
    } else {
      await this.setDefaultPosition();
    }
  }
  async setDefaultPosition() {
    if (!this.activeLeafContainer || !this.positionManager) {
      return;
    }
    const containerRect = this.activeLeafContainer.getBoundingClientRect();
    const x = containerRect.width - this.getComputedSize() - this.getComputedMargin();
    const y = containerRect.height - this.getComputedSize() - this.getComputedMargin();
    requestAnimationFrame(() => {
      if (this.positionManager) {
        this.positionManager.setPosition(x, y, true);
        this.pluginData.buttonPosition = { x, y };
        this.plugin.savePluginData();
      }
    });
  }
  setupWorkspaceEvents() {
    this.registerActiveLeafChangeEvent();
    this.registerLayoutChangeEvent();
    this.registerResizeEvent();
  }
  registerActiveLeafChangeEvent() {
    this.plugin.registerEvent(
      this.plugin.app.workspace.on("active-leaf-change", () => {
        requestAnimationFrame(() => this.attachToActiveLeaf());
      })
    );
  }
  registerLayoutChangeEvent() {
    this.plugin.registerEvent(
      this.plugin.app.workspace.on("layout-change", () => {
        requestAnimationFrame(() => {
          if (this.positionManager && this.activeLeafContainer) {
            this.positionManager.updateContainer(this.activeLeafContainer);
          }
        });
      })
    );
  }
  registerResizeEvent() {
    this.plugin.registerEvent(
      this.plugin.app.workspace.on("resize", () => {
        if (this.resizeTimeout) {
          clearTimeout(this.resizeTimeout);
        }
        this.resizeTimeout = setTimeout(() => {
          if (this.activeLeafContainer && this.positionManager) {
            requestAnimationFrame(() => {
              if (this.positionManager && this.activeLeafContainer) {
                this.positionManager.updateContainer(this.activeLeafContainer);
              }
            });
          }
        }, this.getComputedResizeDelay());
      })
    );
  }
  attachToActiveLeaf() {
    const activeLeaf = this.plugin.app.workspace.getActiveViewOfType(import_obsidian9.MarkdownView);
    if (!activeLeaf) {
      this.hide();
      return;
    }
    const viewContent = activeLeaf.containerEl.querySelector(".view-content");
    if (!(viewContent instanceof HTMLElement)) {
      this.hide();
      return;
    }
    const existingButtons = viewContent.querySelectorAll(".neurovox-button-container");
    existingButtons.forEach((el) => {
      if (el !== this.containerEl && el.parentNode === viewContent) {
        el.remove();
      }
    });
    if (this.containerEl && this.containerEl.parentNode !== viewContent) {
      if (this.containerEl.parentNode) {
        this.containerEl.remove();
      }
      this.updateActiveContainer(viewContent);
    } else if (!this.containerEl) {
      this.createContainer();
      this.createButton();
      this.updateActiveContainer(viewContent);
    }
    if (this.pluginData.showFloatingButton) {
      this.show();
    }
  }
  /**
   * Handles updating the active container when switching notes
   */
  updateActiveContainer(newContainer) {
    var _a, _b;
    if (this.activeLeafContainer) {
      (_a = this.resizeObserver) == null ? void 0 : _a.unobserve(this.activeLeafContainer);
    }
    this.activeLeafContainer = newContainer;
    if (this.containerEl) {
      newContainer.appendChild(this.containerEl);
    }
    (_b = this.resizeObserver) == null ? void 0 : _b.observe(newContainer);
    if (this.pluginData.showFloatingButton) {
      this.show();
      this.initializePositionManager();
    } else {
      this.hide();
    }
  }
  updateButtonColor() {
    if (!this.buttonEl)
      return;
    const color = this.pluginData.micButtonColor;
    this.buttonEl.style.setProperty("--neurovox-button-color", color);
  }
  getCurrentPosition() {
    if (!this.positionManager) {
      return this.pluginData.buttonPosition || { x: 100, y: 100 };
    }
    return this.positionManager.getCurrentPosition();
  }
  show() {
    if (!this.containerEl || !this.pluginData.showFloatingButton)
      return;
    this.containerEl.style.display = "block";
    requestAnimationFrame(() => {
      if (this.containerEl) {
        this.containerEl.style.opacity = "1";
        if (this.positionManager) {
          this.positionManager.constrainPosition();
        }
      }
    });
  }
  hide() {
    if (!this.containerEl)
      return;
    this.containerEl.style.display = "none";
    this.containerEl.style.opacity = "0";
  }
  remove() {
    if (this.resizeTimeout) {
      clearTimeout(this.resizeTimeout);
      this.resizeTimeout = null;
    }
    if (this.positionManager) {
      this.positionManager.cleanup();
      this.positionManager = null;
    }
    if (this.resizeObserver) {
      this.resizeObserver.disconnect();
      this.resizeObserver = null;
    }
    this.cleanup();
    if (this.buttonEl) {
      this.buttonEl.remove();
      this.buttonEl = null;
    }
    if (this.containerEl) {
      this.containerEl.remove();
      this.containerEl = null;
    }
    if (_FloatingButton.instance === this) {
      _FloatingButton.instance = null;
    }
  }
  /**
   * Handles click based on current recording mode
   */
  async handleClick() {
    if (this.isProcessing)
      return;
    if (this.pluginData.useRecordingModal) {
      event == null ? void 0 : event.stopPropagation();
      this.onClickCallback();
      return;
    }
    if (!this.isRecording) {
      await this.startDirectRecording();
    } else {
      await this.stopDirectRecording();
    }
  }
  /**
   * Starts direct recording mode
   */
  async startDirectRecording() {
    try {
      if (!this.audioManager) {
        this.audioManager = new AudioRecordingManager();
        await this.audioManager.initialize();
      }
      this.audioManager.start();
      this.isRecording = true;
      this.updateRecordingState(true);
      new import_obsidian9.Notice("Recording started");
    } catch (error) {
      new import_obsidian9.Notice("Failed to start recording");
      this.cleanup();
    }
  }
  async stopDirectRecording() {
    try {
      if (!this.audioManager) {
        throw new Error("Audio manager not initialized");
      }
      this.isRecording = false;
      this.updateRecordingState(false);
      const blob = await this.audioManager.stop();
      if (!blob)
        return;
      this.isProcessing = true;
      this.updateProcessingState(true);
      const activeView = this.plugin.app.workspace.getActiveViewOfType(import_obsidian9.MarkdownView);
      if (!activeView || !activeView.file) {
        new import_obsidian9.Notice("No active file to insert recording");
        return;
      }
      await this.plugin.recordingProcessor.processRecording(
        blob,
        activeView.file,
        activeView.editor.getCursor()
      );
    } catch (error) {
      new import_obsidian9.Notice("Failed to stop recording");
    } finally {
      this.cleanup();
    }
  }
  /**
   * Updates the visual state for recording
   */
  updateRecordingState(isRecording) {
    if (!this.buttonEl)
      return;
    if (isRecording) {
      this.buttonEl.addClass("recording");
    } else {
      this.buttonEl.removeClass("recording");
    }
    this.buttonEl.setAttribute(
      "aria-label",
      isRecording ? "Stop recording" : "Start recording"
    );
  }
  updateProcessingState(isProcessing) {
    if (!this.buttonEl)
      return;
    this.buttonEl.toggleClass("processing", isProcessing);
  }
  cleanup() {
    this.isRecording = false;
    this.isProcessing = false;
    this.updateRecordingState(false);
    this.updateProcessingState(false);
    if (this.audioManager) {
      this.audioManager.cleanup();
      this.audioManager = null;
    }
  }
};
var FloatingButton = _FloatingButton;
FloatingButton.instance = null;

// src/ui/ToolbarButton.ts
var import_obsidian13 = require("obsidian");

// src/modals/TimerModal.ts
var import_obsidian12 = require("obsidian");

// src/ui/RecordingUI.ts
var import_obsidian11 = require("obsidian");

// src/ui/TouchableButton.ts
var import_obsidian10 = require("obsidian");
var TouchableButton = class extends import_obsidian10.ButtonComponent {
  constructor(options) {
    super(options.container);
    this.isProcessingAction = false;
    this.DEBOUNCE_TIME = 1e3;
    this.actionTimeout = null;
    this.setupButton(options);
  }
  setupButton(options) {
    this.setButtonText(options.text);
    if (options.icon) {
      (0, import_obsidian10.setIcon)(this.buttonEl, options.icon);
    }
    if (options.classes) {
      options.classes.forEach((cls) => this.buttonEl.addClass(cls));
    }
    if (options.ariaLabel) {
      this.buttonEl.setAttribute("aria-label", options.ariaLabel);
    }
    if (options.isCta) {
      this.setCta();
    }
    this.buttonEl.addClass("touch-button");
    this.buttonEl.setAttribute("data-state", "ready");
    this.buttonEl.setAttribute("role", "button");
    this.buttonEl.setAttribute("tabindex", "0");
    this.setupTouchHandlers(options.onClick);
  }
  setupTouchHandlers(onClick) {
    let touchStartTime = 0;
    let isLongPress = false;
    const handleTouchStart = (e) => {
      e.preventDefault();
      e.stopPropagation();
      if (this.isProcessingAction)
        return;
      touchStartTime = Date.now();
      isLongPress = false;
      this.buttonEl.addClass("is-touching");
      setTimeout(() => {
        if (this.buttonEl.matches(":active")) {
          isLongPress = true;
          this.buttonEl.addClass("is-long-press");
        }
      }, 500);
    };
    const handleTouchEnd = async (e) => {
      e.preventDefault();
      e.stopPropagation();
      this.buttonEl.removeClass("is-touching");
      this.buttonEl.removeClass("is-long-press");
      if (this.isProcessingAction || isLongPress)
        return;
      const touchDuration = Date.now() - touchStartTime;
      if (touchDuration > 1e3)
        return;
      await this.processButtonAction(onClick);
    };
    const handleTouchCancel = () => {
      this.buttonEl.removeClass("is-touching");
      this.buttonEl.removeClass("is-long-press");
    };
    this.buttonEl.addEventListener("touchstart", handleTouchStart, { passive: false });
    this.buttonEl.addEventListener("touchend", handleTouchEnd, { passive: false });
    this.buttonEl.addEventListener("touchcancel", handleTouchCancel);
    this.onClick(async (e) => {
      e.preventDefault();
      if (!this.isProcessingAction) {
        await this.processButtonAction(onClick);
      }
    });
  }
  /**
   * Processes button actions with proper state management and feedback
   *  Handles action processing with proper cleanup
   */
  async processButtonAction(onClick) {
    if (this.isProcessingAction)
      return;
    this.buttonEl.setAttribute("data-state", "processing");
    this.buttonEl.addClass("is-processing");
    this.isProcessingAction = true;
    try {
      if (this.actionTimeout) {
        clearTimeout(this.actionTimeout);
      }
      await onClick();
      this.actionTimeout = setTimeout(() => {
        this.isProcessingAction = false;
        this.buttonEl.setAttribute("data-state", "ready");
        this.buttonEl.removeClass("is-processing");
      }, this.DEBOUNCE_TIME);
    } catch (error) {
      this.isProcessingAction = false;
      this.buttonEl.setAttribute("data-state", "error");
      this.buttonEl.addClass("has-error");
      setTimeout(() => {
        this.buttonEl.setAttribute("data-state", "ready");
        this.buttonEl.removeClass("has-error");
      }, 2e3);
    }
  }
  /**
   * Cleanup resources and event listeners
   */
  cleanup() {
    if (this.actionTimeout) {
      clearTimeout(this.actionTimeout);
      this.actionTimeout = null;
    }
    this.buttonEl.remove();
  }
};

// src/ui/RecordingUI.ts
var RecordingUI = class {
  constructor(container, handlers) {
    this.container = container;
    this.handlers = handlers;
    this.currentState = "inactive";
    this.initializeComponents();
    window.addEventListener("unload", () => this.cleanup());
  }
  initializeComponents() {
    this.setupTouchHandlers();
    this.createTimerDisplay();
    this.createControls();
    this.createWaveform();
  }
  /**
   * Sets up touch event handlers for mobile interactions
   *  Prevents unwanted gestures and ensures smooth interaction
   */
  setupTouchHandlers() {
    this.container.addEventListener("gesturestart", (e) => {
      e.preventDefault();
    }, { passive: false });
    this.container.addEventListener("touchmove", (e) => {
      e.preventDefault();
    }, { passive: false });
    let lastTap = 0;
    this.container.addEventListener("touchend", (e) => {
      const currentTime = new Date().getTime();
      const tapLength = currentTime - lastTap;
      if (tapLength < 300 && tapLength > 0) {
        e.preventDefault();
      }
      lastTap = currentTime;
    }, { passive: false });
  }
  createTimerDisplay() {
    this.timerText = this.container.createDiv({
      cls: "neurovox-timer-display",
      text: "00:00"
    });
  }
  createControls() {
    const controls = this.container.createDiv({
      cls: "neurovox-timer-controls"
    });
    this.pauseButton = new TouchableButton({
      container: controls,
      text: "",
      icon: "pause",
      classes: ["neurovox-timer-button", "neurovox-pause-button"],
      ariaLabel: "Pause recording",
      onClick: () => this.handlers.onPause()
    });
    this.stopButton = new TouchableButton({
      container: controls,
      text: "",
      icon: "square",
      classes: ["neurovox-timer-button", "neurovox-stop-button"],
      ariaLabel: "Stop Recording",
      onClick: () => this.handlers.onStop()
    });
  }
  createWaveform() {
    this.waveContainer = this.container.createDiv({
      cls: "neurovox-audio-wave"
    });
    for (let i = 0; i < 5; i++) {
      this.waveContainer.createDiv({
        cls: "neurovox-wave-bar"
      });
    }
  }
  updateTimer(seconds, maxDuration, warningThreshold) {
    const minutes = Math.floor(seconds / 60).toString().padStart(2, "0");
    const remainingSeconds = (seconds % 60).toString().padStart(2, "0");
    this.timerText.setText(`${minutes}:${remainingSeconds}`);
    const timeLeft = maxDuration - seconds;
    this.timerText.toggleClass("is-warning", timeLeft <= warningThreshold);
  }
  updateState(state) {
    this.currentState = state;
    const states = ["is-recording", "is-paused", "is-stopped", "is-inactive"];
    states.forEach((cls) => this.waveContainer.removeClass(cls));
    this.waveContainer.addClass(`is-${state}`);
    const isPaused = state === "paused";
    const iconName = isPaused ? "play" : "pause";
    const label = isPaused ? "Resume recording" : "Pause Recording";
    this.pauseButton.buttonEl.empty();
    (0, import_obsidian11.setIcon)(this.pauseButton.buttonEl, iconName);
    this.pauseButton.buttonEl.setAttribute("aria-label", label);
    this.pauseButton.buttonEl.toggleClass("is-paused", isPaused);
  }
  /**
   * Enhanced cleanup with proper resource management
   *  Ensures all resources are properly released
   */
  cleanup() {
    var _a, _b;
    (_a = this.pauseButton) == null ? void 0 : _a.cleanup();
    (_b = this.stopButton) == null ? void 0 : _b.cleanup();
    this.container.empty();
  }
};

// src/modals/TimerModal.ts
var TimerModal = class extends import_obsidian12.Modal {
  constructor(app) {
    super(app);
    this.intervalId = null;
    this.seconds = 0;
    this.isClosing = false;
    this.currentState = "inactive";
    this.CONFIG = {
      maxDuration: 12 * 60,
      warningThreshold: 60,
      updateInterval: 1e3
    };
    this.recordingManager = new AudioRecordingManager();
    this.setupCloseHandlers();
  }
  /**
   * Sets up handlers for modal closing via escape key, clicks, and touch events
   *  Enhanced with proper mobile touch handling
   */
  setupCloseHandlers() {
    this.contentEl.addEventListener("touchstart", (e) => {
      e.stopPropagation();
    }, { passive: true });
    const handleOutsideInteraction = (event2) => {
      const target = event2.target;
      if (target === this.modalEl) {
        event2.preventDefault();
        event2.stopPropagation();
        void this.requestClose();
      }
    };
    this.modalEl.addEventListener("click", handleOutsideInteraction);
    this.modalEl.addEventListener("touchstart", handleOutsideInteraction, { passive: false });
    this.modalEl.addEventListener("touchend", (e) => e.preventDefault(), { passive: false });
    this.scope.register([], "Escape", () => {
      void this.requestClose();
      return false;
    });
    window.addEventListener("popstate", () => {
      void this.requestClose();
    });
  }
  /**
   * Override the built-in close method to use our custom close handler
   */
  close() {
    if (!this.isClosing) {
      void this.requestClose();
    }
  }
  /**
   * Handles all close attempts, ensuring proper cleanup and save prompts
   */
  async requestClose() {
    if (this.isClosing)
      return;
    this.isClosing = true;
    if (this.currentState === "recording" || this.currentState === "paused") {
      await this.handleStop();
    } else {
      await this.finalizeClose();
    }
  }
  /**
   * Performs final cleanup and closes the modal
   */
  async finalizeClose() {
    this.cleanup();
    this.isClosing = false;
    super.close();
  }
  /**
   * Initializes the modal with enhanced mobile support
   *  Added mobile-specific meta tags and initialization
   */
  async onOpen() {
    try {
      const viewport = document.querySelector('meta[name="viewport"]');
      if (!viewport) {
        const meta = document.createElement("meta");
        meta.name = "viewport";
        meta.content = "width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no";
        document.head.appendChild(meta);
      }
      const { contentEl } = this;
      contentEl.empty();
      contentEl.addClass("neurovox-timer-modal");
      if (this.isMobileDevice()) {
        contentEl.addClass("is-mobile");
      }
      const container = contentEl.createDiv({
        cls: "neurovox-timer-content"
      });
      this.ui = new RecordingUI(container, {
        onPause: () => this.handlePauseToggle(),
        onStop: () => this.handleStop()
      });
      await this.initializeRecording();
    } catch (error) {
      this.handleError("Failed to initialize recording", error);
    }
  }
  /**
   * Initializes recording with mobile-specific handling
   *  Added device-specific audio configuration
   */
  async initializeRecording() {
    try {
      await this.recordingManager.initialize();
      await this.startRecording();
    } catch (error) {
      if (this.isIOSDevice() && error instanceof Error && error.name === "NotAllowedError") {
        this.handleError("iOS requires microphone permission. Please enable it in Settings.", error);
      } else {
        this.handleError("Failed to initialize recording", error);
      }
    }
  }
  /**
   * Detects if current device is mobile using Obsidian's Platform API
   */
  isMobileDevice() {
    return import_obsidian12.Platform.isMobile;
  }
  /**
   * Detects if current device is iOS using Obsidian's Platform API
   */
  isIOSDevice() {
    return import_obsidian12.Platform.isIosApp || import_obsidian12.Platform.isMobile && /iPhone|iPad|iPod/i.test(navigator.userAgent);
  }
  /**
   * Starts or resumes recording
   */
  async startRecording() {
    try {
      if (this.currentState === "paused") {
        this.recordingManager.resume();
        this.resumeTimer();
      } else {
        this.recordingManager.start();
        this.startTimer();
      }
      this.currentState = "recording";
      this.ui.updateState(this.currentState);
      new import_obsidian12.Notice("Recording started");
    } catch (error) {
      this.handleError("Failed to start recording", error);
    }
  }
  /**
   * Handles pause/resume toggle
   */
  handlePauseToggle() {
    if (this.currentState === "paused") {
      void this.startRecording();
    } else {
      this.pauseRecording();
    }
  }
  /**
   * Pauses the current recording
   */
  pauseRecording() {
    try {
      this.recordingManager.pause();
      this.pauseTimer();
      this.currentState = "paused";
      this.ui.updateState(this.currentState);
      new import_obsidian12.Notice("Recording paused");
    } catch (error) {
      this.handleError("Failed to pause recording", error);
    }
  }
  /**
   * Handles stop button click
   */
  async handleStop() {
    try {
      const blob = await this.recordingManager.stop();
      if (!blob) {
        throw new Error("No audio data received from recorder");
      }
      this.cleanup();
      super.close();
      if (this.onStop) {
        const settings = this.app.plugins.plugins["neurovox"].settings;
        await this.onStop(blob, settings.saveRecording);
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      this.handleError("Failed to stop recording", error);
    }
  }
  /**
   * Manages the recording timer
   */
  startTimer() {
    this.seconds = 0;
    this.updateTimerDisplay();
    this.intervalId = window.setInterval(() => {
      this.seconds++;
      this.updateTimerDisplay();
      if (this.seconds >= this.CONFIG.maxDuration) {
        void this.handleStop();
        new import_obsidian12.Notice("Maximum recording duration reached");
      }
    }, this.CONFIG.updateInterval);
  }
  /**
   * Updates the timer display
   */
  updateTimerDisplay() {
    this.ui.updateTimer(
      this.seconds,
      this.CONFIG.maxDuration,
      this.CONFIG.warningThreshold
    );
  }
  /**
   * Pauses the timer
   */
  pauseTimer() {
    if (this.intervalId) {
      window.clearInterval(this.intervalId);
      this.intervalId = null;
    }
  }
  /**
   * Resumes the timer
   */
  resumeTimer() {
    if (!this.intervalId) {
      this.intervalId = window.setInterval(() => {
        this.seconds++;
        this.updateTimerDisplay();
      }, this.CONFIG.updateInterval);
    }
  }
  /**
   * Cleans up all resources
   */
  cleanup() {
    var _a;
    try {
      this.pauseTimer();
      this.recordingManager.cleanup();
      (_a = this.ui) == null ? void 0 : _a.cleanup();
    } catch (error) {
    } finally {
      this.currentState = "inactive";
      this.seconds = 0;
      this.isClosing = false;
    }
  }
  /**
   * Handles errors with user feedback
   */
  handleError(message, error) {
    const errorMessage = error instanceof Error ? error.message : "Unknown error";
    new import_obsidian12.Notice(`${message}: ${errorMessage}`);
    this.cleanup();
    void this.requestClose();
  }
};

// src/ui/ToolbarButton.ts
var ToolbarButton = class {
  constructor(plugin, pluginData) {
    this.plugin = plugin;
    this.pluginData = pluginData;
    this.createButton();
  }
  /**
   * Creates the toolbar microphone button and adds it to the ribbon.
   */
  createButton() {
    this.ribbonIconEl = this.plugin.addRibbonIcon(
      "mic-vocal",
      "Start recording",
      (evt) => {
        this.openRecordingModal();
      }
    );
    this.ribbonIconEl.addClass("neurovox-toolbar-button");
  }
  /**
   * Opens the recording modal.
   */
  openRecordingModal() {
    const activeLeaf = this.plugin.app.workspace.getActiveViewOfType(import_obsidian13.MarkdownView);
    if (activeLeaf) {
      const activeFile = activeLeaf.file;
      if (!activeFile) {
        new import_obsidian13.Notice("No active file to insert transcription.");
        return;
      }
      const editor = activeLeaf.editor;
      const cursorPosition = editor.getCursor();
      const modal = new TimerModal(this.plugin.app);
      modal.onStop = (audioBlob) => {
        this.plugin.recordingProcessor.processRecording(audioBlob, activeFile, cursorPosition);
      };
      modal.open();
    } else {
      new import_obsidian13.Notice("No active note found to insert transcription.");
    }
  }
  /**
   * Removes the toolbar button from the ribbon.
   */
  remove() {
    this.ribbonIconEl.detach();
  }
};

// src/adapters/OpenAIAdapter.ts
var OpenAIAdapter = class extends AIAdapter {
  constructor(settings) {
    super(settings, "openai" /* OpenAI */);
    this.apiKey = "";
  }
  getApiKey() {
    return this.apiKey;
  }
  setApiKeyInternal(key) {
    this.apiKey = key;
  }
  getApiBaseUrl() {
    return "https://api.openai.com/v1";
  }
  getTextGenerationEndpoint() {
    return "/chat/completions";
  }
  getTranscriptionEndpoint() {
    return "/audio/transcriptions";
  }
  async validateApiKeyImpl() {
    if (!this.apiKey) {
      return false;
    }
    try {
      await this.makeAPIRequest(
        `${this.getApiBaseUrl()}/chat/completions`,
        "POST",
        {
          "Content-Type": "application/json"
        },
        JSON.stringify({
          model: "gpt-4o-mini",
          messages: [{ role: "user", content: "test" }],
          max_tokens: 1
        })
      );
      return true;
    } catch (error) {
      return false;
    }
  }
  parseTextGenerationResponse(response) {
    var _a, _b, _c;
    if ((_c = (_b = (_a = response == null ? void 0 : response.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content) {
      return response.choices[0].message.content;
    }
    throw new Error("Invalid response format from OpenAI");
  }
  parseTranscriptionResponse(response) {
    if (response == null ? void 0 : response.text) {
      return response.text;
    }
    throw new Error("Invalid transcription response format from OpenAI");
  }
};

// src/adapters/GroqAdapter.ts
var GroqAdapter = class extends AIAdapter {
  constructor(settings) {
    super(settings, "groq" /* Groq */);
    this.apiKey = "";
  }
  getApiKey() {
    return this.apiKey;
  }
  setApiKeyInternal(key) {
    this.apiKey = key;
  }
  getApiBaseUrl() {
    return "https://api.groq.com/openai/v1";
  }
  getTextGenerationEndpoint() {
    return "/chat/completions";
  }
  getTranscriptionEndpoint() {
    return "/audio/transcriptions";
  }
  async validateApiKeyImpl() {
    if (!this.apiKey) {
      return false;
    }
    try {
      await this.makeAPIRequest(
        `${this.getApiBaseUrl()}/chat/completions`,
        "POST",
        {
          "Content-Type": "application/json"
        },
        JSON.stringify({
          model: "mixtral-8x7b-32768",
          messages: [{ role: "user", content: "test" }],
          max_tokens: 1
        })
      );
      return true;
    } catch (error) {
      return false;
    }
  }
  parseTextGenerationResponse(response) {
    var _a, _b, _c;
    if ((_c = (_b = (_a = response == null ? void 0 : response.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content) {
      return response.choices[0].message.content;
    }
    throw new Error("Invalid response format from Groq");
  }
  parseTranscriptionResponse(response) {
    if (response == null ? void 0 : response.text) {
      return response.text;
    }
    throw new Error("Invalid transcription response format from Groq");
  }
};

// src/main.ts
var NeuroVoxPlugin = class extends import_obsidian14.Plugin {
  constructor() {
    super(...arguments);
    this.buttonMap = /* @__PURE__ */ new Map();
    this.toolbarButton = null;
    this.activeLeaf = null;
    this.settingTab = null;
    this.modalInstance = null;
  }
  async onload() {
    try {
      await this.initializePlugin();
    } catch (error) {
    }
  }
  async initializePlugin() {
    await this.loadPluginData();
    this.initializeAIAdapters();
    await this.validateApiKeys();
    this.registerSettingsTab();
    this.registerCommands();
    this.registerEvents();
    this.recordingProcessor = RecordingProcessor.getInstance(this, this.pluginData);
    this.initializeUI();
  }
  async validateApiKeys() {
    try {
      const openaiAdapter = this.aiAdapters.get("openai" /* OpenAI */);
      const groqAdapter = this.aiAdapters.get("groq" /* Groq */);
      if (openaiAdapter) {
        openaiAdapter.setApiKey(this.settings.openaiApiKey);
        await openaiAdapter.validateApiKey();
      }
      if (groqAdapter) {
        groqAdapter.setApiKey(this.settings.groqApiKey);
        await groqAdapter.validateApiKey();
      }
      if (openaiAdapter && !openaiAdapter.isReady() && this.settings.openaiApiKey) {
        new import_obsidian14.Notice("\u274C OpenAI API key validation failed");
      }
      if (groqAdapter && !groqAdapter.isReady() && this.settings.groqApiKey) {
        new import_obsidian14.Notice("\u274C Groq API key validation failed");
      }
    } catch (error) {
    }
  }
  async loadPluginData() {
    const data = await this.loadData();
    this.pluginData = data ? { ...DEFAULT_SETTINGS, ...data } : { ...DEFAULT_SETTINGS };
    this.settings = this.pluginData;
  }
  async savePluginData() {
    await this.saveData(this.pluginData);
  }
  initializeAIAdapters() {
    const adapters = [
      ["openai" /* OpenAI */, new OpenAIAdapter(this.pluginData)],
      ["groq" /* Groq */, new GroqAdapter(this.pluginData)]
    ];
    this.aiAdapters = new Map(adapters);
  }
  registerSettingsTab() {
    this.addSettingTab(new NeuroVoxSettingTab(this.app, this));
  }
  registerCommands() {
    this.addCommand({
      id: "start-recording",
      name: "Start recording",
      checkCallback: (checking) => {
        const activeView = this.app.workspace.getActiveViewOfType(import_obsidian14.MarkdownView);
        if (!(activeView == null ? void 0 : activeView.file))
          return false;
        if (checking)
          return true;
        this.handleRecordingStart();
        return true;
      }
    });
    this.addCommand({
      id: "transcribe-audio",
      name: "Transcribe audio file",
      callback: async () => {
        const activeFile = this.app.workspace.getActiveFile();
        if (!activeFile || !this.isValidAudioFile(activeFile)) {
          new import_obsidian14.Notice("\u274C Active file is not a valid audio file");
          return;
        }
        new import_obsidian14.Notice(`\u{1F3B5} Transcribing: ${activeFile.path}`);
        await this.processExistingAudioFile(activeFile);
      }
    });
    this.addCommand({
      id: "transcribe-video",
      name: "Transcribe video file",
      checkCallback: (checking) => {
        const activeFile = this.app.workspace.getActiveFile();
        const isValidVideo = this.isValidVideoFile(activeFile);
        if (!activeFile || !isValidVideo)
          return false;
        if (checking)
          return true;
        void this.processVideoFile(activeFile);
        return true;
      }
    });
  }
  isValidAudioFile(file) {
    if (!file)
      return false;
    const validExtensions = ["mp3", "wav", "webm", "m4a"];
    return validExtensions.includes(file.extension.toLowerCase());
  }
  isValidVideoFile(file) {
    if (!file)
      return false;
    const validExtensions = ["mp4", "webm", "mov"];
    return validExtensions.includes(file.extension.toLowerCase());
  }
  getAudioMimeType(extension) {
    const mimeTypes = {
      "mp3": "audio/mpeg",
      "wav": "audio/wav",
      "webm": "audio/webm",
      "m4a": "audio/mp4"
    };
    return mimeTypes[extension.toLowerCase()] || "audio/wav";
  }
  getVideoMimeType(extension) {
    const mimeTypes = {
      "mp4": "video/mp4",
      "webm": "video/webm",
      "mov": "video/quicktime"
    };
    return mimeTypes[extension.toLowerCase()] || "video/mp4";
  }
  async processExistingAudioFile(file) {
    try {
      const adapter = this.aiAdapters.get(this.pluginData.transcriptionProvider);
      if (!adapter) {
        throw new Error(`Transcription provider ${this.pluginData.transcriptionProvider} not found`);
      }
      if (!adapter.getApiKey()) {
        throw new Error(`API key not set for ${this.pluginData.transcriptionProvider}`);
      }
      const timestamp = new Date().toISOString().slice(0, 19).replace(/[-:]/g, "").replace("T", "-");
      const sanitizedName = file.basename.replace(/[\\/:*?"<>|]/g, "");
      const transcriptsFolder = "Transcripts";
      const baseFileName = `${transcriptsFolder}/${timestamp}-${sanitizedName}.md`;
      let newFileName = baseFileName;
      let count = 1;
      const normalizedPath = (0, import_obsidian14.normalizePath)(transcriptsFolder);
      if (!await this.app.vault.adapter.exists(normalizedPath)) {
        await this.app.vault.createFolder(normalizedPath);
      }
      while (await this.app.vault.adapter.exists(newFileName)) {
        newFileName = `Transcripts/${timestamp}-${sanitizedName}-${count}.md`;
        count++;
      }
      const initialContent = [
        "---",
        `source: ${file.path}`,
        `date: ${new Date().toISOString()}`,
        `type: audio-transcription`,
        `size: ${(file.stat.size / (1024 * 1024)).toFixed(2)}MB`,
        "---",
        "",
        "# \u{1F3B5} Audio Transcription",
        "",
        ""
      ].join("\n");
      const newFile = await this.app.vault.create(newFileName, initialContent);
      await this.app.workspace.getLeaf().openFile(newFile);
      const audioBuffer = await this.app.vault.readBinary(file);
      const blob = new Blob([audioBuffer], {
        type: this.getAudioMimeType(file.extension)
      });
      new import_obsidian14.Notice("\u{1F399}\uFE0F Processing audio file...");
      await this.recordingProcessor.processRecording(
        blob,
        newFile,
        { line: initialContent.split("\n").length, ch: 0 },
        file.path
      );
      new import_obsidian14.Notice("\u2728 Transcription completed successfully!");
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      new import_obsidian14.Notice(`\u274C Failed to process audio file: ${errorMessage}`);
      throw error;
    }
  }
  async processVideoFile(file) {
    try {
      const videoProcessor = await VideoProcessor.getInstance(this, this.pluginData);
      await videoProcessor.processVideo(file);
    } catch (error) {
      new import_obsidian14.Notice("\u274C Failed to process video file");
      throw error;
    }
  }
  registerEvents() {
    this.registerEvent(
      this.app.workspace.on("active-leaf-change", this.handleActiveLeafChange.bind(this))
    );
    this.registerEvent(
      this.app.workspace.on("layout-change", this.handleLayoutChange.bind(this))
    );
    this.registerEvent(
      this.app.vault.on("delete", this.handleFileDelete.bind(this))
    );
  }
  handleActiveLeafChange(leaf) {
    this.activeLeaf = leaf;
    this.buttonMap.forEach((button, path) => {
      button.remove();
    });
    this.buttonMap.clear();
    if ((leaf == null ? void 0 : leaf.view) instanceof import_obsidian14.MarkdownView && leaf.view.file) {
      this.createButtonForFile(leaf.view.file);
    }
  }
  handleLayoutChange() {
    const activeView = this.app.workspace.getActiveViewOfType(import_obsidian14.MarkdownView);
    if (activeView == null ? void 0 : activeView.file) {
      const button = this.buttonMap.get(activeView.file.path);
      button == null ? void 0 : button.show();
    }
  }
  handleFileDelete(file) {
    if (file instanceof import_obsidian14.TFile) {
      const button = this.buttonMap.get(file.path);
      if (button) {
        button.remove();
        this.buttonMap.delete(file.path);
      }
    }
  }
  initializeUI() {
    this.cleanupUI();
    if (this.pluginData.showToolbarButton) {
      this.toolbarButton = new ToolbarButton(this, this.pluginData);
    }
  }
  createButtonForFile(file) {
    if (!this.pluginData.showFloatingButton)
      return;
    const existingButton = this.buttonMap.get(file.path);
    if (existingButton) {
      existingButton.remove();
      this.buttonMap.delete(file.path);
    }
    const button = new FloatingButton(
      this,
      this.pluginData,
      () => this.handleRecordingStart()
    );
    this.buttonMap.set(file.path, button);
  }
  cleanupUI() {
    this.buttonMap.forEach((button) => button.remove());
    this.buttonMap.clear();
    if (this.toolbarButton) {
      this.toolbarButton.remove();
      this.toolbarButton = null;
    }
  }
  handleRecordingStart() {
    var _a;
    const activeView = this.app.workspace.getActiveViewOfType(import_obsidian14.MarkdownView);
    if (!activeView) {
      new import_obsidian14.Notice("\u274C No active note found to insert transcription.");
      return;
    }
    const activeFile = activeView.file;
    if (!activeFile) {
      new import_obsidian14.Notice("\u274C No active file found.");
      return;
    }
    if (this.pluginData.useRecordingModal) {
      if (this.modalInstance)
        return;
      this.modalInstance = new TimerModal(this.app);
      this.modalInstance.onStop = async (audioBlob, shouldSave) => {
        try {
          const adapter = this.aiAdapters.get(this.pluginData.transcriptionProvider);
          if (!adapter) {
            throw new Error(`Transcription provider ${this.pluginData.transcriptionProvider} not found`);
          }
          if (!adapter.getApiKey()) {
            throw new Error(`API key not set for ${this.pluginData.transcriptionProvider}`);
          }
          await this.recordingProcessor.processRecording(
            audioBlob,
            activeFile,
            activeView.editor.getCursor(),
            void 0,
            shouldSave
          );
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : "Unknown error";
          new import_obsidian14.Notice(`\u274C Failed to process recording: ${errorMessage}`);
        }
      };
      const originalOnClose = (_a = this.modalInstance.onClose) == null ? void 0 : _a.bind(this.modalInstance);
      this.modalInstance.onClose = async () => {
        if (originalOnClose) {
          await originalOnClose();
        }
        this.modalInstance = null;
        return Promise.resolve();
      };
      this.modalInstance.open();
    }
  }
  async saveSettings() {
    await this.savePluginData();
    this.initializeUI();
  }
  updateAllButtonColors() {
    this.buttonMap.forEach((button) => {
      button.updateButtonColor();
    });
  }
  onunload() {
    this.cleanupUI();
  }
};
/*! Bundled license information:

recordrtc/RecordRTC.js:
  (**
   * {@link https://github.com/muaz-khan/RecordRTC|RecordRTC} is a WebRTC JavaScript library for audio/video as well as screen activity recording. It supports Chrome, Firefox, Opera, Android, and Microsoft Edge. Platforms: Linux, Mac and Windows. 
   * @summary Record audio, video or screen inside the browser.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef RecordRTC
   * @class
   * @example
   * var recorder = RecordRTC(mediaStream or [arrayOfMediaStream], {
   *     type: 'video', // audio or video or gif or canvas
   *     recorderType: MediaStreamRecorder || CanvasRecorder || StereoAudioRecorder || Etc
   * });
   * recorder.startRecording();
   * @see For further information:
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - Single media-stream object, array of media-streams, html-canvas-element, etc.
   * @param {object} config - {type:"video", recorderType: MediaStreamRecorder, disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, desiredSampRate: 16000, video: HTMLVideoElement, etc.}
   *)
  (**
   * {@link RecordRTCConfiguration} is an inner/private helper for {@link RecordRTC}.
   * @summary It configures the 2nd parameter passed over {@link RecordRTC} and returns a valid "config" object.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef RecordRTCConfiguration
   * @class
   * @example
   * var options = RecordRTCConfiguration(mediaStream, options);
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @param {object} config - {type:"video", disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, getNativeBlob:true, etc.}
   *)
  (**
   * {@link GetRecorderType} is an inner/private helper for {@link RecordRTC}.
   * @summary It returns best recorder-type available for your browser.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef GetRecorderType
   * @class
   * @example
   * var RecorderType = GetRecorderType(options);
   * var recorder = new RecorderType(options);
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @param {object} config - {type:"video", disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, etc.}
   *)
  (**
   * MRecordRTC runs on top of {@link RecordRTC} to bring multiple recordings in a single place, by providing simple API.
   * @summary MRecordRTC stands for "Multiple-RecordRTC".
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef MRecordRTC
   * @class
   * @example
   * var recorder = new MRecordRTC();
   * recorder.addStream(MediaStream);
   * recorder.mediaType = {
   *     audio: true, // or StereoAudioRecorder or MediaStreamRecorder
   *     video: true, // or WhammyRecorder or MediaStreamRecorder or WebAssemblyRecorder or CanvasRecorder
   *     gif: true    // or GifRecorder
   * };
   * // mimeType is optional and should be set only in advance cases.
   * recorder.mimeType = {
   *     audio: 'audio/wav',
   *     video: 'video/webm',
   *     gif:   'image/gif'
   * };
   * recorder.startRecording();
   * @see For further information:
   * @see {@link https://github.com/muaz-khan/RecordRTC/tree/master/MRecordRTC|MRecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @requires {@link RecordRTC}
   *)
  (**
   * Storage is a standalone object used by {@link RecordRTC} to store reusable objects e.g. "new AudioContext".
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @example
   * Storage.AudioContext === webkitAudioContext
   * @property {webkitAudioContext} AudioContext - Keeps a reference to AudioContext object.
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   *)
  (**
   * MediaStreamRecorder is an abstraction layer for {@link https://w3c.github.io/mediacapture-record/MediaRecorder.html|MediaRecorder API}. It is used by {@link RecordRTC} to record MediaStream(s) in both Chrome and Firefox.
   * @summary Runs top over {@link https://w3c.github.io/mediacapture-record/MediaRecorder.html|MediaRecorder API}.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://github.com/muaz-khan|Muaz Khan}
   * @typedef MediaStreamRecorder
   * @class
   * @example
   * var config = {
   *     mimeType: 'video/webm', // vp8, vp9, h264, mkv, opus/vorbis
   *     audioBitsPerSecond : 256 * 8 * 1024,
   *     videoBitsPerSecond : 256 * 8 * 1024,
   *     bitsPerSecond: 256 * 8 * 1024,  // if this is provided, skip above two
   *     checkForInactiveTracks: true,
   *     timeSlice: 1000, // concatenate intervals based blobs
   *     ondataavailable: function() {} // get intervals based blobs
   * }
   * var recorder = new MediaStreamRecorder(mediaStream, config);
   * recorder.record();
   * recorder.stop(function(blob) {
   *     video.src = URL.createObjectURL(blob);
   *
   *     // or
   *     var blob = recorder.blob;
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @param {object} config - {disableLogs:true, initCallback: function, mimeType: "video/webm", timeSlice: 1000}
   * @throws Will throw an error if first argument "MediaStream" is missing. Also throws error if "MediaRecorder API" are not supported by the browser.
   *)
  (**
   * StereoAudioRecorder is a standalone class used by {@link RecordRTC} to bring "stereo" audio-recording in chrome.
   * @summary JavaScript standalone object for stereo audio recording.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef StereoAudioRecorder
   * @class
   * @example
   * var recorder = new StereoAudioRecorder(MediaStream, {
   *     sampleRate: 44100,
   *     bufferSize: 4096
   * });
   * recorder.record();
   * recorder.stop(function(blob) {
   *     video.src = URL.createObjectURL(blob);
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @param {object} config - {sampleRate: 44100, bufferSize: 4096, numberOfAudioChannels: 1, etc.}
   *)
  (**
   * CanvasRecorder is a standalone class used by {@link RecordRTC} to bring HTML5-Canvas recording into video WebM. It uses HTML2Canvas library and runs top over {@link Whammy}.
   * @summary HTML2Canvas recording into video WebM.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef CanvasRecorder
   * @class
   * @example
   * var recorder = new CanvasRecorder(htmlElement, { disableLogs: true, useWhammyRecorder: true });
   * recorder.record();
   * recorder.stop(function(blob) {
   *     video.src = URL.createObjectURL(blob);
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {HTMLElement} htmlElement - querySelector/getElementById/getElementsByTagName[0]/etc.
   * @param {object} config - {disableLogs:true, initCallback: function}
   *)
  (**
   * WhammyRecorder is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It runs top over {@link Whammy}.
   * @summary Video recording feature in Chrome.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef WhammyRecorder
   * @class
   * @example
   * var recorder = new WhammyRecorder(mediaStream);
   * recorder.record();
   * recorder.stop(function(blob) {
   *     video.src = URL.createObjectURL(blob);
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @param {object} config - {disableLogs: true, initCallback: function, video: HTMLVideoElement, etc.}
   *)
  (**
   * Whammy is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It is written by {@link https://github.com/antimatter15|antimatter15}
   * @summary A real time javascript webm encoder based on a canvas hack.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef Whammy
   * @class
   * @example
   * var recorder = new Whammy().Video(15);
   * recorder.add(context || canvas || dataURL);
   * var output = recorder.compile();
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   *)
  (**
   * DiskStorage is a standalone object used by {@link RecordRTC} to store recorded blobs in IndexedDB storage.
   * @summary Writing blobs into IndexedDB.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @example
   * DiskStorage.Store({
   *     audioBlob: yourAudioBlob,
   *     videoBlob: yourVideoBlob,
   *     gifBlob  : yourGifBlob
   * });
   * DiskStorage.Fetch(function(dataURL, type) {
   *     if(type === 'audioBlob') { }
   *     if(type === 'videoBlob') { }
   *     if(type === 'gifBlob')   { }
   * });
   * // DiskStorage.dataStoreName = 'recordRTC';
   * // DiskStorage.onError = function(error) { };
   * @property {function} init - This method must be called once to initialize IndexedDB ObjectStore. Though, it is auto-used internally.
   * @property {function} Fetch - This method fetches stored blobs from IndexedDB.
   * @property {function} Store - This method stores blobs in IndexedDB.
   * @property {function} onError - This function is invoked for any known/unknown error.
   * @property {string} dataStoreName - Name of the ObjectStore created in IndexedDB storage.
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   *)
  (**
   * GifRecorder is standalone calss used by {@link RecordRTC} to record video or canvas into animated gif.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef GifRecorder
   * @class
   * @example
   * var recorder = new GifRecorder(mediaStream || canvas || context, { onGifPreview: function, onGifRecordingStarted: function, width: 1280, height: 720, frameRate: 200, quality: 10 });
   * recorder.record();
   * recorder.stop(function(blob) {
   *     img.src = URL.createObjectURL(blob);
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object or HTMLCanvasElement or CanvasRenderingContext2D.
   * @param {object} config - {disableLogs:true, initCallback: function, width: 320, height: 240, frameRate: 200, quality: 10}
   *)
  (**
   * MultiStreamRecorder can record multiple videos in single container.
   * @summary Multi-videos recorder.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef MultiStreamRecorder
   * @class
   * @example
   * var options = {
   *     mimeType: 'video/webm'
   * }
   * var recorder = new MultiStreamRecorder(ArrayOfMediaStreams, options);
   * recorder.record();
   * recorder.stop(function(blob) {
   *     video.src = URL.createObjectURL(blob);
   *
   *     // or
   *     var blob = recorder.blob;
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStreams} mediaStreams - Array of MediaStreams.
   * @param {object} config - {disableLogs:true, frameInterval: 1, mimeType: "video/webm"}
   *)
  (**
   * RecordRTCPromisesHandler adds promises support in {@link RecordRTC}. Try a {@link https://github.com/muaz-khan/RecordRTC/blob/master/simple-demos/RecordRTCPromisesHandler.html|demo here}
   * @summary Promises for {@link RecordRTC}
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef RecordRTCPromisesHandler
   * @class
   * @example
   * var recorder = new RecordRTCPromisesHandler(mediaStream, options);
   * recorder.startRecording()
   *         .then(successCB)
   *         .catch(errorCB);
   * // Note: You can access all RecordRTC API using "recorder.recordRTC" e.g. 
   * recorder.recordRTC.onStateChanged = function(state) {};
   * recorder.recordRTC.setRecordingDuration(5000);
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - Single media-stream object, array of media-streams, html-canvas-element, etc.
   * @param {object} config - {type:"video", recorderType: MediaStreamRecorder, disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, etc.}
   * @throws Will throw an error if "new" keyword is not used to initiate "RecordRTCPromisesHandler". Also throws error if first argument "MediaStream" is missing.
   * @requires {@link RecordRTC}
   *)
  (**
   * WebAssemblyRecorder lets you create webm videos in JavaScript via WebAssembly. The library consumes raw RGBA32 buffers (4 bytes per pixel) and turns them into a webm video with the given framerate and quality. This makes it compatible out-of-the-box with ImageData from a CANVAS. With realtime mode you can also use webm-wasm for streaming webm videos.
   * @summary Video recording feature in Chrome, Firefox and maybe Edge.
   * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}
   * @author {@link https://MuazKhan.com|Muaz Khan}
   * @typedef WebAssemblyRecorder
   * @class
   * @example
   * var recorder = new WebAssemblyRecorder(mediaStream);
   * recorder.record();
   * recorder.stop(function(blob) {
   *     video.src = URL.createObjectURL(blob);
   * });
   * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}
   * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.
   * @param {object} config - {webAssemblyPath:'webm-wasm.wasm',workerPath: 'webm-worker.js', frameRate: 30, width: 1920, height: 1080, bitrate: 1024, realtime: true}
   *)
*/

/* nosourcemap */